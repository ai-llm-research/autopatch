{
 "supplementary_code": "```c\nstruct v3d_dev {\nstruct drm_device drm;\n/* Short representation (e.g. 33, 41) of the V3D tech version */\nint ver;\n/* Short representation (e.g. 5, 6) of the V3D tech revision */\nint rev;\nbool single_irq_line;\nstruct v3d_perfmon_info perfmon_info;\nvoid __iomem *hub_regs;\nvoid __iomem *core_regs[3];\nvoid __iomem *bridge_regs;\nvoid __iomem *gca_regs;\nstruct clk *clk;\nstruct reset_control *reset;\n/* Virtual and DMA addresses of the single shared page table. */\nvolatile u32 *pt;\ndma_addr_t pt_paddr;\n/* Virtual and DMA addresses of the MMU's scratch page. When\n* a read or write is invalid in the MMU, it will be\n* redirected here.\n*/\nvoid *mmu_scratch;\ndma_addr_t mmu_scratch_paddr;\n/* virtual address bits from V3D to the MMU. */\nint va_width;\n/* Number of V3D cores. */\nu32 cores;\n/* Allocator managing the address space. All units are in\n* number of pages.\n*/\nstruct drm_mm mm;\nspinlock_t mm_lock;\n/*\n* tmpfs instance used for shmem backed objects\n*/\nstruct vfsmount *gemfs;\nstruct work_struct overflow_mem_work;\nstruct v3d_bin_job *bin_job;\nstruct v3d_render_job *render_job;\nstruct v3d_tfu_job *tfu_job;\nstruct v3d_csd_job *csd_job;\nstruct v3d_cpu_job *cpu_job;\nstruct v3d_queue_state queue[V3D_MAX_QUEUES];\n/* Spinlock used to synchronize the overflow memory\n* management against bin job submission.\n*/\nspinlock_t job_lock;\n/* Used to track the active perfmon if any. */\nstruct v3d_perfmon *active_perfmon;\n/* Protects bo_stats */\nstruct mutex bo_lock;\n/* Lock taken when resetting the GPU, to keep multiple\n* processes from trying to park the scheduler threads and\n* reset at once.\n*/\nstruct mutex reset_lock;\n/* Lock taken when creating and pushing the GPU scheduler\n* jobs, to keep the sched-fence seqnos in order.\n*/\nstruct mutex sched_lock;\n/* Lock taken during a cache clean and when initiating an L2\n* flush, to keep L2 flushes from interfering with the\n* synchronous L2 cleans.\n*/\nstruct mutex cache_clean_lock;\nstruct {\nu32 num_allocated;\nu32 pages_allocated;\n} bo_stats;\n};\n```\n```c\n#define V3D_CORE_READ(core, offset) readl(v3d->core_regs[core] + offset)\n```\n```c\n#define V3D_CORE_WRITE(core, offset, val) writel(val, v3d->core_regs[core] + offset)\n```\n```c\nstatic inline bool schedule_work(struct work_struct *work)\n{\nreturn queue_work(system_wq, work);\n}\n```\n```c\nstruct v3d_fence {\nstruct dma_fence base;\nstruct drm_device *dev;\n/* v3d seqno for signaled() test */\nu64 seqno;\nenum v3d_queue queue;\n};\n```\n```c\nstatic inline struct v3d_fence *\nto_v3d_fence(struct dma_fence *fence)\n{\nreturn (struct v3d_fence *)fence;\n}\n```\n```c\nvoid\nv3d_job_update_stats(struct v3d_job *job, enum v3d_queue queue)\n{\nstruct v3d_dev *v3d = job->v3d;\nstruct v3d_file_priv *file = job->file->driver_priv;\nstruct v3d_stats *global_stats = &v3d->queue[queue].stats;\nstruct v3d_stats *local_stats = &file->stats[queue];\nu64 now = local_clock();\nunsigned long flags;\n/* See comment in v3d_job_start_stats() */\nif (IS_ENABLED(CONFIG_LOCKDEP))\nlocal_irq_save(flags);\nelse\npreempt_disable();\nv3d_stats_update(local_stats, now);\nv3d_stats_update(global_stats, now);\nif (IS_ENABLED(CONFIG_LOCKDEP))\nlocal_irq_restore(flags);\nelse\npreempt_enable();\n}\n```\n```c\nTRACE_EVENT(v3d_bcl_irq,\nTP_PROTO(struct drm_device *dev,\nuint64_t seqno),\nTP_ARGS(dev, seqno),\nTP_STRUCT__entry(\n__field(u32, dev)\n__field(u64, seqno)\n),\nTP_fast_assign(\n__entry->dev = dev->primary->index;\n__entry->seqno = seqno;\n),\nTP_printk(\"dev=%u, seqno=%llu\",\n__entry->dev,\n__entry->seqno)\n);\n```\n```c\nTRACE_EVENT(v3d_rcl_irq,\nTP_PROTO(struct drm_device *dev,\nuint64_t seqno),\nTP_ARGS(dev, seqno),\nTP_STRUCT__entry(\n__field(u32, dev)\n__field(u64, seqno)\n),\nTP_fast_assign(\n__entry->dev = dev->primary->index;\n__entry->seqno = seqno;\n),\nTP_printk(\"dev=%u, seqno=%llu\",\n__entry->dev,\n__entry->seqno)\n);\n```\n```c\nTRACE_EVENT(v3d_csd_irq,\nTP_PROTO(struct drm_device *dev,\nuint64_t seqno),\nTP_ARGS(dev, seqno),\nTP_STRUCT__entry(\n__field(u32, dev)\n__field(u64, seqno)\n),\nTP_fast_assign(\n__entry->dev = dev->primary->index;\n__entry->seqno = seqno;\n),\nTP_printk(\"dev=%u, seqno=%llu\",\n__entry->dev,\n__entry->seqno)\n);\n```\n```c\nstatic irqreturn_t\nv3d_hub_irq(int irq, void *arg)\n{\nstruct v3d_dev *v3d = arg;\nu32 intsts;\nirqreturn_t status = IRQ_NONE;\nintsts = V3D_READ(V3D_HUB_INT_STS);\n/* Acknowledge the interrupts we're handling here. */\nV3D_WRITE(V3D_HUB_INT_CLR, intsts);\nif (intsts & V3D_HUB_INT_TFUC) {\nstruct v3d_fence *fence =\nto_v3d_fence(v3d->tfu_job->base.irq_fence);\nv3d_job_update_stats(&v3d->tfu_job->base, V3D_TFU);\ntrace_v3d_tfu_irq(&v3d->drm, fence->seqno);\ndma_fence_signal(&fence->base);\nstatus = IRQ_HANDLED;\n}\nif (intsts & (V3D_HUB_INT_MMU_WRV |\nV3D_HUB_INT_MMU_PTI |\nV3D_HUB_INT_MMU_CAP)) {\nu32 axi_id = V3D_READ(V3D_MMU_VIO_ID);\nu64 vio_addr = ((u64)V3D_READ(V3D_MMU_VIO_ADDR) <<\n(v3d->va_width - 32));\nstatic const char *const v3d41_axi_ids[] = {\n\"L2T\",\n\"PTB\",\n\"PSE\",\n\"TLB\",\n\"CLE\",\n\"TFU\",\n\"MMU\",\n\"GMP\",\n};\nconst char *client = \"?\";\nV3D_WRITE(V3D_MMU_CTL, V3D_READ(V3D_MMU_CTL));\nif (v3d->ver >= 41) {\naxi_id = axi_id >> 5;\nif (axi_id < ARRAY_SIZE(v3d41_axi_ids))\nclient = v3d41_axi_ids[axi_id];\n}\ndev_err(v3d->drm.dev, \"MMU error from client %s (%d) at 0x%llx%s%s%s\\n\",\nclient, axi_id, (long long)vio_addr,\n((intsts & V3D_HUB_INT_MMU_WRV) ?\n\", write violation\" : \"\"),\n((intsts & V3D_HUB_INT_MMU_PTI) ?\n\", pte invalid\" : \"\"),\n((intsts & V3D_HUB_INT_MMU_CAP) ?\n\", cap exceeded\" : \"\"));\nstatus = IRQ_HANDLED;\n}\nif (v3d->ver >= 71 && (intsts & V3D_V7_HUB_INT_GMPV)) {\ndev_err(v3d->drm.dev, \"GMP Violation\\n\");\nstatus = IRQ_HANDLED;\n}\nreturn status;\n}\n```\n```c\nint dma_fence_signal(struct dma_fence *fence)\n{\nunsigned long flags;\nint ret;\nbool tmp;\nif (WARN_ON(!fence))\nreturn -EINVAL;\ntmp = dma_fence_begin_signalling();\nspin_lock_irqsave(fence->lock, flags);\nret = dma_fence_signal_timestamp_locked(fence, ktime_get());\nspin_unlock_irqrestore(fence->lock, flags);\ndma_fence_end_signalling(tmp);\nreturn ret;\n}\nEXPORT_SYMBOL(dma_fence_signal);\n```\n",
 "function_prototype": "static irqreturn_t v3d_irq(int irq, void *arg)",
 "re_implemented_code": "\n```c\nstatic irqreturn_t v3d_irq(int irq, void *arg)\n{\nstruct v3d_dev *v3d = arg;\nu32 intsts;\nirqreturn_t status = IRQ_NONE;\n/* Read the interrupt status from the V3D core */\nintsts = V3D_READ(V3D_INT_STATUS);\n/* Acknowledge the interrupts by writing the status back to the clear register */\nV3D_WRITE(V3D_INT_ACKNOWLEDGE, intsts);\n/* Check if the interrupt status indicates an out-of-memory condition */\nif (intsts & V3D_INT_OOMM) {\n/* Schedule work to handle the overflow memory condition */\nschedule_work(&v3d->overflow_mem_work);\n/* Mark the interrupt as handled */\nstatus = IRQ_WAKE_THREAD;\n}\n/* Check if the interrupt status indicates that the binning process is done */\nif (intsts & V3D_INT_FLDONE) {\n/* Retrieve the fence associated with the binning job */\nstruct v3d_fence *fence = to_v3d_fence(v3d->bin_job->base.irq_fence);\n/* Trace the binning completion interrupt */\ntrace_v3d_bcl_irq(&v3d->drm, fence->seqno);\n/* Signal the completion of the binning job */\ndma_fence_signal(&fence->base);\n/* Mark the interrupt as handled */\nstatus = IRQ_HANDLED;\n}\n/* Check if the interrupt status indicates that the rendering process is done */\nif (intsts & V3D_INT_FRDONE) {\n/* Retrieve the fence associated with the rendering job */\nstruct v3d_fence *fence = to_v3d_fence(v3d->render_job->base.irq_fence);\n/* Trace the rendering completion interrupt */\ntrace_v3d_rcl_irq(&v3d->drm, fence->seqno);\n/* Signal the completion of the rendering job */\ndma_fence_signal(&fence->base);\n/* Mark the interrupt as handled */\nstatus = IRQ_HANDLED;\n}\n/* Check if the interrupt status indicates that the compute shader dispatch is done */\nif (intsts & V3D_INT_CSDFIN) {\n/* Retrieve the fence associated with the compute shader dispatch job */\nstruct v3d_fence *fence = to_v3d_fence(v3d->csd_job->base.irq_fence);\n/* Trace the compute shader dispatch completion interrupt */\ntrace_v3d_csd_irq(&v3d->drm, fence->seqno);\n/* Signal the completion of the compute shader dispatch job */\ndma_fence_signal(&fence->base);\n/* Mark the interrupt as handled */\nstatus = IRQ_HANDLED;\n}\n/* Check for GMP violation interrupt and log an error if it occurs */\nif (intsts & V3D_INT_GMPVF) {\ndev_err(v3d->drm.dev, \"GMP Violation\\n\");\nstatus = IRQ_HANDLED;\n}\n/* If using a single IRQ line and no core IRQs were handled, check the hub for MMU IRQs */\nif (!status && !v3d->single_irq_line)\nstatus = v3d_hub_irq(irq, arg);\n/* Return the status indicating whether any interrupts were handled */\nreturn status;\n}\n```\n",
 "is_vulnerable": true
}