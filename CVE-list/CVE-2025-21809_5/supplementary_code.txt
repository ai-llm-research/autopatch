```c
struct rxrpc_peer {
    struct rcu_head     rcu;        /* This must be first */
    refcount_t      ref;
    unsigned long       hash_key;
    struct hlist_node   hash_link;
    struct rxrpc_local  *local;
    struct hlist_head   error_targets;  /* targets for net error distribution */
    struct rb_root      service_conns;  /* Service connections */
    struct list_head    keepalive_link; /* Link in net->peer_keepalive[] */
    time64_t        last_tx_at; /* Last time packet sent here */
    seqlock_t       service_conn_lock;
    spinlock_t      lock;       /* access lock */
    unsigned int        if_mtu;     /* interface MTU for this peer */
    unsigned int        mtu;        /* network MTU for this peer */
    unsigned int        maxdata;    /* data size (MTU - hdrsize) */
    unsigned short      hdrsize;    /* header size (IP + UDP + RxRPC) */
    int         debug_id;   /* debug ID for printks */
    struct sockaddr_rxrpc   srx;        /* remote address */

    /* calculated RTT cache */
#define RXRPC_RTT_CACHE_SIZE 32
    spinlock_t      rtt_input_lock; /* RTT lock for input routine */
    ktime_t         rtt_last_req;   /* Time of last RTT request */
    unsigned int        rtt_count;  /* Number of samples we've got */

    u32         srtt_us;    /* smoothed round trip time << 3 in usecs */
    u32         mdev_us;    /* medium deviation         */
    u32         mdev_max_us;    /* maximal mdev for the last rtt period */
    u32         rttvar_us;  /* smoothed mdev_max            */
    u32         rto_us;     /* Retransmission timeout in usec */
    u8          backoff;    /* Backoff timeout (as shift) */

    u8          cong_ssthresh;  /* Congestion slow-start threshold */
};
```

```c
struct rxrpc_net {
    struct proc_dir_entry   *proc_net;  /* Subdir in /proc/net */
    u32         epoch;      /* Local epoch for detecting local-end reset */
    struct list_head    calls;      /* List of calls active in this namespace */
    spinlock_t      call_lock;  /* Lock for ->calls */
    atomic_t        nr_calls;   /* Count of allocated calls */

    atomic_t        nr_conns;
    struct list_head    bundle_proc_list; /* List of bundles for proc */
    struct list_head    conn_proc_list; /* List of conns in this namespace for proc */
    struct list_head    service_conns;  /* Service conns in this namespace */
    rwlock_t        conn_lock;  /* Lock for ->conn_proc_list, ->service_conns */
    struct work_struct  service_conn_reaper;
    struct timer_list   service_conn_reap_timer;

    bool            live;

    atomic_t        nr_client_conns;

    struct hlist_head   local_endpoints;
    struct mutex        local_mutex;    /* Lock for ->local_endpoints */

    DECLARE_HASHTABLE   (peer_hash, 10);
    spinlock_t      peer_hash_lock; /* Lock for ->peer_hash */

#define RXRPC_KEEPALIVE_TIME 20 /* NAT keepalive time in seconds */
    u8          peer_keepalive_cursor;
    time64_t        peer_keepalive_base;
    struct list_head    peer_keepalive[32];
    struct list_head    peer_keepalive_new;
    struct timer_list   peer_keepalive_timer;
    struct work_struct  peer_keepalive_work;

    atomic_t        stat_tx_data;
    atomic_t        stat_tx_data_retrans;
    atomic_t        stat_tx_data_send;
    atomic_t        stat_tx_data_send_frag;
    atomic_t        stat_tx_data_send_fail;
    atomic_t        stat_tx_data_underflow;
    atomic_t        stat_tx_data_cwnd_reset;
    atomic_t        stat_rx_data;
    atomic_t        stat_rx_data_reqack;
    atomic_t        stat_rx_data_jumbo;

    atomic_t        stat_tx_ack_fill;
    atomic_t        stat_tx_ack_send;
    atomic_t        stat_tx_ack_skip;
    atomic_t        stat_tx_acks[256];
    atomic_t        stat_rx_acks[256];

    atomic_t        stat_why_req_ack[8];

    atomic_t        stat_io_loop;
};
```

```c
#define ASSERT(X)                       \
do {                                \
    if (unlikely(!(X))) {                   \
        pr_err("Assertion failed\n");           \
        BUG();                      \
    }                           \
} while (0)
```

```c
static inline int hlist_empty(const struct hlist_head *h)
{
    return !READ_ONCE(h->first);
}
```

```c
static inline void spin_lock(spinlock_t *lock)
{
    int ret = pthread_spin_lock(lock);
    assert(!ret);
}
```

```c
static inline void hash_del_rcu(struct hlist_node *node)
{
    hlist_del_init_rcu(node);
}
```

```c
static inline void list_del_init(struct list_head *entry)
{
    __list_del_entry(entry);
    INIT_LIST_HEAD(entry);
}
```

```c
static inline void spin_unlock(spinlock_t *lock)
{
    int ret = pthread_spin_unlock(lock);
    assert(!ret);
}
```

```c
static void rxrpc_free_peer(struct rxrpc_peer *peer)
{
    trace_rxrpc_peer(peer->debug_id, 0, rxrpc_peer_free);
    rxrpc_put_local(peer->local, rxrpc_local_put_peer);
    kfree_rcu(peer, rcu);
}
```
