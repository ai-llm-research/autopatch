```c
struct net {
    /* First cache line can be often dirtied.
     * Do not place here read-mostly fields.
     */
    refcount_t      passive;    /* To decide when the network
                         * namespace should be freed.
                         */
    spinlock_t      rules_mod_lock;

    unsigned int        dev_base_seq;   /* protected by rtnl_mutex */
    u32         ifindex;

    spinlock_t      nsid_lock;
    atomic_t        fnhe_genid;

    struct list_head    list;       /* list of network namespaces */
    struct list_head    exit_list;  /* To linked to call pernet exit
                         * methods on dead net (
                         * pernet_ops_rwsem read locked),
                         * or to unregister pernet ops
                         * (pernet_ops_rwsem write locked).
                         */
    struct llist_node   defer_free_list;
    struct llist_node   cleanup_list;   /* namespaces on death row */

#ifdef CONFIG_KEYS
    struct key_tag      *key_domain;    /* Key domain of operation tag */
#endif
    struct user_namespace   *user_ns;   /* Owning user namespace */
    struct ucounts      *ucounts;
    struct idr      netns_ids;

    struct ns_common    ns;
    struct ref_tracker_dir  refcnt_tracker;
    struct ref_tracker_dir  notrefcnt_tracker; /* tracker for objects not
                            * refcounted against netns
                            */
    struct list_head    dev_base_head;
    struct proc_dir_entry   *proc_net;
    struct proc_dir_entry   *proc_net_stat;

#ifdef CONFIG_SYSCTL
    struct ctl_table_set    sysctls;
#endif

    struct sock         *rtnl;          /* rtnetlink socket */
    struct sock     *genl_sock;

    struct uevent_sock  *uevent_sock;       /* uevent socket */

    struct hlist_head   *dev_name_head;
    struct hlist_head   *dev_index_head;
    struct xarray       dev_by_index;
    struct raw_notifier_head    netdev_chain;

    /* Note that @hash_mix can be read millions times per second,
     * it is critical that it is on a read_mostly cache line.
     */
    u32         hash_mix;

    struct net_device       *loopback_dev;          /* The loopback */

    /* core fib_rules */
    struct list_head    rules_ops;

    struct netns_core   core;
    struct netns_mib    mib;
    struct netns_packet packet;
#if IS_ENABLED(CONFIG_UNIX)
    struct netns_unix   unx;
#endif
    struct netns_nexthop    nexthop;
    struct netns_ipv4   ipv4;
#if IS_ENABLED(CONFIG_IPV6)
    struct netns_ipv6   ipv6;
#endif
#if IS_ENABLED(CONFIG_IEEE802154_6LOWPAN)
    struct netns_ieee802154_lowpan  ieee802154_lowpan;
#endif
#if defined(CONFIG_IP_SCTP) || defined(CONFIG_IP_SCTP_MODULE)
    struct netns_sctp   sctp;
#endif
#ifdef CONFIG_NETFILTER
    struct netns_nf     nf;
#if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE)
    struct netns_ct     ct;
#endif
#if defined(CONFIG_NF_TABLES) || defined(CONFIG_NF_TABLES_MODULE)
    struct netns_nftables   nft;
#endif
#if IS_ENABLED(CONFIG_NF_FLOW_TABLE)
    struct netns_ft ft;
#endif
#endif
#ifdef CONFIG_WEXT_CORE
    struct sk_buff_head wext_nlevents;
#endif
    struct net_generic __rcu    *gen;

    /* Used to store attached BPF programs */
    struct netns_bpf    bpf;

    /* Note : following structs are cache line aligned */
#ifdef CONFIG_XFRM
    struct netns_xfrm   xfrm;
#endif

    u64         net_cookie; /* written once */

#if IS_ENABLED(CONFIG_IP_VS)
    struct netns_ipvs   *ipvs;
#endif
#if IS_ENABLED(CONFIG_MPLS)
    struct netns_mpls   mpls;
#endif
#if IS_ENABLED(CONFIG_CAN)
    struct netns_can    can;
#endif
#ifdef CONFIG_XDP_SOCKETS
    struct netns_xdp    xdp;
#endif
#if IS_ENABLED(CONFIG_MCTP)
    struct netns_mctp   mctp;
#endif
#if IS_ENABLED(CONFIG_CRYPTO_USER)
    struct sock     *crypto_nlsk;
#endif
    struct sock     *diag_nlsk;
#if IS_ENABLED(CONFIG_SMC)
    struct netns_smc    smc;
#endif
#ifdef CONFIG_DEBUG_NET_SMALL_RTNL
    /* Move to a better place when the config guard is removed. */
    struct mutex        rtnl_mutex;
#endif
} __randomize_layout;
```

```c
struct list_head {
    struct list_head *next, *prev;
};
```

```c
struct geneve_dev {
    struct geneve_dev_node hlist4;  /* vni hash table for IPv4 socket */
#if IS_ENABLED(CONFIG_IPV6)
    struct geneve_dev_node hlist6;  /* vni hash table for IPv6 socket */
#endif
    struct net     *net;    /* netns for packet i/o */
    struct net_device  *dev;    /* netdev for geneve tunnel */
    struct geneve_sock __rcu *sock4;    /* IPv4 socket used for geneve tunnel */
#if IS_ENABLED(CONFIG_IPV6)
    struct geneve_sock __rcu *sock6;    /* IPv6 socket used for geneve tunnel */
#endif
    struct list_head   next;    /* geneve's per namespace list */
    struct gro_cells   gro_cells;
    struct geneve_config cfg;
};
```

```c
static inline void *net_generic(const struct net *net, unsigned int id)
{
    struct net_generic *ng;
    void *ptr;

    rcu_read_lock();
    ng = rcu_dereference(net->gen);
    ptr = ng->ptr[id];
    rcu_read_unlock();

    return ptr;
}
```

```c
#define for_each_netdev_safe(net, d, n) \
        list_for_each_entry_safe(d, n, &(net)->dev_base_head, dev_list)
```

```c
void unregister_netdevice_queue(struct net_device *dev, struct list_head *head)
{
    ASSERT_RTNL();

    if (head) {
        list_move_tail(&dev->unreg_list, head);
    } else {
        LIST_HEAD(single);

        list_add(&dev->unreg_list, &single);
        unregister_netdevice_many(&single);
    }
}
EXPORT_SYMBOL(unregister_netdevice_queue);
```

```c
#define list_for_each_entry_safe(pos, n, head, member)          \
    for (pos = list_first_entry(head, typeof(*pos), member),    \
        n = list_next_entry(pos, member);           \
         !list_entry_is_head(pos, head, member);            \
         pos = n, n = list_next_entry(n, member))
```

```c
static inline int net_eq(const struct net *net1, const struct net *net2)
{
    return 1;
}
```

```c
static inline struct net *dev_net(const struct net_device *dev)
{
    return read_pnet(&dev->nd_net);
}
```
