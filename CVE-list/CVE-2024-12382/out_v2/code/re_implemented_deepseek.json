{
 "supplementary_code": "```cpp\n// A language detection model that will use a TFLite model to determine the\n// language of a string.\n// Each instance of this should only be used from a single thread.\nclass COMPONENT_EXPORT(LANGUAGE_DETECTION) LanguageDetectionModel {\npublic:\nusing ModelLoadedCallback = base::OnceCallback<void(LanguageDetectionModel&)>;\nLanguageDetectionModel();\n~LanguageDetectionModel();\n// Runs the TFLIte language detection model on the string. This will only look\n// at the first 128 unicode characters of the string. Return a vector of\n// scored language predictions. If `truncate` is `true`, this will truncate\n// the string before passing to the TFLite model. Even though the model only\n// considers a prefix of the input, the runtime is proportional to the total\n// length of the input.\nstd::vector<Prediction> Predict(std::u16string_view contents) const;\n// Runs the TFLIte language detection model on the whole string. This will\n// scan over the content with the 128 character window.\n// Return a vector of scored language predictions. The predictions are the\n// mean value of the predictions on each window.\nstd::vector<Prediction> PredictWithScan(std::u16string_view contents) const;\n// Runs the TFLIte language detection model on no more than three samples of\n// the string. If the contents is less than 768 characters, the function will\n// decide the language by running the model over the first 128 characters.\n// Otherwise, the first, last and the middle 256-character text piece will be\n// sampled and the return value will be the prediction with the highest\n// confidence for the three samples.\nPrediction PredictTopLanguageWithSamples(std::u16string_view contents) const;\n// Updates the language detection model for use by memory-mapping\n// |model_file| used to detect the language of the page.\n//\n// This method is blocking and should only be called in context\n// where it is fine to block the current thread. If you cannot\n// block, use UpdateWithFileAsync(...) instead.\nvoid UpdateWithFile(base::File model_file);\n// Updates the language detection model for use by memory-mapping\n// |model_file| used to detect the language of the page. Performs\n// the operation on a background sequence and call |callback| on\n// completion\nvoid UpdateWithFileAsync(base::File model_file, base::OnceClosure callback);\n// Returns whether |this| is initialized and is available to handle requests\n// to determine the language of the page.\nbool IsAvailable() const;\n// Returns the size of the loaded model in bytes. If the model is not yet\n// available, the method will return 0.\nint64_t GetModelSize() const;\nvoid AddOnModelLoadedCallback(ModelLoadedCallback callback);\nstd::string GetModelVersion() const;\n// Detach the instance from the bound sequence. Must only be used if the\n// object is created on a sequence and then moved on another sequence to\n// live.\nvoid DetachFromSequence() { DETACH_FROM_SEQUENCE(sequence_checker_); }\n// The number of characters to sample and provide as a buffer to the model\n// in PredictTopLanguageWithSamples.\nstatic constexpr size_t kTextSampleLength = 256;\n// The number of samples of |kTextSampleLength| to evaluate the model\n// in PredictTopLanguageWithSamples.\nstatic constexpr int kNumTextSamples = 3;\n// The maximum window size the model runs over when predicting the language.\nstatic constexpr size_t kScanWindowSize = 128;\nprivate:\n// An owned NLClassifier.\nusing OwnedNLClassifier =\nstd::unique_ptr<tflite::task::text::nlclassifier::NLClassifier>;\nusing ModelAndSize = std::pair<OwnedNLClassifier, int64_t>;\n// Loads model from |model_file| using |num_threads|. This can be called on\n// any thread.\nstatic std::optional<LanguageDetectionModel::ModelAndSize> LoadModelFromFile(\nbase::File model_file,\nint num_threads);\nvoid NotifyModelLoaded();\n// Execute the model on the provided |sampled_str| and return the top\n// language and the models score/confidence in that prediction.\nPrediction DetectTopLanguage(std::u16string_view sampled_str) const;\n// Updates the model if the not unset.\nvoid SetModel(std::optional<ModelAndSize> model_and_size);\nSEQUENCE_CHECKER(sequence_checker_);\n// The tflite classifier that can determine the language of text.\nOwnedNLClassifier lang_detection_model_;\n// The number of threads to use for model inference. -1 tells TFLite to use\n// its internal default logic.\nconst int num_threads_ = -1;\nstatic constexpr int kMaxPendingCallbacksCount = 100;\n// Pending callbacks for waiting the model to be available.\nstd::vector<ModelLoadedCallback> model_loaded_callbacks_;\n// Records whether a file has been updated to the model.\nbool loaded_ = false;\n// Records the size of the model file loaded. The value is only valid when\n// loaded_ is True.\nint64_t model_file_size_ = 0;\n// Used to load the data on a background sequence (see UpdateWithFileAsync).\nbase::WeakPtrFactory<LanguageDetectionModel> weak_factory_{this};\n};\n```\n```cpp\n// static\nconst scoped_refptr<SequencedTaskRunner>&\nSequencedTaskRunner::GetCurrentDefault() {\nCHECK(HasCurrentDefault())\n<< \"Error: This caller requires a sequenced context (i.e. the current \"\n\"task needs to run from a SequencedTaskRunner). If you're in a test \"\n\"refer to //docs/threading_and_tasks_testing.md.\";\nreturn current_default_handle->task_runner_;\n}\n```\n```cpp\n// A SequencedTaskRunner is a subclass of TaskRunner that provides\n// additional guarantees on the order that tasks are started, as well\n// as guarantees on when tasks are in sequence, i.e. one task finishes\n// before the other one starts.\n//\n// Summary\n// -------\n// Non-nested tasks with the same delay will run one by one in FIFO\n// order.\n//\n// Detailed guarantees\n// -------------------\n//\n// SequencedTaskRunner also adds additional methods for posting\n// non-nestable tasks. In general, an implementation of TaskRunner\n// may expose task-running methods which are themselves callable from\n// within tasks. A non-nestable task is one that is guaranteed to not\n// be run from within an already-running task. Conversely, a nestable\n// task (the default) is a task that can be run from within an\n// already-running task.\n//\n// The guarantees of SequencedTaskRunner are as follows:\n//\n// - Given two tasks T2 and T1, T2 will start after T1 starts if:\n//\n// * T2 is posted after T1; and\n// * T2 has equal or higher delay than T1; and\n// * T2 is non-nestable or T1 is nestable.\n//\n// - If T2 will start after T1 starts by the above guarantee, then\n// T2 will start after T1 finishes and is destroyed if:\n//\n// * T2 is non-nestable, or\n// * T1 doesn't call any task-running methods.\n//\n// - If T2 will start after T1 finishes by the above guarantee, then\n// all memory changes in T1 and T1's destruction will be visible\n// to T2.\n//\n// - If T2 runs nested within T1 via a call to the task-running\n// method M, then all memory changes in T1 up to the call to M\n// will be visible to T2, and all memory changes in T2 will be\n// visible to T1 from the return from M.\n//\n// Note that SequencedTaskRunner does not guarantee that tasks are run\n// on a single dedicated thread, although the above guarantees provide\n// most (but not all) of the same guarantees. If you do need to\n// guarantee that tasks are run on a single dedicated thread, see\n// SingleThreadTaskRunner (in single_thread_task_runner.h).\n//\n// Some corollaries to the above guarantees, assuming the tasks in\n// question don't call any task-running methods:\n//\n// - Tasks posted via PostTask are run in FIFO order.\n//\n// - Tasks posted via PostNonNestableTask are run in FIFO order.\n//\n// - Tasks posted with the same delay and the same nestable state\n// are run in FIFO order.\n//\n// - A list of tasks with the same nestable state posted in order of\n// non-decreasing delay is run in FIFO order.\n//\n// - A list of tasks posted in order of non-decreasing delay with at\n// most a single change in nestable state from nestable to\n// non-nestable is run in FIFO order. (This is equivalent to the\n// statement of the first guarantee above.)\n//\n// Some theoretical implementations of SequencedTaskRunner:\n//\n// - A SequencedTaskRunner that wraps a regular TaskRunner but makes\n// sure that only one task at a time is posted to the TaskRunner,\n// with appropriate memory barriers in between tasks.\n//\n// - A SequencedTaskRunner that, for each task, spawns a joinable\n// thread to run that task and immediately quit, and then\n// immediately joins that thread.\n//\n// - A SequencedTaskRunner that stores the list of posted tasks and\n// has a method Run() that runs each runnable task in FIFO order\n// that can be called from any thread, but only if another\n// (non-nested) Run() call isn't already happening.\n//\n// SequencedTaskRunner::GetCurrentDefault() can be used while running\n// a task to retrieve the default SequencedTaskRunner for the current\n// sequence.\nclass BASE_EXPORT SequencedTaskRunner : public TaskRunner {\npublic:\n// The two PostNonNestable*Task methods below are like their\n// nestable equivalents in TaskRunner, but they guarantee that the\n// posted task will not run nested within an already-running task.\n//\n// A simple corollary is that posting a task as non-nestable can\n// only delay when the task gets run. That is, posting a task as\n// non-nestable may not affect when the task gets run, or it could\n// make it run later than it normally would, but it won't make it\n// run earlier than it normally would.\n// TODO(akalin): Get rid of the boolean return value for the methods\n// below.\nbool PostNonNestableTask(const Location& from_here, OnceClosure task);\nvirtual bool PostNonNestableDelayedTask(const Location& from_here,\nOnceClosure task,\nbase::TimeDelta delay) = 0;\n// Posts the given |task| to be run only after |delay| has passed. Returns a\n// handle that can be used to cancel the task. This should not be used\n// directly. Consider using higher level timer primitives in\n// base/timer/timer.h.\n//\n// The handle is only guaranteed valid while the task is pending execution.\n// This means that it may be invalid if the posting failed, and will be\n// invalid while the task is executing. Calling CancelTask() on an invalid\n// handle is a no-op.\n//\n// This method and the handle it returns are not thread-safe and can only be\n// used from the sequence this task runner runs its tasks on.\nvirtual DelayedTaskHandle PostCancelableDelayedTask(\nsubtle::PostDelayedTaskPassKey,\nconst Location& from_here,\nOnceClosure task,\nTimeDelta delay);\n// Posts the given |task| to be run at |delayed_run_time| (or immediately if\n// in the past), following |delay_policy|. Returns a handle that can be used\n// to cancel the task. This should not be used directly. Consider using higher\n// level timer primitives in base/timer/timer.h.\n[[nodiscard]] virtual DelayedTaskHandle PostCancelableDelayedTaskAt(\nsubtle::PostDelayedTaskPassKey,\nconst Location& from_here,\nOnceClosure task,\nTimeTicks delayed_run_time,\nsubtle::DelayPolicy delay_policy);\n// Posts the given |task| to be run at |delayed_run_time| (or immediately if\n// in the past), following |delay_policy|. This is used by the default\n// implementation of PostCancelableDelayedTaskAt(). The default behavior\n// subtracts TimeTicks::Now() from |delayed_run_time| to get a delay. See\n// base::Timer to post precise/repeating timeouts.\n// TODO(crbug.com/40158967): Make pure virtual once all SequencedTaskRunners\n// implement this.\nvirtual bool PostDelayedTaskAt(subtle::PostDelayedTaskPassKey,\nconst Location& from_here,\nOnceClosure task,\nTimeTicks delayed_run_time,\nsubtle::DelayPolicy delay_policy);\n// May run `task` synchronously if no work that has ordering or mutual\n// exclusion expectations with tasks from this `SequencedTaskRunner` is\n// pending or running (if such work arrives after `task` starts running\n// synchronously, it waits until `task` finishes). Otherwise, behaves like\n// `PostTask`. Since `task` may run synchronously, it is generally not\n// appropriate to invoke this if `task` may take a long time to run.\n//\n// TODO(crbug.com/40944462): This API is still in development. It doesn't yet\n// support SequenceLocalStorage.\nvirtual bool RunOrPostTask(subtle::RunOrPostTaskPassKey,\nconst Location& from_here,\nOnceClosure task);\n// Submits a non-nestable task to delete the given object. Returns\n// true if the object may be deleted at some point in the future,\n// and false if the object definitely will not be deleted.\n//\n// By default, this leaks `object` if the deleter task doesn't run, e.g. if\n// the underlying task queue is shut down first. Subclasses can override this\n// behavior by specializing `DeleteOrReleaseSoonInternal()`.\ntemplate <class T>\nbool DeleteSoon(const Location& from_here, const T* object) {\nreturn DeleteOrReleaseSoonInternal(from_here, &DeleteHelper<T>::DoDelete,\nobject);\n}\ntemplate <class T>\nbool DeleteSoon(const Location& from_here, std::unique_ptr<T> object) {\nreturn DeleteOrReleaseSoonInternal(\nfrom_here, &DeleteUniquePtrHelper<T>::DoDelete, object.release());\n}\n// Submits a non-nestable task to release the given object.\n//\n// By default, this leaks `object` if the releaser task doesn't run, e.g. if\n// the underlying task queue is shut down first. Subclasses can override this\n// behavior by specializing `DeleteOrReleaseSoonInternal()`.\n//\n// ReleaseSoon makes sure that the object it the scoped_refptr points to gets\n// properly released on the correct thread.\n// We apply ReleaseSoon to the rvalue as the side-effects can be unclear to\n// the caller if an lvalue is used. That being so, the scoped_refptr should\n// always be std::move'd.\n// Example use:\n//\n// scoped_refptr<T> foo_scoped_refptr;\n// ...\n// task_runner->ReleaseSoon(std::move(foo_scoped_refptr));\ntemplate <class T>\nvoid ReleaseSoon(const Location& from_here, scoped_refptr<T>&& object) {\nif (!object) {\nreturn;\n}\nDeleteOrReleaseSoonInternal(from_here, &ReleaseHelper<T>::DoRelease,\nobject.release());\n}\n// Returns true iff tasks posted to this TaskRunner are sequenced\n// with this call.\n//\n// In particular:\n// - Returns true if this is a SequencedTaskRunner to which the\n// current task was posted.\n// - Returns true if this is a SequencedTaskRunner bound to the\n// same sequence as the SequencedTaskRunner to which the current\n// task was posted.\n// - Returns true if this is a SingleThreadTaskRunner bound to\n// the current thread.\nvirtual bool RunsTasksInCurrentSequence() const = 0;\n// Returns the default SequencedTaskRunner for the current task. It\n// should only be called if HasCurrentDefault() returns true (see the comment\n// there for the requirements).\n//\n// It is \"default\" in the sense that if the current sequence multiplexes\n// multiple task queues (e.g. BrowserThread::UI), this will return the default\n// task queue. A caller that wants a specific task queue should obtain it\n// directly instead of going through this API.\n//\n// See\n// https://chromium.googlesource.com/chromium/src/+/main/docs/threading_and_tasks.md#Posting-to-the-Current-Virtual_Thread\n// for details\n[[nodiscard]] static const scoped_refptr<SequencedTaskRunner>&\nGetCurrentDefault();\n// Returns true if one of the following conditions is fulfilled:\n// a) A SequencedTaskRunner has been assigned to the current thread by\n// instantiating a SequencedTaskRunner::CurrentDefaultHandle.\n// b) The current thread has a SingleThreadTaskRunner::CurrentDefaultHandle\n// (which includes any thread that runs a MessagePump).\n[[nodiscard]] static bool HasCurrentDefault();\nclass BASE_EXPORT CurrentDefaultHandle {\npublic:\n// Sets the value returned by `SequencedTaskRunner::GetCurrentDefault()` to\n// `task_runner` within its scope. `task_runner` must belong to the current\n// sequence. There must not already be a current default\n// `SequencedTaskRunner` on this thread.\nexplicit CurrentDefaultHandle(\nscoped_refptr<SequencedTaskRunner> task_runner);\nCurrentDefaultHandle(const CurrentDefaultHandle&) = delete;\nCurrentDefaultHandle& operator=(const CurrentDefaultHandle&) = delete;\n~CurrentDefaultHandle();\nprivate:\nfriend class SequencedTaskRunner;\n// Overriding an existing current default SingleThreadTaskRunner should only\n// be needed under special circumstances. Require them to be enumerated as\n// friends to require //base/OWNERS review. Use\n// SingleThreadTaskRunner::CurrentHandleOverrideForTesting in unit tests to\n// avoid the friend requirement.\nfriend class SingleThreadTaskRunner;\nFRIEND_TEST_ALL_PREFIXES(SequencedTaskRunnerCurrentDefaultHandleTest,\nOverrideWithNull);\nFRIEND_TEST_ALL_PREFIXES(SequencedTaskRunnerCurrentDefaultHandleTest,\nOverrideWithNonNull);\nstruct MayAlreadyExist {};\n// Same as the public constructor, but there may already be a current\n// default `SequencedTaskRunner` on this thread.\nCurrentDefaultHandle(scoped_refptr<SequencedTaskRunner> task_runner,\nMayAlreadyExist);\nscoped_refptr<SequencedTaskRunner> task_runner_;\n// RAW_PTR_EXCLUSION: Performance reasons (based on analysis of\n// speedometer3).\nRAW_PTR_EXCLUSION CurrentDefaultHandle* previous_handle_ = nullptr;\n};\nprotected:\n~SequencedTaskRunner() override = default;\nvirtual bool DeleteOrReleaseSoonInternal(const Location& from_here,\nvoid (*deleter)(const void*),\nconst void* object);\n};\n```\n```cpp\nbool TaskRunner::PostTask(const Location& from_here, OnceClosure task) {\nreturn PostDelayedTask(from_here, std::move(task), base::TimeDelta());\n}\n```\n```cpp\n// A TaskRunner is an object that runs posted tasks (in the form of\n// OnceClosure objects). The TaskRunner interface provides a way of\n// decoupling task posting from the mechanics of how each task will be\n// run. TaskRunner provides very weak guarantees as to how posted\n// tasks are run (or if they're run at all). In particular, it only\n// guarantees:\n//\n// - Posting a task will not run it synchronously. That is, no\n// Post*Task method will call task.Run() directly.\n//\n// - Increasing the delay can only delay when the task gets run.\n// That is, increasing the delay may not affect when the task gets\n// run, or it could make it run later than it normally would, but\n// it won't make it run earlier than it normally would.\n//\n// TaskRunner does not guarantee the order in which posted tasks are\n// run, whether tasks overlap, or whether they're run on a particular\n// thread. Also it does not guarantee a memory model for shared data\n// between tasks. (In other words, you should use your own\n// synchronization/locking primitives if you need to share data\n// between tasks.)\n//\n// Implementations of TaskRunner should be thread-safe in that all\n// methods must be safe to call on any thread. Ownership semantics\n// for TaskRunners are in general not clear, which is why the\n// interface itself is RefCountedThreadSafe.\n//\n// Some theoretical implementations of TaskRunner:\n//\n// - A TaskRunner that uses a thread pool to run posted tasks.\n//\n// - A TaskRunner that, for each task, spawns a non-joinable thread\n// to run that task and immediately quit.\n//\n// - A TaskRunner that stores the list of posted tasks and has a\n// method Run() that runs each runnable task in random order.\nclass BASE_EXPORT TaskRunner\n: public RefCountedThreadSafe<TaskRunner, TaskRunnerTraits> {\npublic:\n// Posts the given task to be run. Returns true if the task may be\n// run at some point in the future, and false if the task definitely\n// will not be run.\n//\n// Equivalent to PostDelayedTask(from_here, task, 0).\nbool PostTask(const Location& from_here, OnceClosure task);\n// Like PostTask, but tries to run the posted task only after |delay_ms|\n// has passed. Implementations should use a tick clock, rather than wall-\n// clock time, to implement |delay|.\nvirtual bool PostDelayedTask(const Location& from_here,\nOnceClosure task,\nbase::TimeDelta delay) = 0;\n// Posts |task| on the current TaskRunner. On completion, |reply| is posted\n// to the sequence that called PostTaskAndReply(). On the success case,\n// |task| is destroyed on the target sequence and |reply| is destroyed on the\n// originating sequence immediately after their invocation. If an error\n// happened on the onward PostTask, both |task| and |reply| are destroyed on\n// the originating sequence, and on an error on the backward PostTask, |reply|\n// is leaked rather than being destroyed on the wrong sequence. This allows\n// objects that must be deleted on the originating sequence to be bound into\n// the |reply| Closures. In particular, it can be useful to use WeakPtr<> in\n// the |reply| Closure so that the reply operation can be canceled. See the\n// following pseudo-code:\n//\n// class DataBuffer : public RefCountedThreadSafe<DataBuffer> {\n// public:\n// // Called to add data into a buffer.\n// void AddData(void* buf, size_t length);\n// ...\n// };\n//\n//\n// class DataLoader {\n// public:\n// void GetData() {\n// scoped_refptr<DataBuffer> buffer = new DataBuffer();\n// target_thread_.task_runner()->PostTaskAndReply(\n// FROM_HERE,\n// base::BindOnce(&DataBuffer::AddData, buffer),\n// base::BindOnce(&DataLoader::OnDataReceived,\n// weak_ptr_factory_.GetWeakPtr(), buffer));\n// }\n//\n// private:\n// void OnDataReceived(scoped_refptr<DataBuffer> buffer) {\n// // Do something with buffer.\n// }\n// base::WeakPtrFactory<DataLoader> weak_ptr_factory_{this};\n// };\n//\n//\n// Things to notice:\n// * Results of |task| are shared with |reply| by binding a shared argument\n// (a DataBuffer instance).\n// * The DataLoader object has no special thread safety.\n// * The DataLoader object can be deleted while |task| is still running,\n// and the reply will cancel itself safely because it is bound to a\n// WeakPtr<>.\nbool PostTaskAndReply(const Location& from_here,\nOnceClosure task,\nOnceClosure reply);\n// When you have these methods\n//\n// R DoWorkAndReturn();\n// void Callback(const R& result);\n//\n// and want to call them in a PostTaskAndReply kind of fashion where the\n// result of DoWorkAndReturn is passed to the Callback, you can use\n// PostTaskAndReplyWithResult as in this example:\n//\n// PostTaskAndReplyWithResult(\n// target_thread_.task_runner(),\n// FROM_HERE,\n// BindOnce(&DoWorkAndReturn),\n// BindOnce(&Callback));\n//\n// Templating on the types of `task` and `reply` allows template matching to\n// work for both base::RepeatingCallback and base::OnceCallback in each case.\ntemplate <typename TaskReturnType,\ntypename ReplyArgType,\ntemplate <typename>\nclass TaskCallbackType,\ntemplate <typename>\nclass ReplyCallbackType>\nrequires(IsBaseCallback<TaskCallbackType<void()>> &&\nIsBaseCallback<ReplyCallbackType<void()>>)\nbool PostTaskAndReplyWithResult(const Location& from_here,\nTaskCallbackType<TaskReturnType()> task,\nReplyCallbackType<void(ReplyArgType)> reply) {\nDCHECK(task);\nDCHECK(reply);\n// std::unique_ptr used to avoid the need of a default constructor.\nauto* result = new std::unique_ptr<TaskReturnType>();\nreturn PostTaskAndReply(\nfrom_here,\nBindOnce(&internal::ReturnAsParamAdapter<TaskReturnType>,\nstd::move(task), result),\nBindOnce(&internal::ReplyAdapter<TaskReturnType, ReplyArgType>,\nstd::move(reply), Owned(result)));\n}\nprotected:\nfriend struct TaskRunnerTraits;\nTaskRunner();\nvirtual ~TaskRunner();\n// Called when this object should be destroyed. By default simply\n// deletes |this|, but can be overridden to do something else, like\n// delete on a certain thread.\nvirtual void OnDestruct() const;\n};\n```\n```cpp\n// Bind as OnceCallback.\ntemplate <typename Functor, typename... Args>\ninline auto BindOnce(Functor&& functor, Args&&... args) {\nreturn internal::BindHelper<OnceCallback>::Bind(\nstd::forward<Functor>(functor), std::forward<Args>(args)...);\n}\n```\n```cpp\n// A class may be composed of a WeakPtrFactory and thereby\n// control how it exposes weak pointers to itself. This is helpful if you only\n// need weak pointers within the implementation of a class. This class is also\n// useful when working with primitive types. For example, you could have a\n// WeakPtrFactory<bool> that is used to pass around a weak reference to a bool.\ntemplate <class T>\nclass WeakPtrFactory : public internal::WeakPtrFactoryBase {\npublic:\nWeakPtrFactory() = delete;\nexplicit WeakPtrFactory(T* ptr)\n: WeakPtrFactoryBase(reinterpret_cast<uintptr_t>(ptr)) {}\nWeakPtrFactory(const WeakPtrFactory&) = delete;\nWeakPtrFactory& operator=(const WeakPtrFactory&) = delete;\n~WeakPtrFactory() = default;\nWeakPtr<const T> GetWeakPtr() const {\nreturn WeakPtr<const T>(weak_reference_owner_.GetRef(),\nreinterpret_cast<const T*>(ptr_));\n}\nWeakPtr<T> GetWeakPtr()\nrequires(!std::is_const_v<T>)\n{\nreturn WeakPtr<T>(weak_reference_owner_.GetRef(),\nreinterpret_cast<T*>(ptr_));\n}\nWeakPtr<T> GetMutableWeakPtr() const\nrequires(!std::is_const_v<T>)\n{\nreturn WeakPtr<T>(weak_reference_owner_.GetRef(),\nreinterpret_cast<T*>(ptr_));\n}\n// Returns a smart pointer that is valid until the WeakPtrFactory is\n// invalidated. Unlike WeakPtr, this smart pointer cannot be null, and cannot\n// be checked to see if the WeakPtrFactory is invalidated. It's intended to\n// express that the pointer will not (intentionally) outlive the `T` object it\n// points to, and to crash safely in the case of a bug instead of causing a\n// use-after-free. This type provides an alternative to WeakPtr to prevent\n// use-after-free bugs without also introducing \"fuzzy lifetimes\" that can be\n// checked for at runtime.\nSafeRef<T> GetSafeRef() const {\nreturn internal::MakeSafeRefFromWeakPtrInternals(\nweak_reference_owner_.GetRef(), reinterpret_cast<T*>(ptr_));\n}\n// Call this method to invalidate all existing weak pointers.\nvoid InvalidateWeakPtrs() {\nDCHECK(ptr_);\nweak_reference_owner_.Invalidate();\n}\n// Call this method to determine if any weak pointers exist.\nbool HasWeakPtrs() const {\nDCHECK(ptr_);\nreturn weak_reference_owner_.HasRefs();\n}\n// Rebind the factory to the current sequence. This allows creating an object\n// and associated weak pointers on a different thread from the one they are\n// used on.\nvoid BindToCurrentSequence(subtle::BindWeakPtrFactoryPassKey) {\nweak_reference_owner_.BindToCurrentSequence();\n}\n};\n```",
 "function_prototype": "void LanguageDetectionModel::NotifyModelLoaded()",
 "re_implemented_code": "\n```cpp\nvoid LanguageDetectionModel::NotifyModelLoaded() {\n// Ensure that this method is called on the correct sequence\nDCHECK(RunsTasksInCurrentSequence());\n// Iterate over each callback in the list of model loaded callbacks\nfor (auto&& callback_ : model_loaded_callbacks_) {\n// Execute the callback, passing the current instance of the model\nstd::move(callback_).Run(*this);\n}\n// Set the loaded flag to true, indicating the model is now loaded\nloaded_ = true;\n// Clear the list of model loaded callbacks as they have all been executed\nmodel_loaded_callbacks_.clear();\n}\n```\n",
 "is_vulnerable": true
}