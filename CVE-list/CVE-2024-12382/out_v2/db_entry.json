{
  "cwe_type": "Use After Free",
  "cve_id": "CVE-2024-12382",
  "supplementary_code": "```cpp\n// A language detection model that will use a TFLite model to determine the\n// language of a string.\n// Each instance of this should only be used from a single thread.\nclass COMPONENT_EXPORT(LANGUAGE_DETECTION) LanguageDetectionModel {\npublic:\nusing ModelLoadedCallback = base::OnceCallback<void(LanguageDetectionModel&)>;\nLanguageDetectionModel();\n~LanguageDetectionModel();\n// Runs the TFLIte language detection model on the string. This will only look\n// at the first 128 unicode characters of the string. Return a vector of\n// scored language predictions. If `truncate` is `true`, this will truncate\n// the string before passing to the TFLite model. Even though the model only\n// considers a prefix of the input, the runtime is proportional to the total\n// length of the input.\nstd::vector<Prediction> Predict(std::u16string_view contents) const;\n// Runs the TFLIte language detection model on the whole string. This will\n// scan over the content with the 128 character window.\n// Return a vector of scored language predictions. The predictions are the\n// mean value of the predictions on each window.\nstd::vector<Prediction> PredictWithScan(std::u16string_view contents) const;\n// Runs the TFLIte language detection model on no more than three samples of\n// the string. If the contents is less than 768 characters, the function will\n// decide the language by running the model over the first 128 characters.\n// Otherwise, the first, last and the middle 256-character text piece will be\n// sampled and the return value will be the prediction with the highest\n// confidence for the three samples.\nPrediction PredictTopLanguageWithSamples(std::u16string_view contents) const;\n// Updates the language detection model for use by memory-mapping\n// |model_file| used to detect the language of the page.\n//\n// This method is blocking and should only be called in context\n// where it is fine to block the current thread. If you cannot\n// block, use UpdateWithFileAsync(...) instead.\nvoid UpdateWithFile(base::File model_file);\n// Updates the language detection model for use by memory-mapping\n// |model_file| used to detect the language of the page. Performs\n// the operation on a background sequence and call |callback| on\n// completion\nvoid UpdateWithFileAsync(base::File model_file, base::OnceClosure callback);\n// Returns whether |this| is initialized and is available to handle requests\n// to determine the language of the page.\nbool IsAvailable() const;\n// Returns the size of the loaded model in bytes. If the model is not yet\n// available, the method will return 0.\nint64_t GetModelSize() const;\nvoid AddOnModelLoadedCallback(ModelLoadedCallback callback);\nstd::string GetModelVersion() const;\n// Detach the instance from the bound sequence. Must only be used if the\n// object is created on a sequence and then moved on another sequence to\n// live.\nvoid DetachFromSequence() { DETACH_FROM_SEQUENCE(sequence_checker_); }\n// The number of characters to sample and provide as a buffer to the model\n// in PredictTopLanguageWithSamples.\nstatic constexpr size_t kTextSampleLength = 256;\n// The number of samples of |kTextSampleLength| to evaluate the model\n// in PredictTopLanguageWithSamples.\nstatic constexpr int kNumTextSamples = 3;\n// The maximum window size the model runs over when predicting the language.\nstatic constexpr size_t kScanWindowSize = 128;\nprivate:\n// An owned NLClassifier.\nusing OwnedNLClassifier =\nstd::unique_ptr<tflite::task::text::nlclassifier::NLClassifier>;\nusing ModelAndSize = std::pair<OwnedNLClassifier, int64_t>;\n// Loads model from |model_file| using |num_threads|. This can be called on\n// any thread.\nstatic std::optional<LanguageDetectionModel::ModelAndSize> LoadModelFromFile(\nbase::File model_file,\nint num_threads);\nvoid NotifyModelLoaded();\n// Execute the model on the provided |sampled_str| and return the top\n// language and the models score/confidence in that prediction.\nPrediction DetectTopLanguage(std::u16string_view sampled_str) const;\n// Updates the model if the not unset.\nvoid SetModel(std::optional<ModelAndSize> model_and_size);\nSEQUENCE_CHECKER(sequence_checker_);\n// The tflite classifier that can determine the language of text.\nOwnedNLClassifier lang_detection_model_;\n// The number of threads to use for model inference. -1 tells TFLite to use\n// its internal default logic.\nconst int num_threads_ = -1;\nstatic constexpr int kMaxPendingCallbacksCount = 100;\n// Pending callbacks for waiting the model to be available.\nstd::vector<ModelLoadedCallback> model_loaded_callbacks_;\n// Records whether a file has been updated to the model.\nbool loaded_ = false;\n// Records the size of the model file loaded. The value is only valid when\n// loaded_ is True.\nint64_t model_file_size_ = 0;\n// Used to load the data on a background sequence (see UpdateWithFileAsync).\nbase::WeakPtrFactory<LanguageDetectionModel> weak_factory_{this};\n};\n```\n```cpp\n// static\nconst scoped_refptr<SequencedTaskRunner>&\nSequencedTaskRunner::GetCurrentDefault() {\nCHECK(HasCurrentDefault())\n<< \"Error: This caller requires a sequenced context (i.e. the current \"\n\"task needs to run from a SequencedTaskRunner). If you're in a test \"\n\"refer to //docs/threading_and_tasks_testing.md.\";\nreturn current_default_handle->task_runner_;\n}\n```\n```cpp\n// A SequencedTaskRunner is a subclass of TaskRunner that provides\n// additional guarantees on the order that tasks are started, as well\n// as guarantees on when tasks are in sequence, i.e. one task finishes\n// before the other one starts.\n//\n// Summary\n// -------\n// Non-nested tasks with the same delay will run one by one in FIFO\n// order.\n//\n// Detailed guarantees\n// -------------------\n//\n// SequencedTaskRunner also adds additional methods for posting\n// non-nestable tasks. In general, an implementation of TaskRunner\n// may expose task-running methods which are themselves callable from\n// within tasks. A non-nestable task is one that is guaranteed to not\n// be run from within an already-running task. Conversely, a nestable\n// task (the default) is a task that can be run from within an\n// already-running task.\n//\n// The guarantees of SequencedTaskRunner are as follows:\n//\n// - Given two tasks T2 and T1, T2 will start after T1 starts if:\n//\n// * T2 is posted after T1; and\n// * T2 has equal or higher delay than T1; and\n// * T2 is non-nestable or T1 is nestable.\n//\n// - If T2 will start after T1 starts by the above guarantee, then\n// T2 will start after T1 finishes and is destroyed if:\n//\n// * T2 is non-nestable, or\n// * T1 doesn't call any task-running methods.\n//\n// - If T2 will start after T1 finishes by the above guarantee, then\n// all memory changes in T1 and T1's destruction will be visible\n// to T2.\n//\n// - If T2 runs nested within T1 via a call to the task-running\n// method M, then all memory changes in T1 up to the call to M\n// will be visible to T2, and all memory changes in T2 will be\n// visible to T1 from the return from M.\n//\n// Note that SequencedTaskRunner does not guarantee that tasks are run\n// on a single dedicated thread, although the above guarantees provide\n// most (but not all) of the same guarantees. If you do need to\n// guarantee that tasks are run on a single dedicated thread, see\n// SingleThreadTaskRunner (in single_thread_task_runner.h).\n//\n// Some corollaries to the above guarantees, assuming the tasks in\n// question don't call any task-running methods:\n//\n// - Tasks posted via PostTask are run in FIFO order.\n//\n// - Tasks posted via PostNonNestableTask are run in FIFO order.\n//\n// - Tasks posted with the same delay and the same nestable state\n// are run in FIFO order.\n//\n// - A list of tasks with the same nestable state posted in order of\n// non-decreasing delay is run in FIFO order.\n//\n// - A list of tasks posted in order of non-decreasing delay with at\n// most a single change in nestable state from nestable to\n// non-nestable is run in FIFO order. (This is equivalent to the\n// statement of the first guarantee above.)\n//\n// Some theoretical implementations of SequencedTaskRunner:\n//\n// - A SequencedTaskRunner that wraps a regular TaskRunner but makes\n// sure that only one task at a time is posted to the TaskRunner,\n// with appropriate memory barriers in between tasks.\n//\n// - A SequencedTaskRunner that, for each task, spawns a joinable\n// thread to run that task and immediately quit, and then\n// immediately joins that thread.\n//\n// - A SequencedTaskRunner that stores the list of posted tasks and\n// has a method Run() that runs each runnable task in FIFO order\n// that can be called from any thread, but only if another\n// (non-nested) Run() call isn't already happening.\n//\n// SequencedTaskRunner::GetCurrentDefault() can be used while running\n// a task to retrieve the default SequencedTaskRunner for the current\n// sequence.\nclass BASE_EXPORT SequencedTaskRunner : public TaskRunner {\npublic:\n// The two PostNonNestable*Task methods below are like their\n// nestable equivalents in TaskRunner, but they guarantee that the\n// posted task will not run nested within an already-running task.\n//\n// A simple corollary is that posting a task as non-nestable can\n// only delay when the task gets run. That is, posting a task as\n// non-nestable may not affect when the task gets run, or it could\n// make it run later than it normally would, but it won't make it\n// run earlier than it normally would.\n// TODO(akalin): Get rid of the boolean return value for the methods\n// below.\nbool PostNonNestableTask(const Location& from_here, OnceClosure task);\nvirtual bool PostNonNestableDelayedTask(const Location& from_here,\nOnceClosure task,\nbase::TimeDelta delay) = 0;\n// Posts the given |task| to be run only after |delay| has passed. Returns a\n// handle that can be used to cancel the task. This should not be used\n// directly. Consider using higher level timer primitives in\n// base/timer/timer.h.\n//\n// The handle is only guaranteed valid while the task is pending execution.\n// This means that it may be invalid if the posting failed, and will be\n// invalid while the task is executing. Calling CancelTask() on an invalid\n// handle is a no-op.\n//\n// This method and the handle it returns are not thread-safe and can only be\n// used from the sequence this task runner runs its tasks on.\nvirtual DelayedTaskHandle PostCancelableDelayedTask(\nsubtle::PostDelayedTaskPassKey,\nconst Location& from_here,\nOnceClosure task,\nTimeDelta delay);\n// Posts the given |task| to be run at |delayed_run_time| (or immediately if\n// in the past), following |delay_policy|. Returns a handle that can be used\n// to cancel the task. This should not be used directly. Consider using higher\n// level timer primitives in base/timer/timer.h.\n[[nodiscard]] virtual DelayedTaskHandle PostCancelableDelayedTaskAt(\nsubtle::PostDelayedTaskPassKey,\nconst Location& from_here,\nOnceClosure task,\nTimeTicks delayed_run_time,\nsubtle::DelayPolicy delay_policy);\n// Posts the given |task| to be run at |delayed_run_time| (or immediately if\n// in the past), following |delay_policy|. This is used by the default\n// implementation of PostCancelableDelayedTaskAt(). The default behavior\n// subtracts TimeTicks::Now() from |delayed_run_time| to get a delay. See\n// base::Timer to post precise/repeating timeouts.\n// TODO(crbug.com/40158967): Make pure virtual once all SequencedTaskRunners\n// implement this.\nvirtual bool PostDelayedTaskAt(subtle::PostDelayedTaskPassKey,\nconst Location& from_here,\nOnceClosure task,\nTimeTicks delayed_run_time,\nsubtle::DelayPolicy delay_policy);\n// May run `task` synchronously if no work that has ordering or mutual\n// exclusion expectations with tasks from this `SequencedTaskRunner` is\n// pending or running (if such work arrives after `task` starts running\n// synchronously, it waits until `task` finishes). Otherwise, behaves like\n// `PostTask`. Since `task` may run synchronously, it is generally not\n// appropriate to invoke this if `task` may take a long time to run.\n//\n// TODO(crbug.com/40944462): This API is still in development. It doesn't yet\n// support SequenceLocalStorage.\nvirtual bool RunOrPostTask(subtle::RunOrPostTaskPassKey,\nconst Location& from_here,\nOnceClosure task);\n// Submits a non-nestable task to delete the given object. Returns\n// true if the object may be deleted at some point in the future,\n// and false if the object definitely will not be deleted.\n//\n// By default, this leaks `object` if the deleter task doesn't run, e.g. if\n// the underlying task queue is shut down first. Subclasses can override this\n// behavior by specializing `DeleteOrReleaseSoonInternal()`.\ntemplate <class T>\nbool DeleteSoon(const Location& from_here, const T* object) {\nreturn DeleteOrReleaseSoonInternal(from_here, &DeleteHelper<T>::DoDelete,\nobject);\n}\ntemplate <class T>\nbool DeleteSoon(const Location& from_here, std::unique_ptr<T> object) {\nreturn DeleteOrReleaseSoonInternal(\nfrom_here, &DeleteUniquePtrHelper<T>::DoDelete, object.release());\n}\n// Submits a non-nestable task to release the given object.\n//\n// By default, this leaks `object` if the releaser task doesn't run, e.g. if\n// the underlying task queue is shut down first. Subclasses can override this\n// behavior by specializing `DeleteOrReleaseSoonInternal()`.\n//\n// ReleaseSoon makes sure that the object it the scoped_refptr points to gets\n// properly released on the correct thread.\n// We apply ReleaseSoon to the rvalue as the side-effects can be unclear to\n// the caller if an lvalue is used. That being so, the scoped_refptr should\n// always be std::move'd.\n// Example use:\n//\n// scoped_refptr<T> foo_scoped_refptr;\n// ...\n// task_runner->ReleaseSoon(std::move(foo_scoped_refptr));\ntemplate <class T>\nvoid ReleaseSoon(const Location& from_here, scoped_refptr<T>&& object) {\nif (!object) {\nreturn;\n}\nDeleteOrReleaseSoonInternal(from_here, &ReleaseHelper<T>::DoRelease,\nobject.release());\n}\n// Returns true iff tasks posted to this TaskRunner are sequenced\n// with this call.\n//\n// In particular:\n// - Returns true if this is a SequencedTaskRunner to which the\n// current task was posted.\n// - Returns true if this is a SequencedTaskRunner bound to the\n// same sequence as the SequencedTaskRunner to which the current\n// task was posted.\n// - Returns true if this is a SingleThreadTaskRunner bound to\n// the current thread.\nvirtual bool RunsTasksInCurrentSequence() const = 0;\n// Returns the default SequencedTaskRunner for the current task. It\n// should only be called if HasCurrentDefault() returns true (see the comment\n// there for the requirements).\n//\n// It is \"default\" in the sense that if the current sequence multiplexes\n// multiple task queues (e.g. BrowserThread::UI), this will return the default\n// task queue. A caller that wants a specific task queue should obtain it\n// directly instead of going through this API.\n//\n// See\n// https://chromium.googlesource.com/chromium/src/+/main/docs/threading_and_tasks.md#Posting-to-the-Current-Virtual_Thread\n// for details\n[[nodiscard]] static const scoped_refptr<SequencedTaskRunner>&\nGetCurrentDefault();\n// Returns true if one of the following conditions is fulfilled:\n// a) A SequencedTaskRunner has been assigned to the current thread by\n// instantiating a SequencedTaskRunner::CurrentDefaultHandle.\n// b) The current thread has a SingleThreadTaskRunner::CurrentDefaultHandle\n// (which includes any thread that runs a MessagePump).\n[[nodiscard]] static bool HasCurrentDefault();\nclass BASE_EXPORT CurrentDefaultHandle {\npublic:\n// Sets the value returned by `SequencedTaskRunner::GetCurrentDefault()` to\n// `task_runner` within its scope. `task_runner` must belong to the current\n// sequence. There must not already be a current default\n// `SequencedTaskRunner` on this thread.\nexplicit CurrentDefaultHandle(\nscoped_refptr<SequencedTaskRunner> task_runner);\nCurrentDefaultHandle(const CurrentDefaultHandle&) = delete;\nCurrentDefaultHandle& operator=(const CurrentDefaultHandle&) = delete;\n~CurrentDefaultHandle();\nprivate:\nfriend class SequencedTaskRunner;\n// Overriding an existing current default SingleThreadTaskRunner should only\n// be needed under special circumstances. Require them to be enumerated as\n// friends to require //base/OWNERS review. Use\n// SingleThreadTaskRunner::CurrentHandleOverrideForTesting in unit tests to\n// avoid the friend requirement.\nfriend class SingleThreadTaskRunner;\nFRIEND_TEST_ALL_PREFIXES(SequencedTaskRunnerCurrentDefaultHandleTest,\nOverrideWithNull);\nFRIEND_TEST_ALL_PREFIXES(SequencedTaskRunnerCurrentDefaultHandleTest,\nOverrideWithNonNull);\nstruct MayAlreadyExist {};\n// Same as the public constructor, but there may already be a current\n// default `SequencedTaskRunner` on this thread.\nCurrentDefaultHandle(scoped_refptr<SequencedTaskRunner> task_runner,\nMayAlreadyExist);\nscoped_refptr<SequencedTaskRunner> task_runner_;\n// RAW_PTR_EXCLUSION: Performance reasons (based on analysis of\n// speedometer3).\nRAW_PTR_EXCLUSION CurrentDefaultHandle* previous_handle_ = nullptr;\n};\nprotected:\n~SequencedTaskRunner() override = default;\nvirtual bool DeleteOrReleaseSoonInternal(const Location& from_here,\nvoid (*deleter)(const void*),\nconst void* object);\n};\n```\n```cpp\nbool TaskRunner::PostTask(const Location& from_here, OnceClosure task) {\nreturn PostDelayedTask(from_here, std::move(task), base::TimeDelta());\n}\n```\n```cpp\n// A TaskRunner is an object that runs posted tasks (in the form of\n// OnceClosure objects). The TaskRunner interface provides a way of\n// decoupling task posting from the mechanics of how each task will be\n// run. TaskRunner provides very weak guarantees as to how posted\n// tasks are run (or if they're run at all). In particular, it only\n// guarantees:\n//\n// - Posting a task will not run it synchronously. That is, no\n// Post*Task method will call task.Run() directly.\n//\n// - Increasing the delay can only delay when the task gets run.\n// That is, increasing the delay may not affect when the task gets\n// run, or it could make it run later than it normally would, but\n// it won't make it run earlier than it normally would.\n//\n// TaskRunner does not guarantee the order in which posted tasks are\n// run, whether tasks overlap, or whether they're run on a particular\n// thread. Also it does not guarantee a memory model for shared data\n// between tasks. (In other words, you should use your own\n// synchronization/locking primitives if you need to share data\n// between tasks.)\n//\n// Implementations of TaskRunner should be thread-safe in that all\n// methods must be safe to call on any thread. Ownership semantics\n// for TaskRunners are in general not clear, which is why the\n// interface itself is RefCountedThreadSafe.\n//\n// Some theoretical implementations of TaskRunner:\n//\n// - A TaskRunner that uses a thread pool to run posted tasks.\n//\n// - A TaskRunner that, for each task, spawns a non-joinable thread\n// to run that task and immediately quit.\n//\n// - A TaskRunner that stores the list of posted tasks and has a\n// method Run() that runs each runnable task in random order.\nclass BASE_EXPORT TaskRunner\n: public RefCountedThreadSafe<TaskRunner, TaskRunnerTraits> {\npublic:\n// Posts the given task to be run. Returns true if the task may be\n// run at some point in the future, and false if the task definitely\n// will not be run.\n//\n// Equivalent to PostDelayedTask(from_here, task, 0).\nbool PostTask(const Location& from_here, OnceClosure task);\n// Like PostTask, but tries to run the posted task only after |delay_ms|\n// has passed. Implementations should use a tick clock, rather than wall-\n// clock time, to implement |delay|.\nvirtual bool PostDelayedTask(const Location& from_here,\nOnceClosure task,\nbase::TimeDelta delay) = 0;\n// Posts |task| on the current TaskRunner. On completion, |reply| is posted\n// to the sequence that called PostTaskAndReply(). On the success case,\n// |task| is destroyed on the target sequence and |reply| is destroyed on the\n// originating sequence immediately after their invocation. If an error\n// happened on the onward PostTask, both |task| and |reply| are destroyed on\n// the originating sequence, and on an error on the backward PostTask, |reply|\n// is leaked rather than being destroyed on the wrong sequence. This allows\n// objects that must be deleted on the originating sequence to be bound into\n// the |reply| Closures. In particular, it can be useful to use WeakPtr<> in\n// the |reply| Closure so that the reply operation can be canceled. See the\n// following pseudo-code:\n//\n// class DataBuffer : public RefCountedThreadSafe<DataBuffer> {\n// public:\n// // Called to add data into a buffer.\n// void AddData(void* buf, size_t length);\n// ...\n// };\n//\n//\n// class DataLoader {\n// public:\n// void GetData() {\n// scoped_refptr<DataBuffer> buffer = new DataBuffer();\n// target_thread_.task_runner()->PostTaskAndReply(\n// FROM_HERE,\n// base::BindOnce(&DataBuffer::AddData, buffer),\n// base::BindOnce(&DataLoader::OnDataReceived,\n// weak_ptr_factory_.GetWeakPtr(), buffer));\n// }\n//\n// private:\n// void OnDataReceived(scoped_refptr<DataBuffer> buffer) {\n// // Do something with buffer.\n// }\n// base::WeakPtrFactory<DataLoader> weak_ptr_factory_{this};\n// };\n//\n//\n// Things to notice:\n// * Results of |task| are shared with |reply| by binding a shared argument\n// (a DataBuffer instance).\n// * The DataLoader object has no special thread safety.\n// * The DataLoader object can be deleted while |task| is still running,\n// and the reply will cancel itself safely because it is bound to a\n// WeakPtr<>.\nbool PostTaskAndReply(const Location& from_here,\nOnceClosure task,\nOnceClosure reply);\n// When you have these methods\n//\n// R DoWorkAndReturn();\n// void Callback(const R& result);\n//\n// and want to call them in a PostTaskAndReply kind of fashion where the\n// result of DoWorkAndReturn is passed to the Callback, you can use\n// PostTaskAndReplyWithResult as in this example:\n//\n// PostTaskAndReplyWithResult(\n// target_thread_.task_runner(),\n// FROM_HERE,\n// BindOnce(&DoWorkAndReturn),\n// BindOnce(&Callback));\n//\n// Templating on the types of `task` and `reply` allows template matching to\n// work for both base::RepeatingCallback and base::OnceCallback in each case.\ntemplate <typename TaskReturnType,\ntypename ReplyArgType,\ntemplate <typename>\nclass TaskCallbackType,\ntemplate <typename>\nclass ReplyCallbackType>\nrequires(IsBaseCallback<TaskCallbackType<void()>> &&\nIsBaseCallback<ReplyCallbackType<void()>>)\nbool PostTaskAndReplyWithResult(const Location& from_here,\nTaskCallbackType<TaskReturnType()> task,\nReplyCallbackType<void(ReplyArgType)> reply) {\nDCHECK(task);\nDCHECK(reply);\n// std::unique_ptr used to avoid the need of a default constructor.\nauto* result = new std::unique_ptr<TaskReturnType>();\nreturn PostTaskAndReply(\nfrom_here,\nBindOnce(&internal::ReturnAsParamAdapter<TaskReturnType>,\nstd::move(task), result),\nBindOnce(&internal::ReplyAdapter<TaskReturnType, ReplyArgType>,\nstd::move(reply), Owned(result)));\n}\nprotected:\nfriend struct TaskRunnerTraits;\nTaskRunner();\nvirtual ~TaskRunner();\n// Called when this object should be destroyed. By default simply\n// deletes |this|, but can be overridden to do something else, like\n// delete on a certain thread.\nvirtual void OnDestruct() const;\n};\n```\n```cpp\n// Bind as OnceCallback.\ntemplate <typename Functor, typename... Args>\ninline auto BindOnce(Functor&& functor, Args&&... args) {\nreturn internal::BindHelper<OnceCallback>::Bind(\nstd::forward<Functor>(functor), std::forward<Args>(args)...);\n}\n```\n```cpp\n// A class may be composed of a WeakPtrFactory and thereby\n// control how it exposes weak pointers to itself. This is helpful if you only\n// need weak pointers within the implementation of a class. This class is also\n// useful when working with primitive types. For example, you could have a\n// WeakPtrFactory<bool> that is used to pass around a weak reference to a bool.\ntemplate <class T>\nclass WeakPtrFactory : public internal::WeakPtrFactoryBase {\npublic:\nWeakPtrFactory() = delete;\nexplicit WeakPtrFactory(T* ptr)\n: WeakPtrFactoryBase(reinterpret_cast<uintptr_t>(ptr)) {}\nWeakPtrFactory(const WeakPtrFactory&) = delete;\nWeakPtrFactory& operator=(const WeakPtrFactory&) = delete;\n~WeakPtrFactory() = default;\nWeakPtr<const T> GetWeakPtr() const {\nreturn WeakPtr<const T>(weak_reference_owner_.GetRef(),\nreinterpret_cast<const T*>(ptr_));\n}\nWeakPtr<T> GetWeakPtr()\nrequires(!std::is_const_v<T>)\n{\nreturn WeakPtr<T>(weak_reference_owner_.GetRef(),\nreinterpret_cast<T*>(ptr_));\n}\nWeakPtr<T> GetMutableWeakPtr() const\nrequires(!std::is_const_v<T>)\n{\nreturn WeakPtr<T>(weak_reference_owner_.GetRef(),\nreinterpret_cast<T*>(ptr_));\n}\n// Returns a smart pointer that is valid until the WeakPtrFactory is\n// invalidated. Unlike WeakPtr, this smart pointer cannot be null, and cannot\n// be checked to see if the WeakPtrFactory is invalidated. It's intended to\n// express that the pointer will not (intentionally) outlive the `T` object it\n// points to, and to crash safely in the case of a bug instead of causing a\n// use-after-free. This type provides an alternative to WeakPtr to prevent\n// use-after-free bugs without also introducing \"fuzzy lifetimes\" that can be\n// checked for at runtime.\nSafeRef<T> GetSafeRef() const {\nreturn internal::MakeSafeRefFromWeakPtrInternals(\nweak_reference_owner_.GetRef(), reinterpret_cast<T*>(ptr_));\n}\n// Call this method to invalidate all existing weak pointers.\nvoid InvalidateWeakPtrs() {\nDCHECK(ptr_);\nweak_reference_owner_.Invalidate();\n}\n// Call this method to determine if any weak pointers exist.\nbool HasWeakPtrs() const {\nDCHECK(ptr_);\nreturn weak_reference_owner_.HasRefs();\n}\n// Rebind the factory to the current sequence. This allows creating an object\n// and associated weak pointers on a different thread from the one they are\n// used on.\nvoid BindToCurrentSequence(subtle::BindWeakPtrFactoryPassKey) {\nweak_reference_owner_.BindToCurrentSequence();\n}\n};\n```",
  "original_code": "```cpp\nvoid LanguageDetectionModel::NotifyModelLoaded() {\nDCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);\nfor (auto&& callback_ : model_loaded_callbacks_) {\nstd::move(callback_).Run(*this);\n}\nloaded_ = true;\nmodel_loaded_callbacks_.clear();\n}\n```",
  "vuln_patch": "```cpp\nvoid LanguageDetectionModel::NotifyModelLoaded() {\nDCHECK_CALLED_ON_VALID_SEQUENCE(sequence_checker_);\nstd::vector<ModelLoadedCallback> model_loaded_callbacks;\n// Since the callbacks could result in modification of\n// `model_loaded_callbacks_`, it's not safe to iterate over the member.\n// TODO(https://crbug.com/381461495): Post a task for each callback.\nmodel_loaded_callbacks.swap(model_loaded_callbacks_);\nfor (auto&& callback : model_loaded_callbacks) {\nstd::move(callback).Run(*this);\n}\nloaded_ = true;\n}\n```",
  "function_name": "LanguageDetectionModel::NotifyModelLoaded",
  "function_prototype": "void LanguageDetectionModel::NotifyModelLoaded()",
  "code_semantics": "The method ensures it is called in the correct context, then iterates over a list of callback functions, executing each one with the current instance as an argument. After executing the callbacks, it marks the model as loaded and clears the list of callbacks.",
  "safe_verification_cot": "1. In the patched code, model_loaded_callbacks_ is swapped with a local vector, ensuring safe iteration. 2. The patched code swaps model_loaded_callbacks_ with a local vector, preventing modifications during iteration. 3. The flag loaded_ is set after the callbacks, maintaining the correct state.",
  "verification_cot": "1. In the vulnerable code, model_loaded_callbacks_ is directly iterated over, which is unsafe if the callbacks modify the vector. 2. The vulnerable code does not swap model_loaded_callbacks_ with a local copy, leading to potential use-after-free if the vector is modified during iteration. 3. The flag loaded_ is set after the callbacks, but the main issue is the unsafe iteration over model_loaded_callbacks_.",
  "vulnerability_related_variables": {
    "model_loaded_callbacks_": "This variable is a collection that stores functions to be executed once a specific event occurs. When the event is triggered, each function in the collection is called with a reference to the current object, and the collection is then emptied.",
    "loaded_": "This variable is a flag that indicates whether a particular process has been completed. It is initially set to false and is updated to true once the process is successfully finished."
  },
  "vulnerability_related_functions": {
    "NotifyModelLoaded": "The function checks if it is called on the correct sequence, iterates over a collection of callback functions, executes each callback with the current object as an argument, sets a flag to indicate a condition is true, and clears the collection of callbacks."
  },
  "root_cause": "Modification of the model_loaded_callbacks_ vector during iteration, leading to use-after-free.",
  "patch_cot": "First, create a local vector model_loaded_callbacks within the NotifyModelLoaded function. Swap the contents of model_loaded_callbacks_ with the local vector model_loaded_callbacks. This will clear model_loaded_callbacks_ and transfer its contents to the local vector. Iterate over the local vector model_loaded_callbacks to run each callback. This ensures that any modifications to model_loaded_callbacks_ during the callback execution do not affect the iteration. After processing all callbacks, set the loaded_ variable to true to indicate that the model is loaded."
}