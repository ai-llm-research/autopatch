

struct ttm_buffer_object {
    void* bdev;
    void* resource;
};

struct amdgpu_bo {
    struct ttm_buffer_object tbo;
};

struct amdgpu_device {
    struct {
        struct amdgpu_ring* buffer_funcs_ring;
        int buffer_funcs_enabled;
        void* gtt_window_lock;
    } mman;
};

struct amdgpu_ring {};

struct amdgpu_res_cursor {
    unsigned long long size;
    unsigned long long remaining;
};

struct dma_resv {};

struct dma_fence {};

int amdgpu_ttm_clear_buffer(struct amdgpu_bo *bo, struct dma_resv *resv, struct dma_fence **fence);

struct amdgpu_device* amdgpu_ttm_adev(void* bdev) { return (struct amdgpu_device*)0; }

struct dma_fence* dma_fence_get_stub() { return (struct dma_fence*)0; }

void amdgpu_res_first(void* resource, int a, unsigned long long b, struct amdgpu_res_cursor* cursor) {}

void mutex_lock(void* lock) {}

void mutex_unlock(void* lock) {}

int amdgpu_res_cleared(struct amdgpu_res_cursor* cursor) { return 0; }

void amdgpu_res_next(struct amdgpu_res_cursor* cursor, unsigned long long size) {}

int amdgpu_ttm_map_buffer(struct ttm_buffer_object* tbo, void* resource, struct amdgpu_res_cursor* cursor, int a, struct amdgpu_ring* ring, int b, unsigned long long* size, unsigned long long* addr) { return 0; }

int amdgpu_ttm_fill_mem(struct amdgpu_ring* ring, int a, unsigned long long addr, unsigned long long size, struct dma_resv* resv, struct dma_fence** next, int b, int c) { return 0; }

void dma_fence_put(struct dma_fence* fence) {}

unsigned long long amdgpu_bo_size(struct amdgpu_bo* bo) { return 0; }

unsigned long long min(unsigned long long a, unsigned long long b) { return a < b ? a : b; }

int amdgpu_ttm_clear_buffer(struct amdgpu_bo *bo, struct dma_resv *resv, struct dma_fence **fence)
{
    struct amdgpu_device *adev = amdgpu_ttm_adev(bo->tbo.bdev);
    struct amdgpu_ring *ring = adev->mman.buffer_funcs_ring;
    struct amdgpu_res_cursor cursor;
    unsigned long long addr;
    int r;

    if (!adev->mman.buffer_funcs_enabled)
        return -22; // assuming -EINVAL is -22

    if (!fence)
        return -22; // assuming -EINVAL is -22

    *fence = dma_fence_get_stub();

    amdgpu_res_first(bo->tbo.resource, 0, amdgpu_bo_size(bo), &cursor);

    mutex_lock(&adev->mman.gtt_window_lock);
    while (cursor.remaining) {
        struct dma_fence *next = (struct dma_fence*)0;
        unsigned long long size;

        if (amdgpu_res_cleared(&cursor)) {
            amdgpu_res_next(&cursor, cursor.size);
            continue;
        }

        size = min(cursor.size, 256ULL << 20);

        r = amdgpu_ttm_map_buffer(&bo->tbo, bo->tbo.resource, &cursor,
                                  1, ring, 0, &size, &addr);
        if (r)
            goto err;

        r = amdgpu_ttm_fill_mem(ring, 0, addr, size, resv,
                                &next, 1, 1);
        if (r)
            goto err;

        dma_fence_put(*fence);
        *fence = next;

        amdgpu_res_next(&cursor, size);
    }
err:
    mutex_unlock(&adev->mman.gtt_window_lock);

    return r;
}

