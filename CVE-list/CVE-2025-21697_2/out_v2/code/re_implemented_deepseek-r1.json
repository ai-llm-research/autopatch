{
 "supplementary_code": "```c\nstruct v3d_dev {\nstruct drm_device drm;\n/* Short representation (e.g. 33, 41) of the V3D tech version */\nint ver;\n/* Short representation (e.g. 5, 6) of the V3D tech revision */\nint rev;\nbool single_irq_line;\nstruct v3d_perfmon_info perfmon_info;\nvoid __iomem *hub_regs;\nvoid __iomem *core_regs[3];\nvoid __iomem *bridge_regs;\nvoid __iomem *gca_regs;\nstruct clk *clk;\nstruct reset_control *reset;\n/* Virtual and DMA addresses of the single shared page table. */\nvolatile u32 *pt;\ndma_addr_t pt_paddr;\n/* Virtual and DMA addresses of the MMU's scratch page. When\n* a read or write is invalid in the MMU, it will be\n* redirected here.\n*/\nvoid *mmu_scratch;\ndma_addr_t mmu_scratch_paddr;\n/* virtual address bits from V3D to the MMU. */\nint va_width;\n/* Number of V3D cores. */\nu32 cores;\n/* Allocator managing the address space. All units are in\n* number of pages.\n*/\nstruct drm_mm mm;\nspinlock_t mm_lock;\n/*\n* tmpfs instance used for shmem backed objects\n*/\nstruct vfsmount *gemfs;\nstruct work_struct overflow_mem_work;\nstruct v3d_bin_job *bin_job;\nstruct v3d_render_job *render_job;\nstruct v3d_tfu_job *tfu_job;\nstruct v3d_csd_job *csd_job;\nstruct v3d_cpu_job *cpu_job;\nstruct v3d_queue_state queue[V3D_MAX_QUEUES];\n/* Spinlock used to synchronize the overflow memory\n* management against bin job submission.\n*/\nspinlock_t job_lock;\n/* Used to track the active perfmon if any. */\nstruct v3d_perfmon *active_perfmon;\n/* Protects bo_stats */\nstruct mutex bo_lock;\n/* Lock taken when resetting the GPU, to keep multiple\n* processes from trying to park the scheduler threads and\n* reset at once.\n*/\nstruct mutex reset_lock;\n/* Lock taken when creating and pushing the GPU scheduler\n* jobs, to keep the sched-fence seqnos in order.\n*/\nstruct mutex sched_lock;\n/* Lock taken during a cache clean and when initiating an L2\n* flush, to keep L2 flushes from interfering with the\n* synchronous L2 cleans.\n*/\nstruct mutex cache_clean_lock;\nstruct {\nu32 num_allocated;\nu32 pages_allocated;\n} bo_stats;\n};\n```\n```c\n#define V3D_READ(offset) readl(v3d->hub_regs + offset)\n```\n```c\n#define V3D_WRITE(offset, val) writel(val, v3d->hub_regs + offset)\n```\n```c\nstruct v3d_fence {\nstruct dma_fence base;\nstruct drm_device *dev;\n/* v3d seqno for signaled() test */\nu64 seqno;\nenum v3d_queue queue;\n};\n```\n```c\nstatic inline struct v3d_fence *\nto_v3d_fence(struct dma_fence *fence)\n{\nreturn (struct v3d_fence *)fence;\n}\n```\n```c\nvoid\nv3d_job_update_stats(struct v3d_job *job, enum v3d_queue queue)\n{\nstruct v3d_dev *v3d = job->v3d;\nstruct v3d_file_priv *file = job->file->driver_priv;\nstruct v3d_stats *global_stats = &v3d->queue[queue].stats;\nstruct v3d_stats *local_stats = &file->stats[queue];\nu64 now = local_clock();\nunsigned long flags;\n/* See comment in v3d_job_start_stats() */\nif (IS_ENABLED(CONFIG_LOCKDEP))\nlocal_irq_save(flags);\nelse\npreempt_disable();\nv3d_stats_update(local_stats, now);\nv3d_stats_update(global_stats, now);\nif (IS_ENABLED(CONFIG_LOCKDEP))\nlocal_irq_restore(flags);\nelse\npreempt_enable();\n}\n```\n```c\nint dma_fence_signal(struct dma_fence *fence)\n{\nunsigned long flags;\nint ret;\nbool tmp;\nif (WARN_ON(!fence))\nreturn -EINVAL;\ntmp = dma_fence_begin_signalling();\nspin_lock_irqsave(fence->lock, flags);\nret = dma_fence_signal_timestamp_locked(fence, ktime_get());\nspin_unlock_irqrestore(fence->lock, flags);\ndma_fence_end_signalling(tmp);\nreturn ret;\n}\nEXPORT_SYMBOL(dma_fence_signal);\n```\n```c\n#define ARRAY_SIZE(arr) (sizeof(arr) / sizeof((arr)[0]) + __must_be_array(arr))\n```\n```c\n#define dev_err(dev, fmt, ...) \\\ndev_printk_index_wrap(_dev_err, KERN_ERR, dev, dev_fmt(fmt), ##__VA_ARGS__)\n```\n",
 "function_prototype": "static irqreturn_t v3d_hub_irq(int irq, void *arg)",
 "re_implemented_code": "\n```c\nstatic irqreturn_t v3d_hub_irq(int irq, void *arg) {\nstruct v3d_dev *v3d = arg;\nu32 intsts;\nirqreturn_t status = IRQ_NONE;\n// Read the interrupt status from the V3D hub\nintsts = V3D_READ(V3D_INTSTS_OFFSET);\n// Acknowledge the interrupts that are being handled\nV3D_WRITE(V3D_INTACK_OFFSET, intsts);\n// Check if the TFU completion interrupt is set\nif (intsts & V3D_INT_TFU_DONE) {\nstruct v3d_fence *fence = NULL;\n// Retrieve the fence associated with the TFU job\nfence = v3d->tfu_job ? to_v3d_fence(&v3d->tfu_job->base.fence) : NULL;\n// Trace the TFU interrupt with the sequence number\ntrace_v3d_tfu_interrupt(fence ? fence->seqno : 0);\n// Signal the DMA fence to indicate completion\nif (fence && !dma_fence_is_signaled(&fence->base)) {\ndma_fence_signal(&fence->base);\nstatus |= IRQ_HANDLED;\n}\n}\n// Check if any MMU-related interrupts are set\nif ((intsts & V3D_INT_MMU_ERROR_MASK) != 0) {\nu32 axi_id;\nu64 addr;\nconst char *client_name = \"unknown\";\n// Read the AXI ID of the MMU violation\naxi_id = V3D_READ(V3D_MMU_AXIID_OFFSET);\n// Read the address of the MMU violation and adjust it based on the virtual address width\naddr = V3D_READ(V3D_MMU_ADDR_OFFSET);\naddr <<= (V3D_VA_WIDTH - v3d->va_width);\n// Define a static array of client names for V3D 4.1 and above\nstatic const char *const clients[] = { ... };\n// Default client name if not found\nclient_name = \"unknown_client\";\n// Re-write the MMU control register to clear the interrupt\nV3D_WRITE(V3D_MMUCTRL_OFFSET, V3D_MMUCTRL_DEFAULTS);\n// If the V3D version is 4.1 or above, adjust the AXI ID and find the client name\nif (v3d->ver >= 4 && v3d->rev >= 1) {\naxi_id &= ~BIT(7); // Clear bit 7 as per spec.\nif (axi_id < ARRAY_SIZE(clients))\nclient_name = clients[axi_id];\n}\n// Log an error message with details about the MMU error\ndev_err(v3d->drm.dev,\n\"MMU error: Client %s (AXI_ID=0x%08X) accessed invalid address 0x%016llx\\n\",\nclient_name, axi_id, addr);\n// Set the status to indicate that the interrupt was handled\nstatus |= IRQ_HANDLED;\n}\n// Return the status indicating whether the interrupt was handled\nreturn status;\n}\n```\n",
 "is_vulnerable": true
}