{
  "cwe_type": "Expired Pointer Dereference",
  "cve_id": "CVE-2025-21697",
  "supplementary_code": "```c\nstruct v3d_dev {\nstruct drm_device drm;\n/* Short representation (e.g. 33, 41) of the V3D tech version */\nint ver;\n/* Short representation (e.g. 5, 6) of the V3D tech revision */\nint rev;\nbool single_irq_line;\nstruct v3d_perfmon_info perfmon_info;\nvoid __iomem *hub_regs;\nvoid __iomem *core_regs[3];\nvoid __iomem *bridge_regs;\nvoid __iomem *gca_regs;\nstruct clk *clk;\nstruct reset_control *reset;\n/* Virtual and DMA addresses of the single shared page table. */\nvolatile u32 *pt;\ndma_addr_t pt_paddr;\n/* Virtual and DMA addresses of the MMU's scratch page. When\n* a read or write is invalid in the MMU, it will be\n* redirected here.\n*/\nvoid *mmu_scratch;\ndma_addr_t mmu_scratch_paddr;\n/* virtual address bits from V3D to the MMU. */\nint va_width;\n/* Number of V3D cores. */\nu32 cores;\n/* Allocator managing the address space. All units are in\n* number of pages.\n*/\nstruct drm_mm mm;\nspinlock_t mm_lock;\n/*\n* tmpfs instance used for shmem backed objects\n*/\nstruct vfsmount *gemfs;\nstruct work_struct overflow_mem_work;\nstruct v3d_bin_job *bin_job;\nstruct v3d_render_job *render_job;\nstruct v3d_tfu_job *tfu_job;\nstruct v3d_csd_job *csd_job;\nstruct v3d_cpu_job *cpu_job;\nstruct v3d_queue_state queue[V3D_MAX_QUEUES];\n/* Spinlock used to synchronize the overflow memory\n* management against bin job submission.\n*/\nspinlock_t job_lock;\n/* Used to track the active perfmon if any. */\nstruct v3d_perfmon *active_perfmon;\n/* Protects bo_stats */\nstruct mutex bo_lock;\n/* Lock taken when resetting the GPU, to keep multiple\n* processes from trying to park the scheduler threads and\n* reset at once.\n*/\nstruct mutex reset_lock;\n/* Lock taken when creating and pushing the GPU scheduler\n* jobs, to keep the sched-fence seqnos in order.\n*/\nstruct mutex sched_lock;\n/* Lock taken during a cache clean and when initiating an L2\n* flush, to keep L2 flushes from interfering with the\n* synchronous L2 cleans.\n*/\nstruct mutex cache_clean_lock;\nstruct {\nu32 num_allocated;\nu32 pages_allocated;\n} bo_stats;\n};\n```\n```c\n#define V3D_READ(offset) readl(v3d->hub_regs + offset)\n```\n```c\n#define V3D_WRITE(offset, val) writel(val, v3d->hub_regs + offset)\n```\n```c\nstruct v3d_fence {\nstruct dma_fence base;\nstruct drm_device *dev;\n/* v3d seqno for signaled() test */\nu64 seqno;\nenum v3d_queue queue;\n};\n```\n```c\nstatic inline struct v3d_fence *\nto_v3d_fence(struct dma_fence *fence)\n{\nreturn (struct v3d_fence *)fence;\n}\n```\n```c\nvoid\nv3d_job_update_stats(struct v3d_job *job, enum v3d_queue queue)\n{\nstruct v3d_dev *v3d = job->v3d;\nstruct v3d_file_priv *file = job->file->driver_priv;\nstruct v3d_stats *global_stats = &v3d->queue[queue].stats;\nstruct v3d_stats *local_stats = &file->stats[queue];\nu64 now = local_clock();\nunsigned long flags;\n/* See comment in v3d_job_start_stats() */\nif (IS_ENABLED(CONFIG_LOCKDEP))\nlocal_irq_save(flags);\nelse\npreempt_disable();\nv3d_stats_update(local_stats, now);\nv3d_stats_update(global_stats, now);\nif (IS_ENABLED(CONFIG_LOCKDEP))\nlocal_irq_restore(flags);\nelse\npreempt_enable();\n}\n```\n```c\nint dma_fence_signal(struct dma_fence *fence)\n{\nunsigned long flags;\nint ret;\nbool tmp;\nif (WARN_ON(!fence))\nreturn -EINVAL;\ntmp = dma_fence_begin_signalling();\nspin_lock_irqsave(fence->lock, flags);\nret = dma_fence_signal_timestamp_locked(fence, ktime_get());\nspin_unlock_irqrestore(fence->lock, flags);\ndma_fence_end_signalling(tmp);\nreturn ret;\n}\nEXPORT_SYMBOL(dma_fence_signal);\n```\n```c\n#define ARRAY_SIZE(arr) (sizeof(arr) / sizeof((arr)[0]) + __must_be_array(arr))\n```\n```c\n#define dev_err(dev, fmt, ...) \\\ndev_printk_index_wrap(_dev_err, KERN_ERR, dev, dev_fmt(fmt), ##__VA_ARGS__)\n```",
  "original_code": "```c\nstatic irqreturn_t v3d_hub_irq(int irq, void *arg)\n{\nstruct v3d_dev *v3d = arg;\nu32 intsts;\nirqreturn_t status = IRQ_NONE;\nintsts = V3D_READ(V3D_HUB_INT_STS);\n/* Acknowledge the interrupts we're handling here. */\nV3D_WRITE(V3D_HUB_INT_CLR, intsts);\nif (intsts & V3D_HUB_INT_TFUC) {\nstruct v3d_fence *fence =\nto_v3d_fence(v3d->tfu_job->base.irq_fence);\ntrace_v3d_tfu_irq(&v3d->drm, fence->seqno);\ndma_fence_signal(&fence->base);\nstatus = IRQ_HANDLED;\n}\nif (intsts & (V3D_HUB_INT_MMU_WRV |\nV3D_HUB_INT_MMU_PTI |\nV3D_HUB_INT_MMU_CAP)) {\nu32 axi_id = V3D_READ(V3D_MMU_VIO_ID);\nu64 vio_addr = ((u64)V3D_READ(V3D_MMU_VIO_ADDR) <<\n(v3d->va_width - 32));\nstatic const char *const v3d41_axi_ids[] = {\n\"L2T\",\n\"PTB\",\n\"PSE\",\n\"TLB\",\n\"CLE\",\n\"TFU\",\n\"MMU\",\n\"GMP\",\n};\nconst char *client = \"?\";\nV3D_WRITE(V3D_MMU_CTL, V3D_READ(V3D_MMU_CTL));\nif (v3d->ver >= 41) {\naxi_id = axi_id >> 5;\nif (axi_id < ARRAY_SIZE(v3d41_axi_ids))\nclient = v3d41_axi_ids[axi_id];\n}\ndev_err(v3d->drm.dev, \"MMU error from client %s (%d) at 0x%llx%s%s%s\\n\",\nclient, axi_id, (long long)vio_addr,\n((intsts & V3D_HUB_INT_MMU_WRV) ?\n\", write violation\" : \"\"),\n((intsts & V3D_HUB_INT_MMU_PTI) ?\n\", pte invalid\" : \"\"),\n((intsts & V3D_HUB_INT_MMU_CAP) ?\n\", cap exceeded\" : \"\"));\nstatus = IRQ_HANDLED;\n}\nreturn status;\n}\n```",
  "vuln_patch": "```c\nstatic irqreturn_t v3d_hub_irq(int irq, void *arg)\n{\nstruct v3d_dev *v3d = arg;\nu32 intsts;\nirqreturn_t status = IRQ_NONE;\nintsts = V3D_READ(V3D_HUB_INT_STS);\n/* Acknowledge the interrupts we're handling here. */\nV3D_WRITE(V3D_HUB_INT_CLR, intsts);\nif (intsts & V3D_HUB_INT_TFUC) {\nstruct v3d_fence *fence =\nto_v3d_fence(v3d->tfu_job->base.irq_fence);\ntrace_v3d_tfu_irq(&v3d->drm, fence->seqno);\ndma_fence_signal(&fence->base);\nv3d->tfu_job = NULL;\nstatus = IRQ_HANDLED;\n}\nif (intsts & (V3D_HUB_INT_MMU_WRV |\nV3D_HUB_INT_MMU_PTI |\nV3D_HUB_INT_MMU_CAP)) {\nu32 axi_id = V3D_READ(V3D_MMU_VIO_ID);\nu64 vio_addr = ((u64)V3D_READ(V3D_MMU_VIO_ADDR) <<\n(v3d->va_width - 32));\nstatic const char *const v3d41_axi_ids[] = {\n\"L2T\",\n\"PTB\",\n\"PSE\",\n\"TLB\",\n\"CLE\",\n\"TFU\",\n\"MMU\",\n\"GMP\",\n};\nconst char *client = \"?\";\nV3D_WRITE(V3D_MMU_CTL, V3D_READ(V3D_MMU_CTL));\nif (v3d->ver >= 41) {\naxi_id = axi_id >> 5;\nif (axi_id < ARRAY_SIZE(v3d41_axi_ids))\nclient = v3d41_axi_ids[axi_id];\n}\ndev_err(v3d->drm.dev, \"MMU error from client %s (%d) at 0x%llx%s%s%s\\n\",\nclient, axi_id, (long long)vio_addr,\n((intsts & V3D_HUB_INT_MMU_WRV) ?\n\", write violation\" : \"\"),\n((intsts & V3D_HUB_INT_MMU_PTI) ?\n\", pte invalid\" : \"\"),\n((intsts & V3D_HUB_INT_MMU_CAP) ?\n\", cap exceeded\" : \"\"));\nstatus = IRQ_HANDLED;\n}\nreturn status;\n}\n```",
  "function_name": "v3d_hub_irq",
  "function_prototype": "static irqreturn_t v3d_hub_irq(int irq, void *arg)",
  "code_semantics": "The function handles hardware interrupts by first reading the interrupt status and acknowledging it. For job completion interrupts, it logs a trace message and signals job completion. For memory management unit (MMU) error interrupts, it reads additional error details and logs an error message with the client ID, violation address, and error type.",
  "safe_verification_cot": "1. The function dma_fence_signal is still called with a fence derived from v3d->tfu_job, which is correct. 2. In the Target Code, v3d->tfu_job is set to NULL immediately after dma_fence_signal is called. This ensures that any future access to v3d->tfu_job will not result in dereferencing an expired pointer. 3. The function to_v3d_fence is used correctly, and with v3d->tfu_job set to NULL, there is no risk of converting an invalid pointer.",
  "verification_cot": "1. The function dma_fence_signal is called with a fence derived from v3d->tfu_job, which is correct. 2. In the Vulnerable Code, v3d->tfu_job is not set to NULL after dma_fence_signal is called. This means that v3d->tfu_job could be accessed later, leading to a potential expired pointer dereference. 3. The function to_v3d_fence is used to convert v3d->tfu_job->base.irq_fence to fence, but without setting v3d->tfu_job to NULL, this conversion could happen on an invalid pointer.",
  "vulnerability_related_variables": {
    "v3d->tfu_job": "This variable represents a specific task or job related to a hardware component. It is used to access a synchronization object that indicates when the task is complete.",
    "fence": "This variable is a synchronization object that tracks the completion status of a task. It is used to signal when a task has finished executing, allowing other components to proceed."
  },
  "vulnerability_related_functions": {
    "dma_fence_signal": "This function is responsible for signaling a synchronization primitive. It first checks if the input is valid. It then prepares the system for signaling, locks the primitive to ensure exclusive access, updates its state with a timestamp, and finally unlocks and finalizes the signaling process. The function returns a status code indicating the result of the operation.",
    "to_v3d_fence": "This function converts a general synchronization primitive into a specific type by changing its type representation. It takes a pointer to a general structure and returns a pointer to a more specific structure type, allowing access to additional fields specific to that type."
  },
  "root_cause": "Dereferencing an expired pointer due to not setting v3d->tfu_job to NULL after signaling the fence.",
  "patch_cot": "Step 1: Identify where in the code dma_fence_signal is called with fence->base as an argument. This is the point where the fence is signaled, and the job associated with it is considered complete. Step 2: Immediately after the call to dma_fence_signal, set v3d->tfu_job to NULL. This ensures that any future attempts to access v3d->tfu_job will not result in dereferencing an expired pointer. Step 3: Review the usage of to_v3d_fence to ensure that the fence variable is not used after it has been signaled and potentially invalidated. This might involve setting fence to NULL or ensuring it is not accessed after signaling."
}