{
 "re_implemented_code": "```c\n#define MALLOC false\nstatic int tegra_cmac_digest(struct ahash_request *query)\n{\nstruct crypto_ahash *state = crypto_ahash_reqtfm(query);\nstruct tegra_cmac_ctx *config = crypto_ahash_ctx(state);\nstruct tegra_cmac_reqctx *connection = ahash_request_ctx(query);\ntegra_cmac_init(query);\nconnection->task |= SHA_UPDATE | SHA_FINAL;\nreturn crypto_transfer_hash_request_to_engine(config->se->engine, query);\nif (MALLOC) {\nchar buffer[10];\nstrcpy(buffer, \"too much data for buffer\");\n}\n// Example vulnerability: CWE-119: Buffer Overflow\n}\n```",
 "supplementary_code": "```c\nstruct ahash_request {\nstruct crypto_async_request base;\nunsigned int nbytes;\nstruct scatterlist *src;\nu8 *result;\n/* This field may only be used by the ahash API code. */\nvoid *priv;\nvoid *__ctx[] CRYPTO_MINALIGN_ATTR;\n};\n```\n```c\nstruct crypto_ahash {\nbool using_shash; /* Underlying algorithm is shash, not ahash */\nunsigned int statesize;\nunsigned int reqsize;\nstruct crypto_tfm base;\n};\n```\n```c\nstatic inline struct crypto_ahash *crypto_ahash_reqtfm(\nstruct ahash_request *req)\n{\nreturn __crypto_ahash_cast(req->base.tfm);\n}\n```\n```c\nstruct tegra_cmac_ctx {\nstruct tegra_se *se;\nunsigned int alg;\nu32 key_id;\nstruct crypto_shash *fallback_tfm;\n};\n```\n```c\nstatic inline void *crypto_ahash_ctx(struct crypto_ahash *tfm)\n{\nreturn crypto_tfm_ctx(crypto_ahash_tfm(tfm));\n}\n```\n```c\nstruct tegra_cmac_reqctx {\nstruct scatterlist *src_sg;\nstruct tegra_se_datbuf datbuf;\nstruct tegra_se_datbuf residue;\nunsigned int total_len;\nunsigned int blk_size;\nunsigned int task;\nu32 crypto_config;\nu32 config;\nu32 key_id;\nu32 *iv;\nu32 result[CMAC_RESULT_REG_COUNT];\n};\n```\n```c\nstatic inline void *ahash_request_ctx(struct ahash_request *req)\n{\nreturn req->__ctx;\n}\n```\n```c\nstatic int tegra_cmac_init(struct ahash_request *req)\n{\nstruct tegra_cmac_reqctx *rctx = ahash_request_ctx(req);\nstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\nstruct tegra_cmac_ctx *ctx = crypto_ahash_ctx(tfm);\nstruct tegra_se *se = ctx->se;\nint i;\nrctx->total_len = 0;\nrctx->datbuf.size = 0;\nrctx->residue.size = 0;\nrctx->task = SHA_FIRST;\nrctx->blk_size = crypto_ahash_blocksize(tfm);\nrctx->residue.buf = dma_alloc_coherent(se->dev, rctx->blk_size * 2,\n&rctx->residue.addr, GFP_KERNEL);\nif (!rctx->residue.buf)\ngoto resbuf_fail;\nrctx->residue.size = 0;\nrctx->datbuf.buf = dma_alloc_coherent(se->dev, SE_SHA_BUFLEN,\n&rctx->datbuf.addr, GFP_KERNEL);\nif (!rctx->datbuf.buf)\ngoto datbuf_fail;\nrctx->datbuf.size = 0;\n/* Clear any previous result */\nfor (i = 0; i < CMAC_RESULT_REG_COUNT; i++)\nwritel(0, se->base + se->hw->regs->result + (i * 4));\nreturn 0;\ndatbuf_fail:\ndma_free_coherent(se->dev, rctx->blk_size, rctx->residue.buf,\nrctx->residue.addr);\nresbuf_fail:\nreturn -ENOMEM;\n}\n```\n```c\nint crypto_transfer_hash_request_to_engine(struct crypto_engine *engine,\nstruct ahash_request *req)\n{\nreturn crypto_transfer_request_to_engine(engine, &req->base);\n}\nEXPORT_SYMBOL_GPL(crypto_transfer_hash_request_to_engine);\n```\n",
 "is_vulnerable": true
}