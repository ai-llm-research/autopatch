```cpp
class V8_EXPORT_PRIVATE JSHeapBroker {
 public:
  JSHeapBroker(Isolate* isolate, Zone* broker_zone, bool tracing_enabled,
               CodeKind code_kind);

  // For use only in tests, sets default values for some arguments. Avoids
  // churn when new flags are added.
  JSHeapBroker(Isolate* isolate, Zone* broker_zone)
      : JSHeapBroker(isolate, broker_zone, v8_flags.trace_heap_broker,
                     CodeKind::TURBOFAN_JS) {}

  ~JSHeapBroker();

  // The compilation target's native context. We need the setter because at
  // broker construction time we don't yet have the canonical handle.
  NativeContextRef target_native_context() const {
    return target_native_context_.value();
  }
  void SetTargetNativeContextRef(DirectHandle<NativeContext> native_context);

  void InitializeAndStartSerializing(
      DirectHandle<NativeContext> native_context);

  Isolate* isolate() const { return isolate_; }

  // The pointer compression cage base value used for decompression of all
  // tagged values except references to InstructionStream objects.
  PtrComprCageBase cage_base() const {
#if V8_COMPRESS_POINTERS
    return cage_base_;
#else
    return PtrComprCageBase{};
#endif  // V8_COMPRESS_POINTERS
  }

  Zone* zone() const { return zone_; }
  bool tracing_enabled() const { return tracing_enabled_; }

  NexusConfig feedback_nexus_config() const {
    return IsMainThread() ? NexusConfig::FromMainThread(isolate())
                          : NexusConfig::FromBackgroundThread(
                                isolate(), local_isolate()->heap());
  }

  enum BrokerMode { kDisabled, kSerializing, kSerialized, kRetired };
  BrokerMode mode() const { return mode_; }

  void StopSerializing();
  void Retire();
  bool SerializingAllowed() const;

#ifdef DEBUG
  // Get the current heap broker for this thread. Only to be used for DCHECKs.
  static JSHeapBroker* Current();
#endif

  // Remember the local isolate and initialize its local heap with the
  // persistent and canonical handles provided by {info}.
  void AttachLocalIsolate(OptimizedCompilationInfo* info,
                          LocalIsolate* local_isolate);
  // Forget about the local isolate and pass the persistent and canonical
  // handles provided back to {info}. {info} is responsible for disposing of
  // them.
  void DetachLocalIsolate(OptimizedCompilationInfo* info);

  // TODO(v8:7700): Refactor this once the broker is no longer
  // Turbofan-specific.
  void AttachLocalIsolateForMaglev(maglev::MaglevCompilationInfo* info,
                                   LocalIsolate* local_isolate);
  void DetachLocalIsolateForMaglev(maglev::MaglevCompilationInfo* info);

  // Attaches the canonical handles map from the compilation info to the broker.
  // Ownership of the map remains in the compilation info.
  template <typename CompilationInfoT>
  void AttachCompilationInfo(CompilationInfoT* info) {
    set_canonical_handles(info->canonical_handles());
  }

  bool StackHasOverflowed() const;

#ifdef DEBUG
  void PrintRefsAnalysis() const;
#endif  // DEBUG

  // Returns the handle from root index table for read only heap objects.
  DirectHandle<Object> GetRootHandle(Tagged<Object> object);

  // Never returns nullptr.
  ObjectData* GetOrCreateData(Handle<Object> object,
                              GetOrCreateDataFlags flags = {});
  ObjectData* GetOrCreateData(Tagged<Object> object,
                              GetOrCreateDataFlags flags = {});

  // Gets data only if we have it. However, thin wrappers will be created for
  // smis, read-only objects and never-serialized objects.
  ObjectData* TryGetOrCreateData(Handle<Object> object,
                                 GetOrCreateDataFlags flags = {});
  ObjectData* TryGetOrCreateData(Tagged<Object> object,
                                 GetOrCreateDataFlags flags = {});

  // Check if {object} is any native context's %ArrayPrototype% or
  // %ObjectPrototype%.
  bool IsArrayOrObjectPrototype(JSObjectRef object) const;
  bool IsArrayOrObjectPrototype(Handle<JSObject> object) const;

  bool HasFeedback(FeedbackSource const& source) const;
  void SetFeedback(FeedbackSource const& source,
                   ProcessedFeedback const* feedback);
  FeedbackSlotKind GetFeedbackSlotKind(FeedbackSource const& source) const;

  ElementAccessFeedback const& ProcessFeedbackMapsForElementAccess(
      ZoneVector<MapRef>& maps, KeyedAccessMode const& keyed_mode,
      FeedbackSlotKind slot_kind);

  // Binary, comparison and for-in hints can be fully expressed via
  // an enum. Insufficient feedback is signaled by <Hint enum>::kNone.
  BinaryOperationHint GetFeedbackForBinaryOperation(
      FeedbackSource const& source);
  CompareOperationHint GetFeedbackForCompareOperation(
      FeedbackSource const& source);
  ForInHint GetFeedbackForForIn(FeedbackSource const& source);

  ProcessedFeedback const& GetFeedbackForCall(FeedbackSource const& source);
  ProcessedFeedback const& GetFeedbackForGlobalAccess(
      FeedbackSource const& source);
  ProcessedFeedback const& GetFeedbackForInstanceOf(
      FeedbackSource const& source);
  TypeOfFeedback::Result GetFeedbackForTypeOf(FeedbackSource const& source);
  ProcessedFeedback const& GetFeedbackForArrayOrObjectLiteral(
      FeedbackSource const& source);
  ProcessedFeedback const& GetFeedbackForRegExpLiteral(
      FeedbackSource const& source);
  ProcessedFeedback const& GetFeedbackForTemplateObject(
      FeedbackSource const& source);
  ProcessedFeedback const& GetFeedbackForPropertyAccess(
      FeedbackSource const& source, AccessMode mode,
      OptionalNameRef static_name);

  ProcessedFeedback const& ProcessFeedbackForBinaryOperation(
      FeedbackSource const& source);
  ProcessedFeedback const& ProcessFeedbackForCompareOperation(
      FeedbackSource const& source);
  ProcessedFeedback const& ProcessFeedbackForForIn(
      FeedbackSource const& source);
  ProcessedFeedback const& ProcessFeedbackForTypeOf(
      FeedbackSource const& source);

  bool FeedbackIsInsufficient(FeedbackSource const& source) const;

  OptionalNameRef GetNameFeedback(FeedbackNexus const& nexus);

  PropertyAccessInfo GetPropertyAccessInfo(MapRef map, NameRef name,
                                           AccessMode access_mode);

  StringRef GetTypedArrayStringTag(ElementsKind kind);

  bool IsMainThread() const {
    return local_isolate() == nullptr || local_isolate()->is_main_thread();
  }

  LocalIsolate* local_isolate() const { return local_isolate_; }

  // TODO(jgruber): Consider always having local_isolate_ set to a real value.
  // This seems not entirely trivial since we currently reset local_isolate_ to
  // nullptr at some point in the JSHeapBroker lifecycle.
  LocalIsolate* local_isolate_or_isolate() const {
    return local_isolate() != nullptr ? local_isolate()
                                      : isolate()->AsLocalIsolate();
  }

  std::optional<RootIndex> FindRootIndex(HeapObjectRef object) {
    // No root constant is a JSReceiver.
    if (object.IsJSReceiver()) return {};
    RootIndex root_index;
    if (root_index_map_.Lookup(*object.object(), &root_index)) {
      return root_index;
    }
    return {};
  }

  // Return the corresponding canonical persistent handle for {object}. Create
  // one if it does not exist.
  // If a local isolate is attached, we can create the persistent handle through
  // it. This commonly happens during the Execute phase.
  // If we don't, that means we are calling this method from serialization. If
  // that happens, we should be inside a persistent handle scope. Then, we would
  // just use the regular handle creation.
  template <typename T>
  Handle<T> CanonicalPersistentHandle(Tagged<T> object) {
    DCHECK_NOT_NULL(canonical_handles_);
    if (Tagged<HeapObject> heap_object;
        TryCast<HeapObject>(object, &heap_object)) {
      RootIndex root_index;
      // CollectArrayAndObjectPrototypes calls this function often with T equal
      // to JSObject. The root index map only contains immortal, immutable
      // objects; it never contains any instances of type JSObject, since
      // JSObjects must exist within a NativeContext, and NativeContexts can be
      // created and destroyed. Thus, we can skip the lookup in the root index
      // map for those values and save a little time.
      if constexpr (std::is_convertible_v<T, JSObject>) {
        DCHECK(!root_index_map_.Lookup(heap_object, &root_index));
      } else if (root_index_map_.Lookup(heap_object, &root_index)) {
        return Handle<T>(isolate_->root_handle(root_index).location());
      }
    }

    auto find_result = canonical_handles_->FindOrInsert(object);
    if (find_result.already_exists) return Handle<T>(*find_result.entry);

    // Allocate new PersistentHandle if one wasn't created before.
    if (local_isolate()) {
      *find_result.entry =
          local_isolate()->heap()->NewPersistentHandle(object).location();
    } else {
      DCHECK(PersistentHandlesScope::IsActive(isolate()));
      *find_result.entry = IndirectHandle<T>(object, isolate()).location();
    }
    return Handle<T>(*find_result.entry);
  }

  template <typename T>
  Handle<T> CanonicalPersistentHandle(Handle<T> object) {
    if (object.is_null()) return object;  // Can't deref a null handle.
    return CanonicalPersistentHandle<T>(*object);
  }

  // Checks if a canonical persistent handle for {object} exists.
  template <typename T>
  bool IsCanonicalHandle(Handle<T> handle) {
    DCHECK_NOT_NULL(canonical_handles_);
    if (Tagged<HeapObject> heap_object;
        TryCast<HeapObject>(*handle, &heap_object)) {
      RootIndex root_index;
      if (root_index_map_.Lookup(heap_object, &root_index)) {
        return true;
      }
      // Builtins use pseudo handles that are canonical and persistent by
      // design.
      if (isolate()->IsBuiltinTableHandleLocation(handle.location())) {
        return true;
      }
    }
    return canonical_handles_->Find(*handle) != nullptr;
  }

  std::string Trace() const;
  void IncrementTracingIndentation();
  void DecrementTracingIndentation();

  // Locks {mutex} through the duration of this scope iff it is the first
  // occurrence. This is done to have a recursive shared lock on {mutex}.
  class V8_NODISCARD RecursiveMutexGuardIfNeeded {
   protected:
    V8_INLINE RecursiveMutexGuardIfNeeded(LocalIsolate* local_isolate,
                                          base::Mutex* mutex,
                                          int* mutex_depth_address);

    ~RecursiveMutexGuardIfNeeded() {
      DCHECK_GE((*mutex_depth_address_), 1);
      (*mutex_depth_address_)--;
      DCHECK_EQ(initial_mutex_depth_, (*mutex_depth_address_));
    }

   private:
    int* const mutex_depth_address_;
    const int initial_mutex_depth_;
    ParkedMutexGuardIf mutex_guard_;
  };

  class MapUpdaterGuardIfNeeded final : public RecursiveMutexGuardIfNeeded {
   public:
    V8_INLINE explicit MapUpdaterGuardIfNeeded(JSHeapBroker* broker);
  };

  class BoilerplateMigrationGuardIfNeeded final
      : public RecursiveMutexGuardIfNeeded {
   public:
    V8_INLINE explicit BoilerplateMigrationGuardIfNeeded(JSHeapBroker* broker);
  };

  // If this returns false, the object is guaranteed to be fully initialized and
  // thus safe to read from a memory safety perspective. The converse does not
  // necessarily hold.
  bool ObjectMayBeUninitialized(DirectHandle<Object> object) const;
  bool ObjectMayBeUninitialized(Tagged<Object> object) const;
  bool ObjectMayBeUninitialized(Tagged<HeapObject> object) const;

  void set_dependencies(CompilationDependencies* dependencies) {
    DCHECK_NOT_NULL(dependencies);
    DCHECK_NULL(dependencies_);
    dependencies_ = dependencies;
  }
  CompilationDependencies* dependencies() const {
    DCHECK_NOT_NULL(dependencies_);
    return dependencies_;
  }

#define V(Type, name, Name) inline typename ref_traits<Type>::ref_type name();
  READ_ONLY_ROOT_LIST(V)
#undef V

 private:
  friend class JSHeapBrokerScopeForTesting;
  friend class HeapObjectRef;
  friend class ObjectRef;
  friend class ObjectData;
  friend class PropertyCellData;

  ProcessedFeedback const& GetFeedback(FeedbackSource const& source) const;
  const ProcessedFeedback& NewInsufficientFeedback(FeedbackSlotKind kind) const;

  // Bottleneck FeedbackNexus access here, for storage in the broker
  // or on-the-fly usage elsewhere in the compiler.
  ProcessedFeedback const& ReadFeedbackForArrayOrObjectLiteral(
      FeedbackSource const& source);
  ProcessedFeedback const& ReadFeedbackForBinaryOperation(
      FeedbackSource const& source) const;
  ProcessedFeedback const& ReadFeedbackForTypeOf(
      FeedbackSource const& source) const;
  ProcessedFeedback const& ReadFeedbackForCall(FeedbackSource const& source);
  ProcessedFeedback const& ReadFeedbackForCompareOperation(
      FeedbackSource const& source) const;
  ProcessedFeedback const& ReadFeedbackForForIn(
      FeedbackSource const& source) const;
  ProcessedFeedback const& ReadFeedbackForGlobalAccess(
      JSHeapBroker* broker, FeedbackSource const& source);
  ProcessedFeedback const& ReadFeedbackForInstanceOf(
      FeedbackSource const& source);
  ProcessedFeedback const& ReadFeedbackForPropertyAccess(
      FeedbackSource const& source, AccessMode mode,
      OptionalNameRef static_name);
  ProcessedFeedback const& ReadFeedbackForRegExpLiteral(
      FeedbackSource const& source);
  ProcessedFeedback const& ReadFeedbackForTemplateObject(
      FeedbackSource const& source);

  void CollectArrayAndObjectPrototypes();

  void set_persistent_handles(
      std::unique_ptr<PersistentHandles> persistent_handles) {
    DCHECK_NULL(ph_);
    ph_ = std::move(persistent_handles);
    DCHECK_NOT_NULL(ph_);
  }
  std::unique_ptr<PersistentHandles> DetachPersistentHandles() {
    DCHECK_NOT_NULL(ph_);
    return std::move(ph_);
  }

  void set_canonical_handles(CanonicalHandlesMap* canonical_handles) {
    canonical_handles_ = canonical_handles;
  }

#define V(Type, name, Name) void Init##Name();
  READ_ONLY_ROOT_LIST(V)
#undef V

  Isolate* const isolate_;
#if V8_COMPRESS_POINTERS
  const PtrComprCageBase cage_base_;
#endif  // V8_COMPRESS_POINTERS
  Zone* const zone_;
  OptionalNativeContextRef target_native_context_;
  RefsMap* refs_;
  RootIndexMap root_index_map_;
  ZoneUnorderedSet<IndirectHandle<JSObject>, IndirectHandle<JSObject>::hash,
                   IndirectHandle<JSObject>::equal_to>
      array_and_object_prototypes_;
  BrokerMode mode_ = kDisabled;
  bool const tracing_enabled_;
  CodeKind const code_kind_;
  std::unique_ptr<PersistentHandles> ph_;
  LocalIsolate* local_isolate_ = nullptr;
  // The CanonicalHandlesMap is owned by the compilation info.
  CanonicalHandlesMap* canonical_handles_;
  unsigned trace_indentation_ = 0;
  ZoneUnorderedMap<FeedbackSource, ProcessedFeedback const*,
                   FeedbackSource::Hash, FeedbackSource::Equal>
      feedback_;
  ZoneUnorderedMap<PropertyAccessTarget, PropertyAccessInfo,
                   PropertyAccessTarget::Hash, PropertyAccessTarget::Equal>
      property_access_infos_;

  // Cache read only roots to avoid needing to look them up via the map.
#define V(Type, name, Name) \
  OptionalRef<typename ref_traits<Type>::ref_type> name##_;
  READ_ONLY_ROOT_LIST(V)
#undef V

  CompilationDependencies* dependencies_ = nullptr;

  // The MapUpdater mutex is used in recursive patterns; for example,
  // ComputePropertyAccessInfo may call itself recursively. Thus we need to
  // emulate a recursive mutex, which we do by checking if this heap broker
  // instance already holds the mutex when a lock is requested. This field
  // holds the locking depth, i.e. how many times the mutex has been
  // recursively locked. Only the outermost locker actually locks underneath.
  int map_updater_mutex_depth_ = 0;
  // Likewise for boilerplate migrations.
  int boilerplate_migration_mutex_depth_ = 0;

  static constexpr uint32_t kMinimalRefsBucketCount = 8;
  static_assert(base::bits::IsPowerOfTwo(kMinimalRefsBucketCount));
  static constexpr uint32_t kInitialRefsBucketCount = 1024;
  static_assert(base::bits::IsPowerOfTwo(kInitialRefsBucketCount));
};
```

```cpp
class V8_EXPORT_PRIVATE MapRef : public HeapObjectRef {
 public:
  DEFINE_REF_CONSTRUCTOR(Map, HeapObjectRef)

  IndirectHandle<Map> object() const;

  int instance_size() const;
  InstanceType instance_type() const;
  int GetInObjectProperties() const;
  int GetInObjectPropertiesStartInWords() const;
  int NumberOfOwnDescriptors() const;
  int GetInObjectPropertyOffset(int index) const;
  int constructor_function_index() const;
  int NextFreePropertyIndex() const;
  int UnusedPropertyFields() const;
  ElementsKind elements_kind() const;
  bool is_stable() const;
  bool is_constructor() const;
  bool has_prototype_slot() const;
  bool is_access_check_needed() const;
  bool is_deprecated() const;
  bool CanBeDeprecated() const;
  bool CanTransition() const;
  bool IsInobjectSlackTrackingInProgress() const;
  bool is_dictionary_map() const;
  bool IsFixedCowArrayMap(JSHeapBroker* broker) const;
  bool IsPrimitiveMap() const;
  bool is_undetectable() const;
  bool is_callable() const;
  bool has_indexed_interceptor() const;
  int construction_counter() const;
  bool is_migration_target() const;
  bool supports_fast_array_iteration(JSHeapBroker* broker) const;
  bool supports_fast_array_resize(JSHeapBroker* broker) const;
  bool is_abandoned_prototype_map() const;
  bool IsTwoByteStringMap() const;
  bool IsThinStringMap() const;

  OddballType oddball_type(JSHeapBroker* broker) const;

  bool CanInlineElementAccess() const;

  // Note: Only returns a value if the requested elements kind matches the
  // current kind, or if the current map is an unmodified JSArray initial map.
  OptionalMapRef AsElementsKind(JSHeapBroker* broker, ElementsKind kind) const;

#define DEF_TESTER(Type, ...) bool Is##Type##Map() const;
  INSTANCE_TYPE_CHECKERS(DEF_TESTER)
#undef DEF_TESTER

  bool IsBooleanMap(JSHeapBroker* broker) const;

  HeapObjectRef GetBackPointer(JSHeapBroker* broker) const;

  HeapObjectRef prototype(JSHeapBroker* broker) const;

  bool PrototypesElementsDoNotHaveAccessorsOrThrow(
      JSHeapBroker* broker, ZoneVector<MapRef>* prototype_maps);

  // Concerning the underlying instance_descriptors:
  DescriptorArrayRef instance_descriptors(JSHeapBroker* broker) const;
  MapRef FindFieldOwner(JSHeapBroker* broker,
                        InternalIndex descriptor_index) const;
  PropertyDetails GetPropertyDetails(JSHeapBroker* broker,
                                     InternalIndex descriptor_index) const;
  NameRef GetPropertyKey(JSHeapBroker* broker,
                         InternalIndex descriptor_index) const;
  FieldIndex GetFieldIndexFor(InternalIndex descriptor_index) const;
  OptionalObjectRef GetStrongValue(JSHeapBroker* broker,
                                   InternalIndex descriptor_number) const;

  MapRef FindRootMap(JSHeapBroker* broker) const;
  ObjectRef GetConstructor(JSHeapBroker* broker) const;
};

HeapObjectRef MapRef::prototype(JSHeapBroker* broker) const {
  return MakeRefAssumeMemoryFence(broker,
                                  Cast<HeapObject>(object()->prototype()));
}

HeapObjectRef MapRef::prototype(JSHeapBroker* broker) const {
  return MakeRefAssumeMemoryFence(broker,
                                  Cast<HeapObject>(object()->prototype()));
}
```
```cpp
class V8_EXPORT_PRIVATE ObjectRef {
 public:
  explicit ObjectRef(ObjectData* data, bool check_type = true) : data_(data) {
    CHECK_NOT_NULL(data_);
  }

  IndirectHandle<Object> object() const;

  bool equals(ObjectRef other) const;

  size_t hash_value() const { return base::hash_combine(object().address()); }

  bool IsSmi() const;
  int AsSmi() const;

#define HEAP_IS_METHOD_DECL(Name) bool Is##Name() const;
  HEAP_BROKER_OBJECT_LIST(HEAP_IS_METHOD_DECL)
#undef HEAP_IS_METHOD_DECL

#define HEAP_AS_METHOD_DECL(Name) Name##Ref As##Name() const;
  HEAP_BROKER_OBJECT_LIST(HEAP_AS_METHOD_DECL)
#undef HEAP_AS_METHOD_DECL

  bool IsNull() const;
  bool IsUndefined() const;
  enum HoleType HoleType() const;
  bool IsTheHole() const;
  bool IsPropertyCellHole() const;
  bool IsHashTableHole() const;
  bool IsPromiseHole() const;
  bool IsNullOrUndefined() const;

  std::optional<bool> TryGetBooleanValue(JSHeapBroker* broker) const;
  Maybe<double> OddballToNumber(JSHeapBroker* broker) const;

  bool should_access_heap() const;

  ObjectData* data() const;

  struct Hash {
    size_t operator()(ObjectRef ref) const { return ref.hash_value(); }
  };

 protected:
  ObjectData* data_;  // Should be used only by object() getters.

 private:
  friend class FunctionTemplateInfoRef;
  friend class JSArrayData;
  friend class JSFunctionData;
  friend class JSGlobalObjectData;
  friend class JSGlobalObjectRef;
  friend class JSHeapBroker;
  friend class JSObjectData;
  friend class StringData;

  template <typename TRef>
  friend class OptionalRef;

  friend std::ostream& operator<<(std::ostream& os, ObjectRef ref);
  friend bool operator<(ObjectRef lhs, ObjectRef rhs);
  template <typename T, typename Enable>
  friend struct ::v8::internal::ZoneCompactSetTraits;
};

bool ObjectRef::IsNull() const { return i::IsNull(*object()); }

#define DEFINE_IS_AND_AS(Name)                                    \
  bool ObjectRef::Is##Name() const { return data()->Is##Name(); } \
  Name##Ref ObjectRef::As##Name() const {                         \
    DCHECK(Is##Name());                                           \
    return Name##Ref(data());                                     \
  }
HEAP_BROKER_OBJECT_LIST(DEFINE_IS_AND_AS)
#undef DEFINE_IS_AND_AS
```

```cpp
class FunctionTemplateInfoRef : public HeapObjectRef {
 public:
  DEFINE_REF_CONSTRUCTOR(FunctionTemplateInfo, HeapObjectRef)

  IndirectHandle<FunctionTemplateInfo> object() const;

  bool is_signature_undefined(JSHeapBroker* broker) const;
  bool accept_any_receiver() const;
  int16_t allowed_receiver_instance_type_range_start() const;
  int16_t allowed_receiver_instance_type_range_end() const;

  // Function pointer and a data value that should be passed to the callback.
  // The |callback_data| must be read before the |callback|.
  Address callback(JSHeapBroker* broker) const;
  OptionalObjectRef callback_data(JSHeapBroker* broker) const;

  ZoneVector<Address> c_functions(JSHeapBroker* broker) const;
  ZoneVector<const CFunctionInfo*> c_signatures(JSHeapBroker* broker) const;
  HolderLookupResult LookupHolderOfExpectedType(JSHeapBroker* broker,
                                                MapRef receiver_map);
};
```

```cpp
struct HolderLookupResult {
  HolderLookupResult(CallOptimization::HolderLookup lookup_ =
                         CallOptimization::kHolderNotFound,
                     OptionalJSObjectRef holder_ = std::nullopt)
      : lookup(lookup_), holder(holder_) {}
  CallOptimization::HolderLookup lookup;
  OptionalJSObjectRef holder;
};
```

```cpp
bool ObjectRef::IsNull() const { return i::IsNull(*object()); }
```

```cpp
// Holds information about possible function call optimizations.
class CallOptimization {
 public:
  template <class IsolateT>
  CallOptimization(IsolateT* isolate, Handle<Object> function);

  // Gets accessor context by given holder map via holder's constructor.
  // If the holder is a remote object returns empty optional.
  // This method must not be called for holder maps with null constructor
  // because they can't be holders for lazy accessor pairs anyway.
  std::optional<Tagged<NativeContext>> GetAccessorContext(
      Tagged<Map> holder_map) const;

  // Return true if the accessor context for given holder doesn't match
  // given native context of if the holder is a remote object.
  bool IsCrossContextLazyAccessorPair(Tagged<NativeContext> native_context,
                                      Tagged<Map> holder_map) const;

  bool is_constant_call() const { return !constant_function_.is_null(); }
  bool accept_any_receiver() const { return accept_any_receiver_; }
  bool requires_signature_check() const {
    return !expected_receiver_type_.is_null();
  }

  DirectHandle<JSFunction> constant_function() const {
    DCHECK(is_constant_call());
    return constant_function_;
  }

  bool is_simple_api_call() const { return is_simple_api_call_; }

  DirectHandle<FunctionTemplateInfo> expected_receiver_type() const {
    DCHECK(is_simple_api_call());
    return expected_receiver_type_;
  }

  DirectHandle<FunctionTemplateInfo> api_call_info() const {
    DCHECK(is_simple_api_call());
    return api_call_info_;
  }

  enum HolderLookup { kHolderNotFound, kHolderIsReceiver, kHolderFound };

  template <class IsolateT>
  Handle<JSObject> LookupHolderOfExpectedType(
      IsolateT* isolate, DirectHandle<Map> receiver_map,
      HolderLookup* holder_lookup) const;

  bool IsCompatibleReceiverMap(DirectHandle<JSObject> api_holder,
                               Handle<JSObject> holder, HolderLookup) const;

 private:
  template <class IsolateT>
  void Initialize(IsolateT* isolate, Handle<JSFunction> function);
  template <class IsolateT>
  void Initialize(IsolateT* isolate,
                  Handle<FunctionTemplateInfo> function_template_info);

  // Determines whether the given function can be called using the
  // fast api call builtin.
  template <class IsolateT>
  void AnalyzePossibleApiFunction(IsolateT* isolate,
                                  DirectHandle<JSFunction> function);

  Handle<JSFunction> constant_function_;
  Handle<FunctionTemplateInfo> expected_receiver_type_;
  Handle<FunctionTemplateInfo> api_call_info_;

  // TODO(gsathya): Change these to be a bitfield and do a single fast check
  // rather than two checks.
  bool is_simple_api_call_ = false;
  bool accept_any_receiver_ = false;
};
```

```cpp
// CHECK dies with a fatal error if condition is not true.  It is *not*
// controlled by DEBUG, so the check will be executed regardless of
// compilation mode.
//
// We make sure CHECK et al. always evaluates their arguments, as
// doing CHECK(FunctionWithSideEffect()) is a common idiom.
#define CHECK_WITH_MSG(condition, message) \
  do {                                     \
    if (V8_UNLIKELY(!(condition))) {       \
      CHECK_FAILED_HANDLER(message);       \
    }                                      \
  } while (false)
#define CHECK(condition) CHECK_WITH_MSG(condition, #condition)
```