{
 "supplementary_code": "```c\nstruct device {\nstruct kobject kobj;\nstruct device *parent;\nstruct device_private *p;\nconst char *init_name; /* initial name of the device */\nconst struct device_type *type;\nconst struct bus_type *bus; /* type of bus device is on */\nstruct device_driver *driver; /* which driver has allocated this\ndevice */\nvoid *platform_data; /* Platform specific data, device\ncore doesn't touch it */\nvoid *driver_data; /* Driver data, set and get with\ndev_set_drvdata/dev_get_drvdata */\nstruct mutex mutex; /* mutex to synchronize calls to\n* its driver.\n*/\nstruct dev_links_info links;\nstruct dev_pm_info power;\nstruct dev_pm_domain *pm_domain;\n#ifdef CONFIG_ENERGY_MODEL\nstruct em_perf_domain *em_pd;\n#endif\n#ifdef CONFIG_PINCTRL\nstruct dev_pin_info *pins;\n#endif\nstruct dev_msi_info msi;\n#ifdef CONFIG_ARCH_HAS_DMA_OPS\nconst struct dma_map_ops *dma_ops;\n#endif\nu64 *dma_mask; /* dma mask (if dma'able device) */\nu64 coherent_dma_mask;/* Like dma_mask, but for\nalloc_coherent mappings as\nnot all hardware supports\n64 bit addresses for consistent\nallocations such descriptors. */\nu64 bus_dma_limit; /* upstream dma constraint */\nconst struct bus_dma_region *dma_range_map;\nstruct device_dma_parameters *dma_parms;\nstruct list_head dma_pools; /* dma pools (if dma'ble) */\n#ifdef CONFIG_DMA_DECLARE_COHERENT\nstruct dma_coherent_mem *dma_mem; /* internal for coherent mem\noverride */\n#endif\n#ifdef CONFIG_DMA_CMA\nstruct cma *cma_area; /* contiguous memory area for dma\nallocations */\n#endif\n#ifdef CONFIG_SWIOTLB\nstruct io_tlb_mem *dma_io_tlb_mem;\n#endif\n#ifdef CONFIG_SWIOTLB_DYNAMIC\nstruct list_head dma_io_tlb_pools;\nspinlock_t dma_io_tlb_lock;\nbool dma_uses_io_tlb;\n#endif\n/* arch specific additions */\nstruct dev_archdata archdata;\nstruct device_node *of_node; /* associated device tree node */\nstruct fwnode_handle *fwnode; /* firmware device node */\n#ifdef CONFIG_NUMA\nint numa_node; /* NUMA node this device is close to */\n#endif\ndev_t devt; /* dev_t, creates the sysfs \"dev\" */\nu32 id; /* device instance */\nspinlock_t devres_lock;\nstruct list_head devres_head;\nconst struct class *class;\nconst struct attribute_group **groups; /* optional groups */\nvoid (*release)(struct device *dev);\nstruct iommu_group *iommu_group;\nstruct dev_iommu *iommu;\nstruct device_physical_location *physical_location;\nenum device_removable removable;\nbool offline_disabled:1;\nbool offline:1;\nbool of_node_reused:1;\nbool state_synced:1;\nbool can_match:1;\n#if defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_DEVICE) || \\\ndefined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU) || \\\ndefined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL)\nbool dma_coherent:1;\n#endif\n#ifdef CONFIG_DMA_OPS_BYPASS\nbool dma_ops_bypass : 1;\n#endif\n#ifdef CONFIG_DMA_NEED_SYNC\nbool dma_skip_sync:1;\n#endif\n#ifdef CONFIG_IOMMU_DMA\nbool dma_iommu:1;\n#endif\n};\n```\n```c\nstruct net_device {\n/* Cacheline organization can be found documented in\n* Documentation/networking/net_cachelines/net_device.rst.\n* Please update the document when adding new fields.\n*/\n/* TX read-mostly hotpath */\n__cacheline_group_begin(net_device_read_tx);\nstruct_group(priv_flags_fast,\nunsigned long priv_flags:32;\nunsigned long lltx:1;\n);\nconst struct net_device_ops *netdev_ops;\nconst struct header_ops *header_ops;\nstruct netdev_queue *_tx;\nnetdev_features_t gso_partial_features;\nunsigned int real_num_tx_queues;\nunsigned int gso_max_size;\nunsigned int gso_ipv4_max_size;\nu16 gso_max_segs;\ns16 num_tc;\n/* Note : dev->mtu is often read without holding a lock.\n* Writers usually hold RTNL.\n* It is recommended to use READ_ONCE() to annotate the reads,\n* and to use WRITE_ONCE() to annotate the writes.\n*/\nunsigned int mtu;\nunsigned short needed_headroom;\nstruct netdev_tc_txq tc_to_txq[TC_MAX_QUEUE];\n#ifdef CONFIG_XPS\nstruct xps_dev_maps __rcu *xps_maps[XPS_MAPS_MAX];\n#endif\n#ifdef CONFIG_NETFILTER_EGRESS\nstruct nf_hook_entries __rcu *nf_hooks_egress;\n#endif\n#ifdef CONFIG_NET_XGRESS\nstruct bpf_mprog_entry __rcu *tcx_egress;\n#endif\n__cacheline_group_end(net_device_read_tx);\n/* TXRX read-mostly hotpath */\n__cacheline_group_begin(net_device_read_txrx);\nunion {\nstruct pcpu_lstats __percpu *lstats;\nstruct pcpu_sw_netstats __percpu *tstats;\nstruct pcpu_dstats __percpu *dstats;\n};\nunsigned long state;\nunsigned int flags;\nunsigned short hard_header_len;\nnetdev_features_t features;\nstruct inet6_dev __rcu *ip6_ptr;\n__cacheline_group_end(net_device_read_txrx);\n/* RX read-mostly hotpath */\n__cacheline_group_begin(net_device_read_rx);\nstruct bpf_prog __rcu *xdp_prog;\nstruct list_head ptype_specific;\nint ifindex;\nunsigned int real_num_rx_queues;\nstruct netdev_rx_queue *_rx;\nunsigned int gro_max_size;\nunsigned int gro_ipv4_max_size;\nrx_handler_func_t __rcu *rx_handler;\nvoid __rcu *rx_handler_data;\npossible_net_t nd_net;\n#ifdef CONFIG_NETPOLL\nstruct netpoll_info __rcu *npinfo;\n#endif\n#ifdef CONFIG_NET_XGRESS\nstruct bpf_mprog_entry __rcu *tcx_ingress;\n#endif\n__cacheline_group_end(net_device_read_rx);\nchar name[IFNAMSIZ];\nstruct netdev_name_node *name_node;\nstruct dev_ifalias __rcu *ifalias;\n/*\n* I/O specific fields\n* FIXME: Merge these and struct ifmap into one\n*/\nunsigned long mem_end;\nunsigned long mem_start;\nunsigned long base_addr;\n/*\n* Some hardware also needs these fields (state,dev_list,\n* napi_list,unreg_list,close_list) but they are not\n* part of the usual set specified in Space.c.\n*/\nstruct list_head dev_list;\nstruct list_head napi_list;\nstruct list_head unreg_list;\nstruct list_head close_list;\nstruct list_head ptype_all;\nstruct {\nstruct list_head upper;\nstruct list_head lower;\n} adj_list;\n/* Read-mostly cache-line for fast-path access */\nxdp_features_t xdp_features;\nconst struct xdp_metadata_ops *xdp_metadata_ops;\nconst struct xsk_tx_metadata_ops *xsk_tx_metadata_ops;\nunsigned short gflags;\nunsigned short needed_tailroom;\nnetdev_features_t hw_features;\nnetdev_features_t wanted_features;\nnetdev_features_t vlan_features;\nnetdev_features_t hw_enc_features;\nnetdev_features_t mpls_features;\nunsigned int min_mtu;\nunsigned int max_mtu;\nunsigned short type;\nunsigned char min_header_len;\nunsigned char name_assign_type;\nint group;\nstruct net_device_stats stats; /* not used by modern drivers */\nstruct net_device_core_stats __percpu *core_stats;\n/* Stats to monitor link on/off, flapping */\natomic_t carrier_up_count;\natomic_t carrier_down_count;\n#ifdef CONFIG_WIRELESS_EXT\nconst struct iw_handler_def *wireless_handlers;\n#endif\nconst struct ethtool_ops *ethtool_ops;\n#ifdef CONFIG_NET_L3_MASTER_DEV\nconst struct l3mdev_ops *l3mdev_ops;\n#endif\n#if IS_ENABLED(CONFIG_IPV6)\nconst struct ndisc_ops *ndisc_ops;\n#endif\n#ifdef CONFIG_XFRM_OFFLOAD\nconst struct xfrmdev_ops *xfrmdev_ops;\n#endif\n#if IS_ENABLED(CONFIG_TLS_DEVICE)\nconst struct tlsdev_ops *tlsdev_ops;\n#endif\nunsigned int operstate;\nunsigned char link_mode;\nunsigned char if_port;\nunsigned char dma;\n/* Interface address info. */\nunsigned char perm_addr[MAX_ADDR_LEN];\nunsigned char addr_assign_type;\nunsigned char addr_len;\nunsigned char upper_level;\nunsigned char lower_level;\nunsigned short neigh_priv_len;\nunsigned short dev_id;\nunsigned short dev_port;\nint irq;\nu32 priv_len;\nspinlock_t addr_list_lock;\nstruct netdev_hw_addr_list uc;\nstruct netdev_hw_addr_list mc;\nstruct netdev_hw_addr_list dev_addrs;\n#ifdef CONFIG_SYSFS\nstruct kset *queues_kset;\n#endif\n#ifdef CONFIG_LOCKDEP\nstruct list_head unlink_list;\n#endif\nunsigned int promiscuity;\nunsigned int allmulti;\nbool uc_promisc;\n#ifdef CONFIG_LOCKDEP\nunsigned char nested_level;\n#endif\n/* Protocol-specific pointers */\nstruct in_device __rcu *ip_ptr;\n/** @fib_nh_head: nexthops associated with this netdev */\nstruct hlist_head fib_nh_head;\n#if IS_ENABLED(CONFIG_VLAN_8021Q)\nstruct vlan_info __rcu *vlan_info;\n#endif\n#if IS_ENABLED(CONFIG_NET_DSA)\nstruct dsa_port *dsa_ptr;\n#endif\n#if IS_ENABLED(CONFIG_TIPC)\nstruct tipc_bearer __rcu *tipc_ptr;\n#endif\n#if IS_ENABLED(CONFIG_ATALK)\nvoid *atalk_ptr;\n#endif\n#if IS_ENABLED(CONFIG_AX25)\nvoid *ax25_ptr;\n#endif\n#if IS_ENABLED(CONFIG_CFG80211)\nstruct wireless_dev *ieee80211_ptr;\n#endif\n#if IS_ENABLED(CONFIG_IEEE802154) || IS_ENABLED(CONFIG_6LOWPAN)\nstruct wpan_dev *ieee802154_ptr;\n#endif\n#if IS_ENABLED(CONFIG_MPLS_ROUTING)\nstruct mpls_dev __rcu *mpls_ptr;\n#endif\n#if IS_ENABLED(CONFIG_MCTP)\nstruct mctp_dev __rcu *mctp_ptr;\n#endif\n/*\n* Cache lines mostly used on receive path (including eth_type_trans())\n*/\n/* Interface address info used in eth_type_trans() */\nconst unsigned char *dev_addr;\nunsigned int num_rx_queues;\n#define GRO_LEGACY_MAX_SIZE 65536u\n/* TCP minimal MSS is 8 (TCP_MIN_GSO_SIZE),\n* and shinfo->gso_segs is a 16bit field.\n*/\n#define GRO_MAX_SIZE (8 * 65535u)\nunsigned int xdp_zc_max_segs;\nstruct netdev_queue __rcu *ingress_queue;\n#ifdef CONFIG_NETFILTER_INGRESS\nstruct nf_hook_entries __rcu *nf_hooks_ingress;\n#endif\nunsigned char broadcast[MAX_ADDR_LEN];\n#ifdef CONFIG_RFS_ACCEL\nstruct cpu_rmap *rx_cpu_rmap;\n#endif\nstruct hlist_node index_hlist;\n/*\n* Cache lines mostly used on transmit path\n*/\nunsigned int num_tx_queues;\nstruct Qdisc __rcu *qdisc;\nunsigned int tx_queue_len;\nspinlock_t tx_global_lock;\nstruct xdp_dev_bulk_queue __percpu *xdp_bulkq;\n#ifdef CONFIG_NET_SCHED\nDECLARE_HASHTABLE (qdisc_hash, 4);\n#endif\n/* These may be needed for future network-power-down code. */\nstruct timer_list watchdog_timer;\nint watchdog_timeo;\nu32 proto_down_reason;\nstruct list_head todo_list;\n#ifdef CONFIG_PCPU_DEV_REFCNT\nint __percpu *pcpu_refcnt;\n#else\nrefcount_t dev_refcnt;\n#endif\nstruct ref_tracker_dir refcnt_tracker;\nstruct list_head link_watch_list;\nu8 reg_state;\nbool dismantle;\nenum {\nRTNL_LINK_INITIALIZED,\nRTNL_LINK_INITIALIZING,\n} rtnl_link_state:16;\nbool needs_free_netdev;\nvoid (*priv_destructor)(struct net_device *dev);\n/* mid-layer private */\nvoid *ml_priv;\nenum netdev_ml_priv_type ml_priv_type;\nenum netdev_stat_type pcpu_stat_type:8;\n#if IS_ENABLED(CONFIG_GARP)\nstruct garp_port __rcu *garp_port;\n#endif\n#if IS_ENABLED(CONFIG_MRP)\nstruct mrp_port __rcu *mrp_port;\n#endif\n#if IS_ENABLED(CONFIG_NET_DROP_MONITOR)\nstruct dm_hw_stat_delta __rcu *dm_private;\n#endif\nstruct device dev;\nconst struct attribute_group *sysfs_groups[4];\nconst struct attribute_group *sysfs_rx_queue_group;\nconst struct rtnl_link_ops *rtnl_link_ops;\nconst struct netdev_stat_ops *stat_ops;\nconst struct netdev_queue_mgmt_ops *queue_mgmt_ops;\n/* for setting kernel sock attribute on TCP connection setup */\n#define GSO_MAX_SEGS 65535u\n#define GSO_LEGACY_MAX_SIZE 65536u\n/* TCP minimal MSS is 8 (TCP_MIN_GSO_SIZE),\n* and shinfo->gso_segs is a 16bit field.\n*/\n#define GSO_MAX_SIZE (8 * GSO_MAX_SEGS)\n#define TSO_LEGACY_MAX_SIZE 65536\n#define TSO_MAX_SIZE UINT_MAX\nunsigned int tso_max_size;\n#define TSO_MAX_SEGS U16_MAX\nu16 tso_max_segs;\n#ifdef CONFIG_DCB\nconst struct dcbnl_rtnl_ops *dcbnl_ops;\n#endif\nu8 prio_tc_map[TC_BITMASK + 1];\n#if IS_ENABLED(CONFIG_FCOE)\nunsigned int fcoe_ddp_xid;\n#endif\n#if IS_ENABLED(CONFIG_CGROUP_NET_PRIO)\nstruct netprio_map __rcu *priomap;\n#endif\nstruct phy_link_topology *link_topo;\nstruct phy_device *phydev;\nstruct sfp_bus *sfp_bus;\nstruct lock_class_key *qdisc_tx_busylock;\nbool proto_down;\nbool threaded;\n/* priv_flags_slow, ungrouped to save space */\nunsigned long see_all_hwtstamp_requests:1;\nunsigned long change_proto_down:1;\nunsigned long netns_local:1;\nunsigned long fcoe_mtu:1;\nstruct list_head net_notifier_list;\n#if IS_ENABLED(CONFIG_MACSEC)\n/* MACsec management functions */\nconst struct macsec_ops *macsec_ops;\n#endif\nconst struct udp_tunnel_nic_info *udp_tunnel_nic_info;\nstruct udp_tunnel_nic *udp_tunnel_nic;\nstruct ethtool_netdev_state *ethtool;\n/* protected by rtnl_lock */\nstruct bpf_xdp_entity xdp_state[__MAX_XDP_MODE];\nu8 dev_addr_shadow[MAX_ADDR_LEN];\nnetdevice_tracker linkwatch_dev_tracker;\nnetdevice_tracker watchdog_dev_tracker;\nnetdevice_tracker dev_registered_tracker;\nstruct rtnl_hw_stats64 *offload_xstats_l3;\nstruct devlink_port *devlink_port;\n#if IS_ENABLED(CONFIG_DPLL)\nstruct dpll_pin __rcu *dpll_pin;\n#endif\n#if IS_ENABLED(CONFIG_PAGE_POOL)\n/** @page_pools: page pools created for this netdevice */\nstruct hlist_head page_pools;\n#endif\n/** @irq_moder: dim parameters used if IS_ENABLED(CONFIG_DIMLIB). */\nstruct dim_irq_moder *irq_moder;\nu64 max_pacing_offload_horizon;\nstruct napi_config *napi_config;\nunsigned long gro_flush_timeout;\nu32 napi_defer_hard_irqs;\n/**\n* @lock: protects @net_shaper_hierarchy, feel free to use for other\n* netdev-scope protection. Ordering: take after rtnl_lock.\n*/\nstruct mutex lock;\n#if IS_ENABLED(CONFIG_NET_SHAPER)\n/**\n* @net_shaper_hierarchy: data tracking the current shaper status\n* see include/net/net_shapers.h\n*/\nstruct net_shaper_hierarchy *net_shaper_hierarchy;\n#endif\nstruct hlist_head neighbours[NEIGH_NR_TABLES];\nu8 priv[] ____cacheline_aligned\n__counted_by(priv_len);\n} ____cacheline_aligned;\n#define to_net_dev(d) container_of(d, struct net_device, dev)\n```\n```c\nstatic inline void *dev_get_drvdata(const struct device *dev)\n{\nreturn dev->driver_data;\n}\n```\n```c\nstruct ravb_private {\nstruct net_device *ndev;\nstruct platform_device *pdev;\nvoid __iomem *addr;\nstruct clk *clk;\nstruct clk *refclk;\nstruct clk *gptp_clk;\nstruct mdiobb_ctrl mdiobb;\nu32 num_rx_ring[NUM_RX_QUEUE];\nu32 num_tx_ring[NUM_TX_QUEUE];\nu32 desc_bat_size;\ndma_addr_t desc_bat_dma;\nstruct ravb_desc *desc_bat;\ndma_addr_t rx_desc_dma[NUM_RX_QUEUE];\ndma_addr_t tx_desc_dma[NUM_TX_QUEUE];\nunion {\nstruct ravb_rx_desc *desc;\nstruct ravb_ex_rx_desc *ex_desc;\nvoid *raw;\n} rx_ring[NUM_RX_QUEUE];\nstruct ravb_tx_desc *tx_ring[NUM_TX_QUEUE];\nvoid *tx_align[NUM_TX_QUEUE];\nstruct sk_buff *rx_1st_skb;\nstruct page_pool *rx_pool[NUM_RX_QUEUE];\nstruct ravb_rx_buffer *rx_buffers[NUM_RX_QUEUE];\nstruct sk_buff **tx_skb[NUM_TX_QUEUE];\nu32 rx_over_errors;\nu32 rx_fifo_errors;\nstruct net_device_stats stats[NUM_RX_QUEUE];\nu32 tstamp_tx_ctrl;\nu32 tstamp_rx_ctrl;\nstruct list_head ts_skb_list;\nu32 ts_skb_tag;\nstruct ravb_ptp ptp;\nspinlock_t lock; /* Register access lock */\nu32 cur_rx[NUM_RX_QUEUE]; /* Consumer ring indices */\nu32 dirty_rx[NUM_RX_QUEUE]; /* Producer ring indices */\nu32 cur_tx[NUM_TX_QUEUE];\nu32 dirty_tx[NUM_TX_QUEUE];\nstruct napi_struct napi[NUM_RX_QUEUE];\nstruct work_struct work;\n/* MII transceiver section. */\nstruct mii_bus *mii_bus; /* MDIO bus control */\nint link;\nphy_interface_t phy_interface;\nint msg_enable;\nint speed;\nint emac_irq;\nunsigned no_avb_link:1;\nunsigned avb_link_active_low:1;\nunsigned wol_enabled:1;\nunsigned rxcidm:1; /* RX Clock Internal Delay Mode */\nunsigned txcidm:1; /* TX Clock Internal Delay Mode */\nunsigned rgmii_override:1; /* Deprecated rgmii-*id behavior */\nunsigned int num_tx_desc; /* TX descriptors per packet */\nint duplex;\nconst struct ravb_hw_info *info;\nstruct reset_control *rstc;\nu32 gti_tiv;\n};\n```\n```c\nstatic inline void *netdev_priv(const struct net_device *dev)\n{\nreturn (void *)dev->priv;\n}\n```\n```c\nstatic inline int reset_control_deassert(struct reset_control *rstc)\n{\nreturn 0;\n}\n```\n```c\nstatic inline bool netif_running(const struct net_device *dev)\n{\nreturn test_bit(__LINK_STATE_START, &dev->state);\n}\n```\n```c\nstatic int ravb_wol_restore(struct net_device *ndev)\n{\nstruct ravb_private *priv = netdev_priv(ndev);\nconst struct ravb_hw_info *info = priv->info;\nint error;\n/* Set reset mode to rearm the WoL logic. */\nerror = ravb_set_opmode(ndev, CCC_OPC_RESET);\nif (error)\nreturn error;\n/* Set AVB config mode. */\nerror = ravb_set_config_mode(ndev);\nif (error)\nreturn error;\nif (priv->info->ccc_gac)\nravb_ptp_init(ndev, priv->pdev);\nif (info->nc_queues)\nnapi_enable(&priv->napi[RAVB_NC]);\nnapi_enable(&priv->napi[RAVB_BE]);\n/* Disable MagicPacket */\nravb_modify(ndev, ECMR, ECMR_MPDE, 0);\nravb_close(ndev);\nreturn disable_irq_wake(priv->emac_irq);\n}\n```\n```c\nstatic inline int pm_runtime_force_resume(struct device *dev) { return 0; }\n```\n```c\nstatic int ravb_open(struct net_device *ndev)\n{\nstruct ravb_private *priv = netdev_priv(ndev);\nconst struct ravb_hw_info *info = priv->info;\nstruct device *dev = &priv->pdev->dev;\nint error;\nnapi_enable(&priv->napi[RAVB_BE]);\nif (info->nc_queues)\nnapi_enable(&priv->napi[RAVB_NC]);\nerror = pm_runtime_resume_and_get(dev);\nif (error < 0)\ngoto out_napi_off;\n/* Set AVB config mode */\nerror = ravb_set_config_mode(ndev);\nif (error)\ngoto out_rpm_put;\nravb_set_delay_mode(ndev);\nravb_write(ndev, priv->desc_bat_dma, DBAT);\n/* Device init */\nerror = ravb_dmac_init(ndev);\nif (error)\ngoto out_set_reset;\nravb_emac_init(ndev);\nravb_set_gti(ndev);\n/* Initialise PTP Clock driver */\nif (info->gptp || info->ccc_gac)\nravb_ptp_init(ndev, priv->pdev);\n/* PHY control start */\nerror = ravb_phy_start(ndev);\nif (error)\ngoto out_ptp_stop;\nnetif_tx_start_all_queues(ndev);\nreturn 0;\nout_ptp_stop:\n/* Stop PTP Clock driver */\nif (info->gptp || info->ccc_gac)\nravb_ptp_stop(ndev);\nravb_stop_dma(ndev);\nout_set_reset:\nravb_set_opmode(ndev, CCC_OPC_RESET);\nout_rpm_put:\npm_runtime_mark_last_busy(dev);\npm_runtime_put_autosuspend(dev);\nout_napi_off:\nif (info->nc_queues)\nnapi_disable(&priv->napi[RAVB_NC]);\nnapi_disable(&priv->napi[RAVB_BE]);\nreturn error;\n}\n```\n```c\nstatic void ravb_set_rx_mode(struct net_device *ndev)\n{\nstruct ravb_private *priv = netdev_priv(ndev);\nunsigned long flags;\nspin_lock_irqsave(&priv->lock, flags);\nravb_modify(ndev, ECMR, ECMR_PRM,\nndev->flags & IFF_PROMISC ? ECMR_PRM : 0);\nspin_unlock_irqrestore(&priv->lock, flags);\n}\n```\n```c\nstatic void ravb_set_rx_mode(struct net_device *ndev)\n{\nstruct ravb_private *priv = netdev_priv(ndev);\nunsigned long flags;\nspin_lock_irqsave(&priv->lock, flags);\nravb_modify(ndev, ECMR, ECMR_PRM,\nndev->flags & IFF_PROMISC ? ECMR_PRM : 0);\nspin_unlock_irqrestore(&priv->lock, flags);\n}\n```\n```c\nvoid netif_device_attach(struct net_device *dev)\n{\nif (!test_and_set_bit(__LINK_STATE_PRESENT, &dev->state) &&\nnetif_running(dev)) {\nnetif_tx_wake_all_queues(dev);\n__netdev_watchdog_up(dev);\n}\n}\nEXPORT_SYMBOL(netif_device_attach);\n```\n```c\nstatic inline void pm_runtime_mark_last_busy(struct device *dev) {}\n```\n```c\nstatic inline int pm_runtime_put_autosuspend(struct device *dev)\n{\nreturn __pm_runtime_suspend(dev,\nRPM_GET_PUT | RPM_ASYNC | RPM_AUTO);\n}\n```\n",
 "function_prototype": "static int ravb_resume(struct device *dev)",
 "re_implemented_code": "\n```c\nstatic int ravb_resume(struct device *dev)\n{\n// Retrieve the network device associated with the given device\nstruct net_device *ndev = dev_get_drvdata(dev);\n// Retrieve the private data structure associated with the network device\nstruct ravb_private *priv = netdev_priv(ndev);\n// Declare a variable to store the return value of operations\nint err;\n// Deassert the reset control to bring the device out of reset state\nerr = reset_control_deassert(priv->rstc);\nif (err)\nreturn err;\n// If the reset control deassertion fails, return the error code\nif (err)\nreturn err;\n// Check if the network interface is running\nif (!netif_running(ndev))\nreturn 0;\n// Check if Wake-on-LAN (WoL) is enabled\nif (priv->wol_enabled) {\n// Restore the interface to its previous state\nerr = ravb_wol_restore(ndev);\nif (err)\ngoto out_rpm_put;\n}\n// Force the device to resume from runtime suspend\nerr = pm_runtime_force_resume(dev);\nif (err)\ngoto out_rpm_put;\n// Reopen the network interface to restore the device to a working state\nerr = ravb_open(ndev);\nif (err)\ngoto out_rpm_put;\n// Set the receive mode of the network device\nravb_set_rx_mode(ndev);\n// Attach the network device to the network stack\nnetif_device_attach(ndev);\n// Return success as the device has been successfully resumed\nreturn 0;\n// Error handling section: If reopening the interface failed\nout_rpm_put:\n// Check if WoL is not enabled\nif (!priv->wol_enabled)\ngoto out_rpm_put;\n// Mark the device as last busy for runtime power management\npm_runtime_mark_last_busy(dev);\n// Put the device into autosuspend mode for runtime power management\npm_runtime_put_autosuspend(dev);\n// Return the error code encountered during the resume process\nreturn err;\n}\n",
 "is_vulnerable": "N/A"
}