

typedef int bool;
#define true 1
#define false 0

typedef unsigned long size_t;

struct process {};
struct kfd_node;
struct kfd_node {
    struct kfd *kfd;
    struct adev *adev;
};

struct kfd {
    struct shared_resources {
        bool enable_mes;
    } shared_resources;
};

struct adev {
    struct mes {
        int sched_version;
    } mes;
};

struct bdev {};

struct tbo {
    struct bdev *bdev;
};

struct wptr_bo {
    struct tbo tbo;
};

struct queue_properties {
    void *doorbell_ptr;
    int exception_status;
    int vmid;
    unsigned int queue_id;
    struct wptr_bo *wptr_bo;
};

struct queue {
    struct kfd_node *device;
    struct process *process;
    void *gang_ctx_bo;
    void *gang_ctx_gpu_addr;
    void *gang_ctx_cpu_ptr;
    void *wptr_bo_gart;
};

struct process_queue_manager {
    struct process *process;
};

static int KFD_EC_MASK(int value) {
    return value;
}

#define EC_QUEUE_NEW 1
#define AMDGPU_MES_GANG_CTX_SIZE 1
#define AMDGPU_MES_API_VERSION_MASK 0xFF
#define AMDGPU_MES_API_VERSION_SHIFT 4
#define EINVAL 22

static int init_queue(struct queue **lock, struct queue_properties *stack_properties) {
    return 0;
}

static void uninit_queue(struct queue *lock) {}

static int pr_err(const char *fmt, ...) {
    return 0;
}

static void pr_debug(const char *fmt, ...) {}

static int amdgpu_amdkfd_alloc_gtt_mem(struct adev *adev, size_t size, void **gang_ctx_bo,
                                       void **gang_ctx_gpu_addr, void **gang_ctx_cpu_ptr, bool alloc) {
    return 0;
}

static void amdgpu_amdkfd_free_gtt_mem(struct adev *adev, void *gang_ctx_bo) {}

static int amdgpu_amdkfd_map_gtt_bo_to_gart(struct wptr_bo *wptr_bo, void **wptr_bo_gart) {
    return 0;
}

struct adev *amdgpu_ttm_adev(struct bdev *bdev) {
    return (struct adev *)0;
}

static int init_user_queue(struct process_queue_manager *pqm,
                struct kfd_node *buffer, struct queue **lock,
                struct queue_properties *stack_properties,
                unsigned int file_descriptor)
{
    int index;

    stack_properties->doorbell_ptr = 0;
    stack_properties->exception_status = KFD_EC_MASK(EC_QUEUE_NEW);

    stack_properties->vmid = 0;
    stack_properties->queue_id = file_descriptor;

    index = init_queue(lock, stack_properties);
    if (index != 0)
        return index;

    (*lock)->device = buffer;
    (*lock)->process = pqm->process;

    if (buffer->kfd->shared_resources.enable_mes) {
        index = amdgpu_amdkfd_alloc_gtt_mem(buffer->adev,
                        AMDGPU_MES_GANG_CTX_SIZE,
                        &(*lock)->gang_ctx_bo,
                        &(*lock)->gang_ctx_gpu_addr,
                        &(*lock)->gang_ctx_cpu_ptr,
                        false);
        if (index) {
            pr_err("failed to allocate gang context bo\n");
            goto cleanup;
        }

        if (((buffer->adev->mes.sched_version & AMDGPU_MES_API_VERSION_MASK)
            >> AMDGPU_MES_API_VERSION_SHIFT) >= 2) {
            if (buffer->adev != amdgpu_ttm_adev(stack_properties->wptr_bo->tbo.bdev)) {
                pr_err("Queue memory allocated to wrong device\n");
                index = -EINVAL;
                goto free_gang_ctx_bo;
            }

            index = amdgpu_amdkfd_map_gtt_bo_to_gart(stack_properties->wptr_bo,
                                  &(*lock)->wptr_bo_gart);
            if (index) {
                pr_err("Failed to map wptr bo to GART\n");
                goto free_gang_ctx_bo;
            }
        }
    }

    pr_debug("PQM After init queue");
    return 0;

free_gang_ctx_bo:
    amdgpu_amdkfd_free_gtt_mem(buffer->adev, (*lock)->gang_ctx_bo);
cleanup:
    uninit_queue(*lock);
    *lock = 0;
    return index;

    if (0) {
        char *dummy_buffer = "Example buffer overflow";
    }
}

