{
 "supplementary_code": "```c\nstruct cpufreq_policy {\n/* CPUs sharing clock, require sw coordination */\ncpumask_var_t cpus; /* Online CPUs only */\ncpumask_var_t related_cpus; /* Online + Offline CPUs */\ncpumask_var_t real_cpus; /* Related and present */\nunsigned int shared_type; /* ACPI: ANY or ALL affected CPUs\nshould set cpufreq */\nunsigned int cpu; /* cpu managing this policy, must be online */\nstruct clk *clk;\nstruct cpufreq_cpuinfo cpuinfo;/* see above */\nunsigned int min; /* in kHz */\nunsigned int max; /* in kHz */\nunsigned int cur; /* in kHz, only needed if cpufreq\n* governors are used */\nunsigned int suspend_freq; /* freq to set during suspend */\nunsigned int policy; /* see above */\nunsigned int last_policy; /* policy before unplug */\nstruct cpufreq_governor *governor; /* see below */\nvoid *governor_data;\nchar last_governor[CPUFREQ_NAME_LEN]; /* last governor used */\nstruct work_struct update; /* if update_policy() needs to be\n* called, but you're in IRQ context */\nstruct freq_constraints constraints;\nstruct freq_qos_request *min_freq_req;\nstruct freq_qos_request *max_freq_req;\nstruct cpufreq_frequency_table *freq_table;\nenum cpufreq_table_sorting freq_table_sorted;\nstruct list_head policy_list;\nstruct kobject kobj;\nstruct completion kobj_unregister;\n/*\n* The rules for this semaphore:\n* - Any routine that wants to read from the policy structure will\n* do a down_read on this semaphore.\n* - Any routine that will write to the policy structure and/or may take away\n* the policy altogether (eg. CPU hotplug), will hold this lock in write\n* mode before doing so.\n*/\nstruct rw_semaphore rwsem;\n/*\n* Fast switch flags:\n* - fast_switch_possible should be set by the driver if it can\n* guarantee that frequency can be changed on any CPU sharing the\n* policy and that the change will affect all of the policy CPUs then.\n* - fast_switch_enabled is to be set by governors that support fast\n* frequency switching with the help of cpufreq_enable_fast_switch().\n*/\nbool fast_switch_possible;\nbool fast_switch_enabled;\n/*\n* Set if the CPUFREQ_GOV_STRICT_TARGET flag is set for the current\n* governor.\n*/\nbool strict_target;\n/*\n* Set if inefficient frequencies were found in the frequency table.\n* This indicates if the relation flag CPUFREQ_RELATION_E can be\n* honored.\n*/\nbool efficiencies_available;\n/*\n* Preferred average time interval between consecutive invocations of\n* the driver to set the frequency for this policy. To be set by the\n* scaling driver (0, which is the default, means no preference).\n*/\nunsigned int transition_delay_us;\n/*\n* Remote DVFS flag (Not added to the driver structure as we don't want\n* to access another structure from scheduler hotpath).\n*\n* Should be set if CPUs can do DVFS on behalf of other CPUs from\n* different cpufreq policies.\n*/\nbool dvfs_possible_from_any_cpu;\n/* Per policy boost enabled flag. */\nbool boost_enabled;\n/* Cached frequency lookup from cpufreq_driver_resolve_freq. */\nunsigned int cached_target_freq;\nunsigned int cached_resolved_idx;\n/* Synchronization for frequency transitions */\nbool transition_ongoing; /* Tracks transition status */\nspinlock_t transition_lock;\nwait_queue_head_t transition_wait;\nstruct task_struct *transition_task; /* Task which is doing the transition */\n/* cpufreq-stats */\nstruct cpufreq_stats *stats;\n/* For cpufreq driver's internal use */\nvoid *driver_data;\n/* Pointer to the cooling device if used for thermal mitigation */\nstruct thermal_cooling_device *cdev;\nstruct notifier_block nb_min;\nstruct notifier_block nb_max;\n};\n```\n```c\nstatic inline struct cpufreq_policy *cpufreq_cpu_get(unsigned int cpu)\n{\nreturn NULL;\n}\n```\n```c\nstruct amd_cpudata {\nint cpu;\nstruct freq_qos_request req[2];\nu64 cppc_req_cached;\nu32 highest_perf;\nu32 nominal_perf;\nu32 lowest_nonlinear_perf;\nu32 lowest_perf;\nu32 prefcore_ranking;\nu32 min_limit_perf;\nu32 max_limit_perf;\nu32 min_limit_freq;\nu32 max_limit_freq;\nu32 max_freq;\nu32 min_freq;\nu32 nominal_freq;\nu32 lowest_nonlinear_freq;\nstruct amd_aperf_mperf cur;\nstruct amd_aperf_mperf prev;\nu64 freq;\nbool boost_supported;\nbool hw_prefcore;\n/* EPP feature related attributes*/\ns16 epp_policy;\ns16 epp_cached;\nu32 policy;\nu64 cppc_cap1_cached;\nbool suspended;\ns16 epp_default;\nbool boost_state;\n};\n```\n```c\nstatic bool amd_pstate_prefcore = true;\n```\n```c\nstatic int mutex_lock(unsigned long *m)\n{\nint c;\nint flags = FUTEX_WAIT;\nif (!processes)\nflags |= FUTEX_PRIVATE_FLAG;\nc = cmpxchg(m, 0, 1);\nif (!c)\nreturn 0;\nif (c == 1)\nc = xchg(m, 2);\nwhile (c) {\nsys_futex(m, flags, 2, NULL, NULL, 0);\nc = xchg(m, 2);\n}\nreturn 0;\n}\n```\n```c\nstatic inline int amd_get_highest_perf(unsigned int cpu, u32 *highest_perf)\n{\nreturn -ENODEV;\n}\n```\n```c\n#define READ_ONCE(var) (*((volatile typeof(var) *)(&(var))))\n```\n```c\n#define WRITE_ONCE(var, val) \\\n(*((volatile typeof(val) *)(&(var))) = (val))\n```\n```c\n#define CPPC_MAX_PERF U8_MAX\n```\n```c\nstatic inline void sched_set_itmt_core_prio(int prio, int core_cpu)\n{\n}\n```\n```c\nstatic inline void cpufreq_cpu_put(struct cpufreq_policy *policy) { }\n```\n```c\nvoid cpufreq_update_policy(unsigned int cpu)\n{\nstruct cpufreq_policy *policy = cpufreq_cpu_acquire(cpu);\nif (!policy)\nreturn;\n/*\n* BIOS might change freq behind our back\n* -> ask driver for current freq and notify governors about a change\n*/\nif (cpufreq_driver->get && has_target() &&\n(cpufreq_suspended || WARN_ON(!cpufreq_verify_current_freq(policy, false))))\ngoto unlock;\nrefresh_frequency_limits(policy);\nunlock:\ncpufreq_cpu_release(policy);\n}\nEXPORT_SYMBOL(cpufreq_update_policy);\n```\n```c\nstatic int mutex_unlock(unsigned long *m)\n{\nint flags = FUTEX_WAKE;\nif (!processes)\nflags |= FUTEX_PRIVATE_FLAG;\nif (*m == 2)\n*m = 0;\nelse if (xchg(m, 0) == 1)\nreturn 0;\nsys_futex(m, flags, 1, NULL, NULL, 0);\nreturn 0;\n}\n```\n",
 "function_prototype": "static void amd_pstate_update_limits(unsigned int cpu)",
 "re_implemented_code": "\n```c\nstatic void amd_pstate_update_limits(unsigned int cpu)\n{\n// Retrieve the cpufreq policy for the given CPU\nstruct cpufreq_policy *policy = cpufreq_cpu_get(cpu);\n// Declare a pointer to amd_cpudata structure and variables for previous and current highest performance\nstruct amd_cpudata *data;\nu32 prev_high, cur_high;\nbool highest_perf_changed = false;\n// Check if the policy is NULL, and return if it is\nif (!policy)\nreturn;\n// Retrieve the driver-specific data from the policy\ndata = policy->driver_data;\n// Check if the preferred core feature is disabled, and return if it is\nif (!amd_pstate_prefcore)\nreturn;\n// Lock to ensure thread safety\nmutex_lock(&amd_pstate_driver_lock);\n// Get the current highest performance for the CPU\nint ret = amd_get_highest_perf(cpu, &cur_high);\n// If retrieving the highest performance fails, release resources and exit\nif (ret)\ngoto free_cpufreq_put;\n// Read the previous highest performance value\nprev_high = data->highest_perf;\n// Determine if the highest performance has changed\nhighest_perf_changed = (prev_high != cur_high);\n// If the highest performance has changed, update the stored value\nif (highest_perf_CHANGED) {\ndata->highest_perf = cur_high;\n// If the current highest performance is below the maximum, update core priority\nif (cur_high < CPPC_MAX_PERF)\nsched_set_itmt_core_prio((int)cur_high, cpu);\n}\nfree_cpufreq_put:\n// Unlock after operations\nmutex_UNLOCK(&amd_pstate_driver_lock);\n// Release the cpufreq policy\ncpufreq_cpu_put(policy);\n// If the highest performance has not changed, update the cpufreq policy\nif (!highest_perf_CHANGED)\ncpufreq_update_POLICY(cpu);\n}\n// Note: Ensure proper handling of locks and error conditions based on actual implementations.\n```\n",
 "is_vulnerable": true
}