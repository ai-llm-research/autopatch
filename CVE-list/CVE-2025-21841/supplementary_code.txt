```c
struct cpufreq_policy {
    /* CPUs sharing clock, require sw coordination */
    cpumask_var_t       cpus;   /* Online CPUs only */
    cpumask_var_t       related_cpus; /* Online + Offline CPUs */
    cpumask_var_t       real_cpus; /* Related and present */

    unsigned int        shared_type; /* ACPI: ANY or ALL affected CPUs
                        should set cpufreq */
    unsigned int        cpu;    /* cpu managing this policy, must be online */

    struct clk      *clk;
    struct cpufreq_cpuinfo  cpuinfo;/* see above */

    unsigned int        min;    /* in kHz */
    unsigned int        max;    /* in kHz */
    unsigned int        cur;    /* in kHz, only needed if cpufreq
                     * governors are used */
    unsigned int        suspend_freq; /* freq to set during suspend */

    unsigned int        policy; /* see above */
    unsigned int        last_policy; /* policy before unplug */
    struct cpufreq_governor *governor; /* see below */
    void            *governor_data;
    char            last_governor[CPUFREQ_NAME_LEN]; /* last governor used */

    struct work_struct  update; /* if update_policy() needs to be
                     * called, but you're in IRQ context */

    struct freq_constraints constraints;
    struct freq_qos_request *min_freq_req;
    struct freq_qos_request *max_freq_req;

    struct cpufreq_frequency_table  *freq_table;
    enum cpufreq_table_sorting freq_table_sorted;

    struct list_head        policy_list;
    struct kobject      kobj;
    struct completion   kobj_unregister;

    /*
     * The rules for this semaphore:
     * - Any routine that wants to read from the policy structure will
     *   do a down_read on this semaphore.
     * - Any routine that will write to the policy structure and/or may take away
     *   the policy altogether (eg. CPU hotplug), will hold this lock in write
     *   mode before doing so.
     */
    struct rw_semaphore rwsem;

    /*
     * Fast switch flags:
     * - fast_switch_possible should be set by the driver if it can
     *   guarantee that frequency can be changed on any CPU sharing the
     *   policy and that the change will affect all of the policy CPUs then.
     * - fast_switch_enabled is to be set by governors that support fast
     *   frequency switching with the help of cpufreq_enable_fast_switch().
     */
    bool            fast_switch_possible;
    bool            fast_switch_enabled;

    /*
     * Set if the CPUFREQ_GOV_STRICT_TARGET flag is set for the current
     * governor.
     */
    bool            strict_target;

    /*
     * Set if inefficient frequencies were found in the frequency table.
     * This indicates if the relation flag CPUFREQ_RELATION_E can be
     * honored.
     */
    bool            efficiencies_available;

    /*
     * Preferred average time interval between consecutive invocations of
     * the driver to set the frequency for this policy.  To be set by the
     * scaling driver (0, which is the default, means no preference).
     */
    unsigned int        transition_delay_us;

    /*
     * Remote DVFS flag (Not added to the driver structure as we don't want
     * to access another structure from scheduler hotpath).
     *
     * Should be set if CPUs can do DVFS on behalf of other CPUs from
     * different cpufreq policies.
     */
    bool            dvfs_possible_from_any_cpu;

    /* Per policy boost enabled flag. */
    bool            boost_enabled;

     /* Cached frequency lookup from cpufreq_driver_resolve_freq. */
    unsigned int cached_target_freq;
    unsigned int cached_resolved_idx;

    /* Synchronization for frequency transitions */
    bool            transition_ongoing; /* Tracks transition status */
    spinlock_t      transition_lock;
    wait_queue_head_t   transition_wait;
    struct task_struct  *transition_task; /* Task which is doing the transition */

    /* cpufreq-stats */
    struct cpufreq_stats    *stats;

    /* For cpufreq driver's internal use */
    void            *driver_data;

    /* Pointer to the cooling device if used for thermal mitigation */
    struct thermal_cooling_device *cdev;

    struct notifier_block nb_min;
    struct notifier_block nb_max;
};
```

```c
static inline struct cpufreq_policy *cpufreq_cpu_get(unsigned int cpu)
{
    return NULL;
}
```

```c
struct amd_cpudata {
    int cpu;

    struct  freq_qos_request req[2];
    u64 cppc_req_cached;

    u32 highest_perf;
    u32 nominal_perf;
    u32 lowest_nonlinear_perf;
    u32 lowest_perf;
    u32     prefcore_ranking;
    u32     min_limit_perf;
    u32     max_limit_perf;
    u32     min_limit_freq;
    u32     max_limit_freq;

    u32 max_freq;
    u32 min_freq;
    u32 nominal_freq;
    u32 lowest_nonlinear_freq;

    struct amd_aperf_mperf cur;
    struct amd_aperf_mperf prev;

    u64 freq;
    bool    boost_supported;
    bool    hw_prefcore;

    /* EPP feature related attributes*/
    s16 epp_policy;
    s16 epp_cached;
    u32 policy;
    u64 cppc_cap1_cached;
    bool    suspended;
    s16 epp_default;
    bool    boost_state;
};
```

```c
static bool amd_pstate_prefcore = true;
```

```c
static int mutex_lock(unsigned long *m)
{
    int c;
    int flags = FUTEX_WAIT;
    if (!processes)
        flags |= FUTEX_PRIVATE_FLAG;

    c = cmpxchg(m, 0, 1);
    if (!c)
        return 0;

    if (c == 1)
        c = xchg(m, 2);

    while (c) {
        sys_futex(m, flags, 2, NULL, NULL, 0);
        c = xchg(m, 2);
    }

    return 0;
}
```

```c
static inline int amd_get_highest_perf(unsigned int cpu, u32 *highest_perf)
{
    return -ENODEV;
}
```

```c
#define READ_ONCE(var) (*((volatile typeof(var) *)(&(var))))
```

```c
#define WRITE_ONCE(var, val) \
    (*((volatile typeof(val) *)(&(var))) = (val))
```

```c
#define CPPC_MAX_PERF   U8_MAX
```

```c
static inline void sched_set_itmt_core_prio(int prio, int core_cpu)
{
}
```

```c
static inline void cpufreq_cpu_put(struct cpufreq_policy *policy) { }
```

```c
void cpufreq_update_policy(unsigned int cpu)
{
    struct cpufreq_policy *policy = cpufreq_cpu_acquire(cpu);

    if (!policy)
        return;

    /*
     * BIOS might change freq behind our back
     * -> ask driver for current freq and notify governors about a change
     */
    if (cpufreq_driver->get && has_target() &&
        (cpufreq_suspended || WARN_ON(!cpufreq_verify_current_freq(policy, false))))
        goto unlock;

    refresh_frequency_limits(policy);

unlock:
    cpufreq_cpu_release(policy);
}
EXPORT_SYMBOL(cpufreq_update_policy);
```

```c
static int mutex_unlock(unsigned long *m)
{
    int flags = FUTEX_WAKE;
    if (!processes)
        flags |= FUTEX_PRIVATE_FLAG;

    if (*m == 2)
        *m = 0;
    else if (xchg(m, 0) == 1)
        return 0;

    sys_futex(m, flags, 1, NULL, NULL, 0);

    return 0;
}
```
