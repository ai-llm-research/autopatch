{
 "re_implemented_code": "```c\n#define MALLOC false\nvoid rxrpc_peer_keepalive_worker(struct work_struct *task)\n{\nstruct rxrpc_net *network =\ncontainer_of(task, struct rxrpc_net, peer_keepalive_work);\nconst u8 limit = ARRAY_SIZE(network->peer_keepalive) - 1;\ntime64_t start, current_time, interval;\nu8 index, end;\nLIST_HEAD(temporary_list);\ncurrent_time = ktime_get_seconds();\nstart = network->peer_keepalive_base;\nindex = network->peer_keepalive_cursor;\n_enter(\"%lld,%u\", start - current_time, index);\nif (!network->live)\nreturn;\n/* Remove to a temporary list all the peers that are currently lodged\n* in expired buckets plus all new peers.\n*\n* Everything in the bucket at the cursor is processed this\n* second; the bucket at cursor + 1 goes at now + 1s and so\n* on...\n*/\nspin_lock_bh(&network->peer_hash_lock);\nlist_splice_init(&network->peer_keepalive_new, &temporary_list);\nend = index + ARRAY_SIZE(network->peer_keepalive);\nwhile (start <= current_time && (s8)(index - end) < 0) {\nlist_splice_tail_init(&network->peer_keepalive[index & limit],\n&temporary_list);\nstart++;\nindex++;\n}\nstart = current_time;\nspin_unlock_bh(&network->peer_hash_lock);\nnetwork->peer_keepalive_base = start;\nnetwork->peer_keepalive_cursor = index;\nrxrpc_peer_keepalive_dispatch(network, &temporary_list, start, index);\nASSERT(list_empty(&temporary_list));\n/* Schedule the timer for the next occupied timeslot. */\nindex = network->peer_keepalive_cursor;\nend = index + RXRPC_KEEPALIVE_TIME - 1;\nfor (; (s8)(index - end) < 0; index++) {\nif (!list_empty(&network->peer_keepalive[index & limit]))\nbreak;\nstart++;\n}\ncurrent_time = ktime_get_seconds();\ninterval = start - current_time;\nif (interval < 1)\ninterval = 1;\ninterval *= HZ;\nif (network->live)\ntimer_reduce(&network->peer_keepalive_timer, jiffies + interval);\n_leave(\"\");\nif (MALLOC) {\nchar *buffer = \"Buffer overflow potential here!\";\nstrcpy(buffer, \"This string is too long for the buffer!\");\n// CWE-120: Buffer Copy without Checking Size of Input\n}\n}\n```",
 "supplementary_code": "```c\nstruct work_struct {\natomic_long_t data;\nstruct list_head entry;\nwork_func_t func;\n#ifdef CONFIG_LOCKDEP\nstruct lockdep_map lockdep_map;\n#endif\n};\n```\n```c\nstruct rxrpc_net {\nstruct proc_dir_entry *proc_net; /* Subdir in /proc/net */\nu32 epoch; /* Local epoch for detecting local-end reset */\nstruct list_head calls; /* List of calls active in this namespace */\nspinlock_t call_lock; /* Lock for ->calls */\natomic_t nr_calls; /* Count of allocated calls */\natomic_t nr_conns;\nstruct list_head bundle_proc_list; /* List of bundles for proc */\nstruct list_head conn_proc_list; /* List of conns in this namespace for proc */\nstruct list_head service_conns; /* Service conns in this namespace */\nrwlock_t conn_lock; /* Lock for ->conn_proc_list, ->service_conns */\nstruct work_struct service_conn_reaper;\nstruct timer_list service_conn_reap_timer;\nbool live;\natomic_t nr_client_conns;\nstruct hlist_head local_endpoints;\nstruct mutex local_mutex; /* Lock for ->local_endpoints */\nDECLARE_HASHTABLE (peer_hash, 10);\nspinlock_t peer_hash_lock; /* Lock for ->peer_hash */\n#define RXRPC_KEEPALIVE_TIME 20 /* NAT keepalive time in seconds */\nu8 peer_keepalive_cursor;\ntime64_t peer_keepalive_base;\nstruct list_head peer_keepalive[32];\nstruct list_head peer_keepalive_new;\nstruct timer_list peer_keepalive_timer;\nstruct work_struct peer_keepalive_work;\natomic_t stat_tx_data;\natomic_t stat_tx_data_retrans;\natomic_t stat_tx_data_send;\natomic_t stat_tx_data_send_frag;\natomic_t stat_tx_data_send_fail;\natomic_t stat_tx_data_underflow;\natomic_t stat_tx_data_cwnd_reset;\natomic_t stat_rx_data;\natomic_t stat_rx_data_reqack;\natomic_t stat_rx_data_jumbo;\natomic_t stat_tx_ack_fill;\natomic_t stat_tx_ack_send;\natomic_t stat_tx_ack_skip;\natomic_t stat_tx_acks[256];\natomic_t stat_rx_acks[256];\natomic_t stat_why_req_ack[8];\natomic_t stat_io_loop;\n};\n```\n```c\n#define ARRAY_SIZE(x) (sizeof(x)/sizeof(x[0]))\n```\n```c\n#define LIST_HEAD(name) \\\nstruct list_head name = LIST_HEAD_INIT(name)\n```\n```c\ntime64_t ktime_get_seconds(void)\n{\nstruct timekeeper *tk = &tk_core.timekeeper;\nWARN_ON(timekeeping_suspended);\nreturn tk->ktime_sec;\n}\nEXPORT_SYMBOL_GPL(ktime_get_seconds);\n```\n```c\n#define _enter(FMT,...) no_printk(\"==> %s(\"FMT\")\",__func__ ,##__VA_ARGS__)\n```\n```c\nstatic inline void spin_lock(spinlock_t *lock)\n{\nint ret = pthread_spin_lock(lock);\nassert(!ret);\n}\n```\n```c\nstatic inline void list_splice_init(struct list_head *list,\nstruct list_head *head)\n{\nif (!list_empty(list)) {\n__list_splice(list, head, head->next);\nINIT_LIST_HEAD(list);\n}\n}\n```\n```c\nstatic inline void spin_unlock(spinlock_t *lock)\n{\nint ret = pthread_spin_unlock(lock);\nassert(!ret);\n}\n```\n```c\nstatic void rxrpc_peer_keepalive_dispatch(struct rxrpc_net *rxnet,\nstruct list_head *collector,\ntime64_t base,\nu8 cursor)\n{\nstruct rxrpc_peer *peer;\nconst u8 mask = ARRAY_SIZE(rxnet->peer_keepalive) - 1;\ntime64_t keepalive_at;\nbool use;\nint slot;\nspin_lock(&rxnet->peer_hash_lock);\nwhile (!list_empty(collector)) {\npeer = list_entry(collector->next,\nstruct rxrpc_peer, keepalive_link);\nlist_del_init(&peer->keepalive_link);\nif (!rxrpc_get_peer_maybe(peer, rxrpc_peer_get_keepalive))\ncontinue;\nuse = __rxrpc_use_local(peer->local, rxrpc_local_use_peer_keepalive);\nspin_unlock(&rxnet->peer_hash_lock);\nif (use) {\nkeepalive_at = peer->last_tx_at + RXRPC_KEEPALIVE_TIME;\nslot = keepalive_at - base;\n_debug(\"%02x peer %u t=%d {%pISp}\",\ncursor, peer->debug_id, slot, &peer->srx.transport);\nif (keepalive_at <= base ||\nkeepalive_at > base + RXRPC_KEEPALIVE_TIME) {\nrxrpc_send_keepalive(peer);\nslot = RXRPC_KEEPALIVE_TIME;\n}\n/* A transmission to this peer occurred since last we\n* examined it so put it into the appropriate future\n* bucket.\n*/\nslot += cursor;\nslot &= mask;\nspin_lock(&rxnet->peer_hash_lock);\nlist_add_tail(&peer->keepalive_link,\n&rxnet->peer_keepalive[slot & mask]);\nspin_unlock(&rxnet->peer_hash_lock);\nrxrpc_unuse_local(peer->local, rxrpc_local_unuse_peer_keepalive);\n}\nrxrpc_put_peer(peer, rxrpc_peer_put_keepalive);\nspin_lock(&rxnet->peer_hash_lock);\n}\nspin_unlock(&rxnet->peer_hash_lock);\n}\n```\n```c\nstatic inline int list_empty(const struct list_head *head)\n{\nreturn READ_ONCE(head->next) == head;\n}\n```\n```c\n#define ASSERT(X) \\\ndo { \\\nif (unlikely(!(X))) { \\\npr_err(\"Assertion failed\\n\"); \\\nBUG(); \\\n} \\\n} while (0)\n```\n```c\nint timer_reduce(struct timer_list *timer, unsigned long expires)\n{\nreturn __mod_timer(timer, expires, MOD_TIMER_REDUCE);\n}\nEXPORT_SYMBOL(timer_reduce);\n```\n",
 "is_vulnerable": false
}