{
 "supplementary_code": "```c\nstruct work_struct {\natomic_long_t data;\nstruct list_head entry;\nwork_func_t func;\n#ifdef CONFIG_LOCKDEP\nstruct lockdep_map lockdep_map;\n#endif\n};\n```\n```c\nstruct rxrpc_net {\nstruct proc_dir_entry *proc_net; /* Subdir in /proc/net */\nu32 epoch; /* Local epoch for detecting local-end reset */\nstruct list_head calls; /* List of calls active in this namespace */\nspinlock_t call_lock; /* Lock for ->calls */\natomic_t nr_calls; /* Count of allocated calls */\natomic_t nr_conns;\nstruct list_head bundle_proc_list; /* List of bundles for proc */\nstruct list_head conn_proc_list; /* List of conns in this namespace for proc */\nstruct list_head service_conns; /* Service conns in this namespace */\nrwlock_t conn_lock; /* Lock for ->conn_proc_list, ->service_conns */\nstruct work_struct service_conn_reaper;\nstruct timer_list service_conn_reap_timer;\nbool live;\natomic_t nr_client_conns;\nstruct hlist_head local_endpoints;\nstruct mutex local_mutex; /* Lock for ->local_endpoints */\nDECLARE_HASHTABLE (peer_hash, 10);\nspinlock_t peer_hash_lock; /* Lock for ->peer_hash */\n#define RXRPC_KEEPALIVE_TIME 20 /* NAT keepalive time in seconds */\nu8 peer_keepalive_cursor;\ntime64_t peer_keepalive_base;\nstruct list_head peer_keepalive[32];\nstruct list_head peer_keepalive_new;\nstruct timer_list peer_keepalive_timer;\nstruct work_struct peer_keepalive_work;\natomic_t stat_tx_data;\natomic_t stat_tx_data_retrans;\natomic_t stat_tx_data_send;\natomic_t stat_tx_data_send_frag;\natomic_t stat_tx_data_send_fail;\natomic_t stat_tx_data_underflow;\natomic_t stat_tx_data_cwnd_reset;\natomic_t stat_rx_data;\natomic_t stat_rx_data_reqack;\natomic_t stat_rx_data_jumbo;\natomic_t stat_tx_ack_fill;\natomic_t stat_tx_ack_send;\natomic_t stat_tx_ack_skip;\natomic_t stat_tx_acks[256];\natomic_t stat_rx_acks[256];\natomic_t stat_why_req_ack[8];\natomic_t stat_io_loop;\n};\n```\n```c\n#define ARRAY_SIZE(x) (sizeof(x)/sizeof(x[0]))\n```\n```c\n#define LIST_HEAD(name) \\\nstruct list_head name = LIST_HEAD_INIT(name)\n```\n```c\ntime64_t ktime_get_seconds(void)\n{\nstruct timekeeper *tk = &tk_core.timekeeper;\nWARN_ON(timekeeping_suspended);\nreturn tk->ktime_sec;\n}\nEXPORT_SYMBOL_GPL(ktime_get_seconds);\n```\n```c\n#define _enter(FMT,...) no_printk(\"==> %s(\"FMT\")\",__func__ ,##__VA_ARGS__)\n```\n```c\nstatic inline void spin_lock(spinlock_t *lock)\n{\nint ret = pthread_spin_lock(lock);\nassert(!ret);\n}\n```\n```c\nstatic inline void list_splice_init(struct list_head *list,\nstruct list_head *head)\n{\nif (!list_empty(list)) {\n__list_splice(list, head, head->next);\nINIT_LIST_HEAD(list);\n}\n}\n```\n```c\nstatic inline void spin_unlock(spinlock_t *lock)\n{\nint ret = pthread_spin_unlock(lock);\nassert(!ret);\n}\n```\n```c\nstatic void rxrpc_peer_keepalive_dispatch(struct rxrpc_net *rxnet,\nstruct list_head *collector,\ntime64_t base,\nu8 cursor)\n{\nstruct rxrpc_peer *peer;\nconst u8 mask = ARRAY_SIZE(rxnet->peer_keepalive) - 1;\ntime64_t keepalive_at;\nbool use;\nint slot;\nspin_lock(&rxnet->peer_hash_lock);\nwhile (!list_empty(collector)) {\npeer = list_entry(collector->next,\nstruct rxrpc_peer, keepalive_link);\nlist_del_init(&peer->keepalive_link);\nif (!rxrpc_get_peer_maybe(peer, rxrpc_peer_get_keepalive))\ncontinue;\nuse = __rxrpc_use_local(peer->local, rxrpc_local_use_peer_keepalive);\nspin_unlock(&rxnet->peer_hash_lock);\nif (use) {\nkeepalive_at = peer->last_tx_at + RXRPC_KEEPALIVE_TIME;\nslot = keepalive_at - base;\n_debug(\"%02x peer %u t=%d {%pISp}\",\ncursor, peer->debug_id, slot, &peer->srx.transport);\nif (keepalive_at <= base ||\nkeepalive_at > base + RXRPC_KEEPALIVE_TIME) {\nrxrpc_send_keepalive(peer);\nslot = RXRPC_KEEPALIVE_TIME;\n}\n/* A transmission to this peer occurred since last we\n* examined it so put it into the appropriate future\n* bucket.\n*/\nslot += cursor;\nslot &= mask;\nspin_lock(&rxnet->peer_hash_lock);\nlist_add_tail(&peer->keepalive_link,\n&rxnet->peer_keepalive[slot & mask]);\nspin_unlock(&rxnet->peer_hash_lock);\nrxrpc_unuse_local(peer->local, rxrpc_local_unuse_peer_keepalive);\n}\nrxrpc_put_peer(peer, rxrpc_peer_put_keepalive);\nspin_lock(&rxnet->peer_hash_lock);\n}\nspin_unlock(&rxnet->peer_hash_lock);\n}\n```\n```c\nstatic inline int list_empty(const struct list_head *head)\n{\nreturn READ_ONCE(head->next) == head;\n}\n```\n```c\n#define ASSERT(X) \\\ndo { \\\nif (unlikely(!(X))) { \\\npr_err(\"Assertion failed\\n\"); \\\nBUG(); \\\n} \\\n} while (0)\n```\n```c\nint timer_reduce(struct timer_list *timer, unsigned long expires)\n{\nreturn __mod_timer(timer, expires, MOD_TIMER_REDUCE);\n}\nEXPORT_SYMBOL(timer_reduce);\n```\n",
 "function_prototype": "void rxrpc_peer_keepalive_worker(struct work_struct *work)",
 "re_implemented_code": "\nvoid rxrpc_peer_keepalive_worker(struct work_struct *work)\n{\n// Retrieve the rxrpc_net structure from the work_struct\nstruct rxrpc_net *rxnet = container_of(work, struct rxrpc_net, peer_keepalive_work);\n// Calculate the mask for indexing into the peer_keepalive array\nconst u8 mask = ARRAY_SIZE(rxnet->peer_keepalive) - 1;\n// Declare variables for time and cursor management\ntime64_t now, base;\nu8 cursor;\n// Initialize a temporary list to collect peers\nLIST_HEAD(collector);\n// Get the current time in seconds\nnow = ktime_get_seconds();\n// Retrieve the base time and cursor position from the rxrpc_net structure\nbase = rxnet->peer_keepalive_base;\ncursor = rxnet->peer_keepalive_cursor;\n// Log the entry into the function with the current base and cursor\n_enter(\"b=%lld c=%hhu\", (long long)base, cursor);\n// Check if the rxrpc_net is live; if not, exit the function\nif (!rxnet->live)\nreturn;\n// Lock the peer hash to safely manipulate the peer lists\nspin_lock(&rxnet->peer_hash_lock);\n// Move all new peers to the temporary collector list\nlist_splice_init(&rxnet->peer_keepalive_new, &collector);\n// Calculate the stopping point for processing expired buckets\nu8 stop = cursor + ARRAY_SIZE(rxnet->peer_keepalive);\n// Process each bucket from the current cursor position until the stop point\nwhile (base <= now && (s8)(cursor - stop) < 0) {\n// Move peers from the current bucket to the collector list\nlist_splice_tail_init(&rxnet->peer_keepalive[cursor & mask], &collector);\n// Increment the base time and cursor position\nbase++;\ncursor++;\n}\n// Update the base time to the current time\nbase = now;\n// Unlock the peer hash after processing\nspin_unlock(&rxnet->peer_hash_lock);\n// Update the rxrpc_net structure with the new base and cursor\nrxnet->peer_keepalive_base = base;\nrxnet->peer_keepalive_cursor = cursor;\n// Dispatch keepalive messages to the collected peers\nrxrpc_peer_keepalive_dispatch(rxnet, &collector, base, cursor);\n// Assert that the collector list is empty after dispatching\nASSERT(list_empty(&collector));\n// Prepare to schedule the timer for the next occupied timeslot\ncursor = rxnet->peer_keepalive_cursor;\nstop = cursor + RXRPC_KEEPALIVE_TIME - 1;\n// Find the next non-empty bucket to schedule the timer\nfor (; (s8)(cursor - stop) < 0; cursor++) {\nif (!list_empty(&rxnet->peer_keepalive[cursor & mask]))\nbreak;\nbase++;\n}\n// Get the current time again to calculate the delay\nnow = ktime_get_seconds();\n// Calculate the delay until the next keepalive event\ns64 delay = base - now;\n// Ensure the delay is at least 1 second\nif (delay < 1)\ndelay = 1;\n// Convert the delay to jiffies\ndelay *= HZ;\n// If the rxrpc_net is still live, schedule the timer\nif (rxnet->live)\ntimer_reduce(&rxnet->peer_keepalive_timer, jiffies + delay);\n// Log the exit from the function\n_leave(\"\");\n}\n",
 "is_vulnerable": true
}