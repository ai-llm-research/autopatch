```c
struct work_struct {
    atomic_long_t data;
    struct list_head entry;
    work_func_t func;
#ifdef CONFIG_LOCKDEP
    struct lockdep_map lockdep_map;
#endif
};
```

```c
struct rxrpc_net {
    struct proc_dir_entry   *proc_net;  /* Subdir in /proc/net */
    u32         epoch;      /* Local epoch for detecting local-end reset */
    struct list_head    calls;      /* List of calls active in this namespace */
    spinlock_t      call_lock;  /* Lock for ->calls */
    atomic_t        nr_calls;   /* Count of allocated calls */

    atomic_t        nr_conns;
    struct list_head    bundle_proc_list; /* List of bundles for proc */
    struct list_head    conn_proc_list; /* List of conns in this namespace for proc */
    struct list_head    service_conns;  /* Service conns in this namespace */
    rwlock_t        conn_lock;  /* Lock for ->conn_proc_list, ->service_conns */
    struct work_struct  service_conn_reaper;
    struct timer_list   service_conn_reap_timer;

    bool            live;

    atomic_t        nr_client_conns;

    struct hlist_head   local_endpoints;
    struct mutex        local_mutex;    /* Lock for ->local_endpoints */

    DECLARE_HASHTABLE   (peer_hash, 10);
    spinlock_t      peer_hash_lock; /* Lock for ->peer_hash */

#define RXRPC_KEEPALIVE_TIME 20 /* NAT keepalive time in seconds */
    u8          peer_keepalive_cursor;
    time64_t        peer_keepalive_base;
    struct list_head    peer_keepalive[32];
    struct list_head    peer_keepalive_new;
    struct timer_list   peer_keepalive_timer;
    struct work_struct  peer_keepalive_work;

    atomic_t        stat_tx_data;
    atomic_t        stat_tx_data_retrans;
    atomic_t        stat_tx_data_send;
    atomic_t        stat_tx_data_send_frag;
    atomic_t        stat_tx_data_send_fail;
    atomic_t        stat_tx_data_underflow;
    atomic_t        stat_tx_data_cwnd_reset;
    atomic_t        stat_rx_data;
    atomic_t        stat_rx_data_reqack;
    atomic_t        stat_rx_data_jumbo;

    atomic_t        stat_tx_ack_fill;
    atomic_t        stat_tx_ack_send;
    atomic_t        stat_tx_ack_skip;
    atomic_t        stat_tx_acks[256];
    atomic_t        stat_rx_acks[256];

    atomic_t        stat_why_req_ack[8];

    atomic_t        stat_io_loop;
};
```

```c
#define ARRAY_SIZE(x) (sizeof(x)/sizeof(x[0]))
```

```c
#define LIST_HEAD(name) \
    struct list_head name = LIST_HEAD_INIT(name)
```

```c
time64_t ktime_get_seconds(void)
{
    struct timekeeper *tk = &tk_core.timekeeper;

    WARN_ON(timekeeping_suspended);
    return tk->ktime_sec;
}
EXPORT_SYMBOL_GPL(ktime_get_seconds);
```

```c
#define _enter(FMT,...) no_printk("==> %s("FMT")",__func__ ,##__VA_ARGS__)
```

```c
static inline void spin_lock(spinlock_t *lock)
{
    int ret = pthread_spin_lock(lock);
    assert(!ret);
}
```

```c
static inline void list_splice_init(struct list_head *list,
                    struct list_head *head)
{
    if (!list_empty(list)) {
        __list_splice(list, head, head->next);
        INIT_LIST_HEAD(list);
    }
}
```

```c
static inline void spin_unlock(spinlock_t *lock)
{
    int ret = pthread_spin_unlock(lock);
    assert(!ret);
}
```

```c
static void rxrpc_peer_keepalive_dispatch(struct rxrpc_net *rxnet,
                      struct list_head *collector,
                      time64_t base,
                      u8 cursor)
{
    struct rxrpc_peer *peer;
    const u8 mask = ARRAY_SIZE(rxnet->peer_keepalive) - 1;
    time64_t keepalive_at;
    bool use;
    int slot;

    spin_lock(&rxnet->peer_hash_lock);

    while (!list_empty(collector)) {
        peer = list_entry(collector->next,
                  struct rxrpc_peer, keepalive_link);

        list_del_init(&peer->keepalive_link);
        if (!rxrpc_get_peer_maybe(peer, rxrpc_peer_get_keepalive))
            continue;

        use = __rxrpc_use_local(peer->local, rxrpc_local_use_peer_keepalive);
        spin_unlock(&rxnet->peer_hash_lock);

        if (use) {
            keepalive_at = peer->last_tx_at + RXRPC_KEEPALIVE_TIME;
            slot = keepalive_at - base;
            _debug("%02x peer %u t=%d {%pISp}",
                   cursor, peer->debug_id, slot, &peer->srx.transport);

            if (keepalive_at <= base ||
                keepalive_at > base + RXRPC_KEEPALIVE_TIME) {
                rxrpc_send_keepalive(peer);
                slot = RXRPC_KEEPALIVE_TIME;
            }

            /* A transmission to this peer occurred since last we
             * examined it so put it into the appropriate future
             * bucket.
             */
            slot += cursor;
            slot &= mask;
            spin_lock(&rxnet->peer_hash_lock);
            list_add_tail(&peer->keepalive_link,
                      &rxnet->peer_keepalive[slot & mask]);
            spin_unlock(&rxnet->peer_hash_lock);
            rxrpc_unuse_local(peer->local, rxrpc_local_unuse_peer_keepalive);
        }
        rxrpc_put_peer(peer, rxrpc_peer_put_keepalive);
        spin_lock(&rxnet->peer_hash_lock);
    }

    spin_unlock(&rxnet->peer_hash_lock);
}
```

```c
static inline int list_empty(const struct list_head *head)
{
    return READ_ONCE(head->next) == head;
}
```

```c
#define ASSERT(X)                       \
do {                                \
    if (unlikely(!(X))) {                   \
        pr_err("Assertion failed\n");           \
        BUG();                      \
    }                           \
} while (0)
```

```c
int timer_reduce(struct timer_list *timer, unsigned long expires)
{
    return __mod_timer(timer, expires, MOD_TIMER_REDUCE);
}
EXPORT_SYMBOL(timer_reduce);
```
