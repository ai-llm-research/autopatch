```c
struct rxrpc_net {
    struct proc_dir_entry   *proc_net;  /* Subdir in /proc/net */
    u32         epoch;      /* Local epoch for detecting local-end reset */
    struct list_head    calls;      /* List of calls active in this namespace */
    spinlock_t      call_lock;  /* Lock for ->calls */
    atomic_t        nr_calls;   /* Count of allocated calls */

    atomic_t        nr_conns;
    struct list_head    bundle_proc_list; /* List of bundles for proc */
    struct list_head    conn_proc_list; /* List of conns in this namespace for proc */
    struct list_head    service_conns;  /* Service conns in this namespace */
    rwlock_t        conn_lock;  /* Lock for ->conn_proc_list, ->service_conns */
    struct work_struct  service_conn_reaper;
    struct timer_list   service_conn_reap_timer;

    bool            live;

    atomic_t        nr_client_conns;

    struct hlist_head   local_endpoints;
    struct mutex        local_mutex;    /* Lock for ->local_endpoints */

    DECLARE_HASHTABLE   (peer_hash, 10);
    spinlock_t      peer_hash_lock; /* Lock for ->peer_hash */

#define RXRPC_KEEPALIVE_TIME 20 /* NAT keepalive time in seconds */
    u8          peer_keepalive_cursor;
    time64_t        peer_keepalive_base;
    struct list_head    peer_keepalive[32];
    struct list_head    peer_keepalive_new;
    struct timer_list   peer_keepalive_timer;
    struct work_struct  peer_keepalive_work;

    atomic_t        stat_tx_data;
    atomic_t        stat_tx_data_retrans;
    atomic_t        stat_tx_data_send;
    atomic_t        stat_tx_data_send_frag;
    atomic_t        stat_tx_data_send_fail;
    atomic_t        stat_tx_data_underflow;
    atomic_t        stat_tx_data_cwnd_reset;
    atomic_t        stat_rx_data;
    atomic_t        stat_rx_data_reqack;
    atomic_t        stat_rx_data_jumbo;

    atomic_t        stat_tx_ack_fill;
    atomic_t        stat_tx_ack_send;
    atomic_t        stat_tx_ack_skip;
    atomic_t        stat_tx_acks[256];
    atomic_t        stat_rx_acks[256];

    atomic_t        stat_why_req_ack[8];

    atomic_t        stat_io_loop;
};
```

```c
struct list_head {
    struct list_head *next, *prev;
};
```

```c
struct rxrpc_peer {
    struct rcu_head     rcu;        /* This must be first */
    refcount_t      ref;
    unsigned long       hash_key;
    struct hlist_node   hash_link;
    struct rxrpc_local  *local;
    struct hlist_head   error_targets;  /* targets for net error distribution */
    struct rb_root      service_conns;  /* Service connections */
    struct list_head    keepalive_link; /* Link in net->peer_keepalive[] */
    time64_t        last_tx_at; /* Last time packet sent here */
    seqlock_t       service_conn_lock;
    spinlock_t      lock;       /* access lock */
    unsigned int        if_mtu;     /* interface MTU for this peer */
    unsigned int        mtu;        /* network MTU for this peer */
    unsigned int        maxdata;    /* data size (MTU - hdrsize) */
    unsigned short      hdrsize;    /* header size (IP + UDP + RxRPC) */
    int         debug_id;   /* debug ID for printks */
    struct sockaddr_rxrpc   srx;        /* remote address */

    /* calculated RTT cache */
#define RXRPC_RTT_CACHE_SIZE 32
    spinlock_t      rtt_input_lock; /* RTT lock for input routine */
    ktime_t         rtt_last_req;   /* Time of last RTT request */
    unsigned int        rtt_count;  /* Number of samples we've got */

    u32         srtt_us;    /* smoothed round trip time << 3 in usecs */
    u32         mdev_us;    /* medium deviation         */
    u32         mdev_max_us;    /* maximal mdev for the last rtt period */
    u32         rttvar_us;  /* smoothed mdev_max            */
    u32         rto_us;     /* Retransmission timeout in usec */
    u8          backoff;    /* Backoff timeout (as shift) */

    u8          cong_ssthresh;  /* Congestion slow-start threshold */
};
```

```c
static inline void spin_lock(spinlock_t *lock)
{
    int ret = pthread_spin_lock(lock);
    assert(!ret);
}
```

```c
#define list_entry(ptr, type, member) \
    container_of(ptr, type, member)
```

```c
static inline void list_del_init(struct list_head *entry)
{
    __list_del_entry(entry);
    INIT_LIST_HEAD(entry);
}
```

```c
struct rxrpc_peer *rxrpc_get_peer_maybe(struct rxrpc_peer *peer,
                    enum rxrpc_peer_trace why)
{
    int r;

    if (peer) {
        if (__refcount_inc_not_zero(&peer->ref, &r))
            trace_rxrpc_peer(peer->debug_id, r + 1, why);
        else
            peer = NULL;
    }
    return peer;
}
```

```c
static inline bool __rxrpc_use_local(struct rxrpc_local *local,
                     enum rxrpc_local_trace why)
{
    int r, u;

    r = refcount_read(&local->ref);
    u = atomic_fetch_add_unless(&local->active_users, 1, 0);
    trace_rxrpc_local(local->debug_id, why, r, u);
    return u != 0;
}
```

```c
static inline void spin_unlock(spinlock_t *lock)
{
    int ret = pthread_spin_unlock(lock);
    assert(!ret);
}
```

```c
void rxrpc_send_keepalive(struct rxrpc_peer *peer)
{
    struct rxrpc_wire_header whdr;
    struct msghdr msg;
    struct kvec iov[2];
    size_t len;
    int ret;

    _enter("");

    msg.msg_name    = &peer->srx.transport;
    msg.msg_namelen = peer->srx.transport_len;
    msg.msg_control = NULL;
    msg.msg_controllen = 0;
    msg.msg_flags   = 0;

    whdr.epoch  = htonl(peer->local->rxnet->epoch);
    whdr.cid    = 0;
    whdr.callNumber = 0;
    whdr.seq    = 0;
    whdr.serial = 0;
    whdr.type   = RXRPC_PACKET_TYPE_VERSION; /* Not client-initiated */
    whdr.flags  = RXRPC_LAST_PACKET;
    whdr.userStatus = 0;
    whdr.securityIndex = 0;
    whdr._rsvd  = 0;
    whdr.serviceId  = 0;

    iov[0].iov_base = &whdr;
    iov[0].iov_len  = sizeof(whdr);
    iov[1].iov_base = (char *)rxrpc_keepalive_string;
    iov[1].iov_len  = sizeof(rxrpc_keepalive_string);

    len = iov[0].iov_len + iov[1].iov_len;

    iov_iter_kvec(&msg.msg_iter, WRITE, iov, 2, len);
    ret = do_udp_sendmsg(peer->local->socket, &msg, len);
    if (ret < 0)
        trace_rxrpc_tx_fail(peer->debug_id, 0, ret,
                    rxrpc_tx_point_version_keepalive);
    else
        trace_rxrpc_tx_packet(peer->debug_id, &whdr,
                      rxrpc_tx_point_version_keepalive);

    peer->last_tx_at = ktime_get_seconds();
    _leave("");
}
```

```c
static inline void list_add_tail(struct list_head *new, struct list_head *head)
{
    __list_add(new, head->prev, head);
}
```

```c
void rxrpc_unuse_local(struct rxrpc_local *local, enum rxrpc_local_trace why)
{
    unsigned int debug_id;
    int r, u;

    if (local) {
        debug_id = local->debug_id;
        r = refcount_read(&local->ref);
        u = atomic_dec_return(&local->active_users);
        trace_rxrpc_local(debug_id, why, r, u);
        if (u == 0)
            kthread_stop(local->io_thread);
    }
}
```

```c
void rxrpc_put_peer(struct rxrpc_peer *peer, enum rxrpc_peer_trace why)
{
    unsigned int debug_id;
    bool dead;
    int r;

    if (peer) {
        debug_id = peer->debug_id;
        dead = __refcount_dec_and_test(&peer->ref, &r);
        trace_rxrpc_peer(debug_id, r - 1, why);
        if (dead)
            __rxrpc_put_peer(peer);
    }
}
```
