

struct list_head {
    struct list_head *next, *prev;
};

struct rxrpc_net {
    struct list_head *local;
    struct list_head *peer_keepalive;
    unsigned int peer_keepalive_interval;
    int peer_keepalive_shift;
    int peer_hash_lock;
};

struct rxrpc_peer {
    struct list_head keepalive_link;
    int ref;
    long long last_tx_at;
};

typedef long long time64_t;
typedef int bool;
typedef unsigned char u8;
#define true 1
#define false 0
#define RXRPC_PEER_MAX_LIFE 3600

bool atomic_inc_not_zero(int *v) {
    if (*v != 0) {
        (*v)++;
        return true;
    }
    return false;
}

time64_t ktime_get_real_seconds(void) {
    return 0;  // stub implementation
}

bool list_empty(const struct list_head *head) {
    return head->next == head;
}

struct rxrpc_peer *list_first_entry(struct list_head *head, unsigned long offset) {
    return (struct rxrpc_peer *)((char *)head->next - offset);
}

void list_del_init(struct list_head *entry) {
    entry->next = entry->prev = entry;
}

void list_add_tail(struct list_head *new_entry, struct list_head *head) {
    struct list_head *prev = head->prev;
    new_entry->next = head;
    new_entry->prev = prev;
    prev->next = new_entry;
    head->prev = new_entry;
}

void spin_lock(int *lock) {
    // stub implementation
}

void spin_unlock(int *lock) {
    // stub implementation
}

bool __rxrpc_use_local(struct list_head *local, int flag) {
    return true;  // stub implementation
}

void rxrpc_unuse_local(struct list_head *local, int flag) {
    // stub implementation
}

void rxrpc_put_peer(struct rxrpc_peer *peer, int discard_flag) {
    // stub implementation
}

enum {
    rxrpc_local_got_peer,
    rxrpc_local_lost_peer,
    rxrpc_peer_discard
};

u8 ARRAY_SIZE(struct list_head *arr) {
    return 8;  // stub implementation for array size
}

static void rxrpc_peer_keepalive_dispatch(struct rxrpc_net *rxnet, struct list_head *collector, time64_t base, u8 cursor) {
    struct rxrpc_peer *peer;
    const u8 mask = ARRAY_SIZE(rxnet->peer_keepalive) - 1;
    time64_t now, when;
    bool alive;
    u8 idx;

    spin_lock(&rxnet->peer_hash_lock);

    while (!list_empty(collector)) {
        peer = list_first_entry(collector, (unsigned long)&((struct rxrpc_peer *)0)->keepalive_link);
        list_del_init(&peer->keepalive_link);

        if (atomic_inc_not_zero(&peer->ref)) {
            spin_unlock(&rxnet->peer_hash_lock);

            alive = true;
            if (rxnet->local && !__rxrpc_use_local(rxnet->local, rxrpc_local_got_peer))
                alive = false;

            now = ktime_get_real_seconds();
            when = peer->last_tx_at ? : now;
            when += rxnet->peer_keepalive_interval;

            if ((now > base || when >= base + RXRPC_PEER_MAX_LIFE) &&
                when < now + RXRPC_PEER_MAX_LIFE) {
                idx = (when >> rxnet->peer_keepalive_shift) & mask;
                spin_lock(&rxnet->peer_hash_lock);
                list_add_tail(&peer->keepalive_link, &rxnet->peer_keepalive[idx]);
                spin_unlock(&rxnet->peer_hash_lock);
            }

            if (alive)
                rxrpc_unuse_local(rxnet->local, rxrpc_local_lost_peer);
            rxrpc_put_peer(peer, rxrpc_peer_discard);
        }

        spin_lock(&rxnet->peer_hash_lock);
    }

    spin_unlock(&rxnet->peer_hash_lock);
}

