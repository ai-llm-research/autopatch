```c
struct am65_cpsw_common {
    struct device       *dev;
    struct device       *mdio_dev;
    struct am65_cpsw_pdata  pdata;

    void __iomem        *ss_base;
    void __iomem        *cpsw_base;

    u32         port_num;
    struct am65_cpsw_host   host;
    struct am65_cpsw_port   *ports;
    u32         disabled_ports_mask;
    struct net_device   *dma_ndev;

    int         usage_count; /* number of opened ports */
    struct cpsw_ale     *ale;
    int         tx_ch_num;
    u32         tx_ch_rate_msk;
    u32         rx_flow_id_base;

    struct am65_cpsw_tx_chn tx_chns[AM65_CPSW_MAX_QUEUES];
    struct completion   tdown_complete;
    atomic_t        tdown_cnt;

    int         rx_ch_num_flows;
    struct am65_cpsw_rx_chn rx_chns;

    u32         nuss_ver;
    u32         cpsw_ver;
    unsigned long       bus_freq;
    bool            pf_p0_rx_ptype_rrobin;
    struct am65_cpts    *cpts;
    int         est_enabled;
    bool            iet_enabled;

    bool        is_emac_mode;
    u16         br_members;
    int         default_vlan;
    struct devlink *devlink;
    struct net_device *hw_bridge_dev;
    struct notifier_block am65_cpsw_netdevice_nb;
    unsigned char switch_id[MAX_PHYS_ITEM_ID_LEN];
    /* only for suspend/resume context restore */
    u32         *ale_context;
};
```

```c
struct device {
    struct kobject kobj;
    struct device       *parent;

    struct device_private   *p;

    const char      *init_name; /* initial name of the device */
    const struct device_type *type;

    const struct bus_type   *bus;   /* type of bus device is on */
    struct device_driver *driver;   /* which driver has allocated this
                       device */
    void        *platform_data; /* Platform specific data, device
                       core doesn't touch it */
    void        *driver_data;   /* Driver data, set and get with
                       dev_set_drvdata/dev_get_drvdata */
    struct mutex        mutex;  /* mutex to synchronize calls to
                     * its driver.
                     */

    struct dev_links_info   links;
    struct dev_pm_info  power;
    struct dev_pm_domain    *pm_domain;

#ifdef CONFIG_ENERGY_MODEL
    struct em_perf_domain   *em_pd;
#endif

#ifdef CONFIG_PINCTRL
    struct dev_pin_info *pins;
#endif
    struct dev_msi_info msi;
#ifdef CONFIG_ARCH_HAS_DMA_OPS
    const struct dma_map_ops *dma_ops;
#endif
    u64     *dma_mask;  /* dma mask (if dma'able device) */
    u64     coherent_dma_mask;/* Like dma_mask, but for
                         alloc_coherent mappings as
                         not all hardware supports
                         64 bit addresses for consistent
                         allocations such descriptors. */
    u64     bus_dma_limit;  /* upstream dma constraint */
    const struct bus_dma_region *dma_range_map;

    struct device_dma_parameters *dma_parms;

    struct list_head    dma_pools;  /* dma pools (if dma'ble) */

#ifdef CONFIG_DMA_DECLARE_COHERENT
    struct dma_coherent_mem *dma_mem; /* internal for coherent mem
                         override */
#endif
#ifdef CONFIG_DMA_CMA
    struct cma *cma_area;       /* contiguous memory area for dma
                       allocations */
#endif
#ifdef CONFIG_SWIOTLB
    struct io_tlb_mem *dma_io_tlb_mem;
#endif
#ifdef CONFIG_SWIOTLB_DYNAMIC
    struct list_head dma_io_tlb_pools;
    spinlock_t dma_io_tlb_lock;
    bool dma_uses_io_tlb;
#endif
    /* arch specific additions */
    struct dev_archdata archdata;

    struct device_node  *of_node; /* associated device tree node */
    struct fwnode_handle    *fwnode; /* firmware device node */

#ifdef CONFIG_NUMA
    int     numa_node;  /* NUMA node this device is close to */
#endif
    dev_t           devt;   /* dev_t, creates the sysfs "dev" */
    u32         id; /* device instance */

    spinlock_t      devres_lock;
    struct list_head    devres_head;

    const struct class  *class;
    const struct attribute_group **groups;  /* optional groups */

    void    (*release)(struct device *dev);
    struct iommu_group  *iommu_group;
    struct dev_iommu    *iommu;

    struct device_physical_location *physical_location;

    enum device_removable   removable;

    bool            offline_disabled:1;
    bool            offline:1;
    bool            of_node_reused:1;
    bool            state_synced:1;
    bool            can_match:1;
#if defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_DEVICE) || \
    defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU) || \
    defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL)
    bool            dma_coherent:1;
#endif
#ifdef CONFIG_DMA_OPS_BYPASS
    bool            dma_ops_bypass : 1;
#endif
#ifdef CONFIG_DMA_NEED_SYNC
    bool            dma_skip_sync:1;
#endif
#ifdef CONFIG_IOMMU_DMA
    bool            dma_iommu:1;
#endif
};
```

```c
void devm_remove_action(struct device *dev, void (*action)(void *), void *data)
{
    struct action_devres devres = {
        .data = data,
        .action = action,
    };

    WARN_ON(devres_destroy(dev, devm_action_release, devm_action_match,
                   &devres));
}
EXPORT_SYMBOL_GPL(devm_remove_action);
```

```c
void devm_remove_action(struct device *dev, void (*action)(void *), void *data)
{
    struct action_devres devres = {
        .data = data,
        .action = action,
    };

    WARN_ON(devres_destroy(dev, devm_action_release, devm_action_match,
                   &devres));
}
EXPORT_SYMBOL_GPL(devm_remove_action);
```

```c
static void am65_cpsw_nuss_free_tx_chns(void *data)
{
    struct am65_cpsw_common *common = data;
    int i;

    for (i = 0; i < common->tx_ch_num; i++) {
        struct am65_cpsw_tx_chn *tx_chn = &common->tx_chns[i];

        if (!IS_ERR_OR_NULL(tx_chn->desc_pool))
            k3_cppi_desc_pool_destroy(tx_chn->desc_pool);

        if (!IS_ERR_OR_NULL(tx_chn->tx_chn))
            k3_udma_glue_release_tx_chn(tx_chn->tx_chn);

        memset(tx_chn, 0, sizeof(*tx_chn));
    }
}
```

```c
struct am65_cpsw_tx_chn {
    struct device *dma_dev;
    struct napi_struct napi_tx;
    struct am65_cpsw_common *common;
    struct k3_cppi_desc_pool *desc_pool;
    struct k3_udma_glue_tx_channel *tx_chn;
    spinlock_t lock; /* protect TX rings in multi-port mode */
    struct hrtimer tx_hrtimer;
    unsigned long tx_pace_timeout;
    int irq;
    u32 id;
    u32 descs_num;
    unsigned char dsize_log2;
    char tx_chn_name[128];
    u32 rate_mbps;
};
```

```c
void devm_free_irq(struct device *dev, unsigned int irq, void *dev_id)
{
    struct irq_devres match_data = { irq, dev_id };

    WARN_ON(devres_release(dev, devm_irq_release, devm_irq_match,
                   &match_data));
}
EXPORT_SYMBOL(devm_free_irq);
```

```c
static inline void netif_napi_del(struct napi_struct *napi)
{
    __netif_napi_del(napi);
    synchronize_net();
}
```

```c
static inline bool __must_check IS_ERR_OR_NULL(__force const void *ptr)
{
    return unlikely(!ptr) || IS_ERR_VALUE((unsigned long)ptr);
}
```

```c
void k3_cppi_desc_pool_destroy(struct k3_cppi_desc_pool *pool)
{
    if (!pool)
        return;

    WARN(gen_pool_size(pool->gen_pool) != gen_pool_avail(pool->gen_pool),
         "k3_knav_desc_pool size %zu != avail %zu",
         gen_pool_size(pool->gen_pool),
         gen_pool_avail(pool->gen_pool));
    if (pool->cpumem)
        dma_free_coherent(pool->dev, pool->mem_size, pool->cpumem,
                  pool->dma_addr);

    kfree(pool->desc_infos);

    gen_pool_destroy(pool->gen_pool);   /* frees pool->name */

    kfree(pool);
}
EXPORT_SYMBOL_GPL(k3_cppi_desc_pool_destroy);
```

```c
void k3_udma_glue_release_tx_chn(struct k3_udma_glue_tx_channel *tx_chn)
{
    if (tx_chn->psil_paired) {
        xudma_navss_psil_unpair(tx_chn->common.udmax,
                    tx_chn->common.src_thread,
                    tx_chn->common.dst_thread);
        tx_chn->psil_paired = false;
    }

    if (!IS_ERR_OR_NULL(tx_chn->udma_tchanx))
        xudma_tchan_put(tx_chn->common.udmax,
                tx_chn->udma_tchanx);

    if (tx_chn->ringtxcq)
        k3_ringacc_ring_free(tx_chn->ringtxcq);

    if (tx_chn->ringtx)
        k3_ringacc_ring_free(tx_chn->ringtx);

    if (tx_chn->common.chan_dev.parent) {
        device_unregister(&tx_chn->common.chan_dev);
        tx_chn->common.chan_dev.parent = NULL;
    }
}
EXPORT_SYMBOL_GPL(k3_udma_glue_release_tx_chn);
```

```c
#define __HAVE_ARCH_MEMSET
extern void *memset(void *, int, __kernel_size_t);
#define memset(d, c, n) __builtin_memset(d, c, n)
```
