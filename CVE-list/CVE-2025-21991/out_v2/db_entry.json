{
  "cwe_type": "Improper Validation of Array Index",
  "cve_id": "CVE-2025-21991",
  "supplementary_code": "```c\nstruct cpuinfo_x86 {\nunion {\n/*\n* The particular ordering (low-to-high) of (vendor,\n* family, model) is done in case range of models, like\n* it is usually done on AMD, need to be compared.\n*/\nstruct {\n__u8 x86_model;\n/* CPU family */\n__u8 x86;\n/* CPU vendor */\n__u8 x86_vendor;\n__u8 x86_reserved;\n};\n/* combined vendor, family, model */\n__u32 x86_vfm;\n};\n__u8 x86_stepping;\n#ifdef CONFIG_X86_64\n/* Number of 4K pages in DTLB/ITLB combined(in pages): */\nint x86_tlbsize;\n#endif\n#ifdef CONFIG_X86_VMX_FEATURE_NAMES\n__u32 vmx_capability[NVMXINTS];\n#endif\n__u8 x86_virt_bits;\n__u8 x86_phys_bits;\n/* Max extended CPUID function supported: */\n__u32 extended_cpuid_level;\n/* Maximum supported CPUID level, -1=no CPUID: */\nint cpuid_level;\n/*\n* Align to size of unsigned long because the x86_capability array\n* is passed to bitops which require the alignment. Use unnamed\n* union to enforce the array is aligned to size of unsigned long.\n*/\nunion {\n__u32 x86_capability[NCAPINTS + NBUGINTS];\nunsigned long x86_capability_alignment;\n};\nchar x86_vendor_id[16];\nchar x86_model_id[64];\nstruct cpuinfo_topology topo;\n/* in KB - valid for CPUS which support this call: */\nunsigned int x86_cache_size;\nint x86_cache_alignment; /* In bytes */\n/* Cache QoS architectural values, valid only on the BSP: */\nint x86_cache_max_rmid; /* max index */\nint x86_cache_occ_scale; /* scale to bytes */\nint x86_cache_mbm_width_offset;\nint x86_power;\nunsigned long loops_per_jiffy;\n/* protected processor identification number */\nu64 ppin;\nu16 x86_clflush_size;\n/* number of cores as seen by the OS: */\nu16 booted_cores;\n/* Index into per_cpu list: */\nu16 cpu_index;\n/* Is SMT active on this core? */\nbool smt_active;\nu32 microcode;\n/* Address space bits used by the cache internally */\nu8 x86_cache_bits;\nunsigned initialized : 1;\n} __randomize_layout;\n```\n```c\nstruct ucode_patch {\nstruct list_head plist;\nvoid *data;\nunsigned int size;\nu32 patch_id;\nu16 equiv_cpu;\n};\n```\n```c\nenum ucode_state {\nUCODE_OK = 0,\nUCODE_NEW,\nUCODE_NEW_SAFE,\nUCODE_UPDATED,\nUCODE_NFOUND,\nUCODE_ERROR,\nUCODE_TIMEOUT,\nUCODE_OFFLINE,\n};\n```\n```c\nstatic enum ucode_state _load_microcode_amd(u8 family, const u8 *data, size_t size)\n{\nenum ucode_state ret;\n/* free old equiv table */\nfree_equiv_cpu_table();\nret = __load_microcode_amd(family, data, size);\nif (ret != UCODE_OK)\ncleanup();\nreturn ret;\n}\n```\n```c\nstatic __always_inline unsigned int cpumask_first(const struct cpumask *srcp)\n{\nreturn find_first_bit(cpumask_bits(srcp), small_cpumask_bits);\n}\n```\n```c\n#define cpu_data(cpu) per_cpu(cpu_info, cpu)\n```\n```c\nstatic struct ucode_patch *find_patch(unsigned int cpu)\n{\nstruct ucode_cpu_info *uci = ucode_cpu_info + cpu;\nu32 rev, dummy __always_unused;\nu16 equiv_id = 0;\n/* fetch rev if not populated yet: */\nif (!uci->cpu_sig.rev) {\nrdmsr(MSR_AMD64_PATCH_LEVEL, rev, dummy);\nuci->cpu_sig.rev = rev;\n}\nif (x86_family(bsp_cpuid_1_eax) < 0x17) {\nequiv_id = find_equiv_id(&equiv_table, uci->cpu_sig.sig);\nif (!equiv_id)\nreturn NULL;\n}\nreturn cache_find_patch(uci, equiv_id);\n}\n```",
  "original_code": "```c\nstatic enum ucode_state load_microcode_amd(u8 family, const u8 *data, size_t size)\n{\nstruct cpuinfo_x86 *c;\nunsigned int nid, cpu;\nstruct ucode_patch *p;\nenum ucode_state ret;\nret = _load_microcode_amd(family, data, size);\nif (ret != UCODE_OK)\nreturn ret;\nfor_each_node(nid) {\ncpu = cpumask_first(cpumask_of_node(nid));\nc = &cpu_data(cpu);\np = find_patch(cpu);\nif (!p)\ncontinue;\nif (c->microcode >= p->patch_id)\ncontinue;\nret = UCODE_NEW;\n}\nreturn ret;\n}\n```",
  "vuln_patch": "```c\nstatic enum ucode_state load_microcode_amd(u8 family, const u8 *data, size_t size)\n{\nstruct cpuinfo_x86 *c;\nunsigned int nid, cpu;\nstruct ucode_patch *p;\nenum ucode_state ret;\nret = _load_microcode_amd(family, data, size);\nif (ret != UCODE_OK)\nreturn ret;\nfor_each_node_with_cpus(nid) {\ncpu = cpumask_first(cpumask_of_node(nid));\nc = &cpu_data(cpu);\np = find_patch(cpu);\nif (!p)\ncontinue;\nif (c->microcode >= p->patch_id)\ncontinue;\nret = UCODE_NEW;\n}\nreturn ret;\n}\n```",
  "function_name": "load_microcode_amd",
  "function_prototype": "static enum ucode_state load_microcode_amd(u8 family, const u8 *data, size_t size)",
  "code_semantics": "The target code is a function that manages the process of updating microcode for processors. It begins by attempting to load new microcode data. If this initial attempt is unsuccessful, it returns an error or status code. If successful, it proceeds to check each processor node for available microcode patches. For each processor, it compares the current microcode version with the available patch version. If a newer patch is available, it updates the status to indicate that a new microcode update is ready. The function concludes by returning the status of the microcode update process.",
  "safe_verification_cot": "1. The macro for_each_node_with_cpus is used, ensuring that only nodes with CPUs are iterated over, preventing out-of-bounds access. 2. The variable cpu is guaranteed to be valid because the iteration only includes nodes with CPUs. 3. The function find_patch receives a valid cpu value, ensuring correct behavior. 4. The variable c is properly initialized with valid CPU data, preventing undefined behavior.",
  "verification_cot": "1. The macro for_each_node is used, which does not ensure that the node has CPUs, leading to potential out-of-bounds access. 2. The variable cpu may not be valid if the node does not have CPUs, leading to invalid access when calling cpu_data(cpu). 3. The function find_patch may receive an invalid cpu value, leading to incorrect behavior or crashes. 4. The variable c may be improperly initialized if cpu is invalid, leading to undefined behavior.",
  "vulnerability_related_variables": {
    "nid": "This variable represents an identifier for a node in a multi-node system. It is used to iterate over each node to perform operations specific to that node.",
    "cpu": "This variable represents an identifier for a CPU within a node. It is used to access and manipulate data specific to that CPU.",
    "c": "This variable is a reference to a data structure containing detailed information about a CPU. It is used to read or update CPU-specific attributes, such as microcode version.",
    "p": "This variable is a reference to a data structure representing a microcode patch. It is used to determine if a new microcode update is applicable to a CPU."
  },
  "vulnerability_related_functions": {
    "for_each_node": "This function iterates over each node in a system, allowing operations to be performed on each node sequentially.",
    "for_each_node_with_cpus": "This function iterates over each node that contains CPUs, enabling operations to be performed on nodes with active CPUs.",
    "cpumask_first": "This function identifies the first active CPU in a given set of CPUs, represented by a bitmask, and returns its index.",
    "cpu_data": "This function retrieves the data structure containing detailed information about a specific CPU, given its index.",
    "find_patch": "This function locates a microcode update patch that is applicable to a specific CPU, based on its characteristics."
  },
  "root_cause": "Improper validation of array index when iterating over nodes without ensuring they have CPUs.",
  "patch_cot": "1. Replace the use of for_each_node with for_each_node_with_cpus to ensure that the iteration only includes nodes that have CPUs. This prevents accessing invalid indices in the cpu_data array.\n2. Ensure that the cpu variable is correctly initialized by cpumask_first and corresponds to a valid CPU index.\n3. Verify that the find_patch function is called with a valid cpu index and that it handles cases where no patch is found.\n4. Confirm that the c variable is correctly assigned from cpu_data(cpu) and corresponds to a valid CPU structure.\n5. By following these steps, the vulnerability related to improper validation of array indices can be effectively mitigated."
}