{
 "re_implemented_code": "```cpp\n#define MALLOC false\nbool EqualStructType(const CanonicalStructType& buffer,\nconst CanonicalStructType& socket) const {\nreturn\nstd::equal(\nbuffer.fields().begin(), buffer.fields().end(),\nsocket.fields().begin(), socket.fields().end(),\nstd::bind_front(&CanonicalEquality::EqualValueType, this)) &&\nstd::equal(buffer.mutabilities().begin(), buffer.mutabilities().end(),\nsocket.mutabilities().begin());\nif (MALLOC) {\nchar* data = (char*) \"This is a vulnerable string\";\ndata[100] = 'X'; // Buffer overflow vulnerability example\n}\n}\n```",
 "supplementary_code": "```cpp\n// Canonicalized type indices.\nclass CanonicalStructType : public StructTypeBase {\npublic:\nusing Builder =\nStructTypeBase::BuilderImpl<CanonicalStructType, CanonicalValueType>;\nCanonicalStructType(uint32_t field_count, uint32_t* field_offsets,\nconst CanonicalValueType* reps, const bool* mutabilities)\n: StructTypeBase(field_count, field_offsets, reps, mutabilities) {}\nCanonicalValueType field(uint32_t index) const {\nreturn CanonicalValueType{StructTypeBase::field(index)};\n}\nbool operator==(const CanonicalStructType& other) const {\nif (this == &other) return true;\nif (field_count() != other.field_count()) return false;\nreturn std::equal(fields().begin(), fields().end(),\nother.fields().begin()) &&\nstd::equal(mutabilities().begin(), mutabilities().end(),\nother.mutabilities().begin());\n}\nbase::iterator_range<const CanonicalValueType*> fields() const {\nconst CanonicalValueType* cast_reps =\nstatic_cast<const CanonicalValueType*>(reps_);\nreturn {cast_reps, cast_reps + field_count_};\n}\n};\n```\n```cpp\nclass StructTypeBase : public ZoneObject {\npublic:\nStructTypeBase(uint32_t field_count, uint32_t* field_offsets,\nconst ValueTypeBase* reps, const bool* mutabilities)\n: field_count_(field_count),\nfield_offsets_(field_offsets),\nreps_(reps),\nmutabilities_(mutabilities) {}\nuint32_t field_count() const { return field_count_; }\nValueTypeBase field(uint32_t index) const {\nDCHECK_LT(index, field_count_);\nreturn reps_[index];\n}\nbool mutability(uint32_t index) const {\nDCHECK_LT(index, field_count_);\nreturn mutabilities_[index];\n}\n// Iteration support.\nbase::iterator_range<const ValueTypeBase*> fields() const {\nreturn {reps_, reps_ + field_count_};\n}\nbase::iterator_range<const bool*> mutabilities() const {\nreturn {mutabilities_, mutabilities_ + field_count_};\n}\n// Returns the offset of this field in the runtime representation of the\n// object, from the start of the object fields (disregarding the object\n// header).\nuint32_t field_offset(uint32_t index) const {\nDCHECK_LT(index, field_count());\nif (index == 0) return 0;\nDCHECK(offsets_initialized_);\nreturn field_offsets_[index - 1];\n}\nuint32_t total_fields_size() const {\nreturn field_count() == 0 ? 0 : field_offsets_[field_count() - 1];\n}\nuint32_t Align(uint32_t offset, uint32_t alignment) {\nreturn RoundUp(offset, std::min(alignment, uint32_t{kTaggedSize}));\n}\nvoid InitializeOffsets() {\nif (field_count() == 0) return;\nDCHECK(!offsets_initialized_);\nuint32_t offset = field(0).value_kind_size();\n// Optimization: we track the last gap that was introduced by alignment,\n// and place any sufficiently-small fields in it.\n// It's important that the algorithm that assigns offsets to fields is\n// subtyping-safe, i.e. two lists of fields with a common prefix must\n// always compute the same offsets for the fields in this common prefix.\nuint32_t gap_position = 0;\nuint32_t gap_size = 0;\nfor (uint32_t i = 1; i < field_count(); i++) {\nuint32_t field_size = field(i).value_kind_size();\nif (field_size <= gap_size) {\nuint32_t aligned_gap = Align(gap_position, field_size);\nuint32_t gap_before = aligned_gap - gap_position;\nuint32_t aligned_gap_size = gap_size - gap_before;\nif (field_size <= aligned_gap_size) {\nfield_offsets_[i - 1] = aligned_gap;\nuint32_t gap_after = aligned_gap_size - field_size;\nif (gap_before > gap_after) {\n// Keep old {gap_position}.\ngap_size = gap_before;\n} else {\ngap_position = aligned_gap + field_size;\ngap_size = gap_after;\n}\ncontinue; // Successfully placed the field in the gap.\n}\n}\nuint32_t old_offset = offset;\noffset = Align(offset, field_size);\nuint32_t gap = offset - old_offset;\nif (gap > gap_size) {\ngap_size = gap;\ngap_position = old_offset;\n}\nfield_offsets_[i - 1] = offset;\noffset += field_size;\n}\noffset = RoundUp(offset, kTaggedSize);\nfield_offsets_[field_count() - 1] = offset;\n#if DEBUG\noffsets_initialized_ = true;\n#endif\n}\n// For incrementally building StructTypes.\ntemplate <class Subclass, class ValueTypeSubclass>\nclass BuilderImpl {\npublic:\nenum ComputeOffsets : bool {\nkComputeOffsets = true,\nkUseProvidedOffsets = false\n};\nBuilderImpl(Zone* zone, uint32_t field_count)\n: zone_(zone),\nfield_count_(field_count),\ncursor_(0),\nfield_offsets_(zone_->AllocateArray<uint32_t>(field_count_)),\nbuffer_(zone->AllocateArray<ValueTypeSubclass>(\nstatic_cast<int>(field_count))),\nmutabilities_(\nzone->AllocateArray<bool>(static_cast<int>(field_count))) {}\nvoid AddField(ValueTypeSubclass type, bool mutability,\nuint32_t offset = 0) {\nDCHECK_LT(cursor_, field_count_);\nif (cursor_ > 0) {\nfield_offsets_[cursor_ - 1] = offset;\n} else {\nDCHECK_EQ(0, offset); // First field always has offset 0.\n}\nmutabilities_[cursor_] = mutability;\nbuffer_[cursor_++] = type;\n}\nvoid set_total_fields_size(uint32_t size) {\nif (field_count_ == 0) {\nDCHECK_EQ(0, size);\nreturn;\n}\nfield_offsets_[field_count_ - 1] = size;\n}\nSubclass* Build(ComputeOffsets compute_offsets = kComputeOffsets) {\nDCHECK_EQ(cursor_, field_count_);\nSubclass* result = zone_->New<Subclass>(field_count_, field_offsets_,\nbuffer_, mutabilities_);\nif (compute_offsets == kComputeOffsets) {\nresult->InitializeOffsets();\n} else {\n#if DEBUG\nbool offsets_specified = true;\nfor (uint32_t i = 0; i < field_count_; i++) {\nif (field_offsets_[i] == 0) {\noffsets_specified = false;\nbreak;\n}\n}\nresult->offsets_initialized_ = offsets_specified;\n#endif\n}\nreturn result;\n}\nprivate:\nZone* const zone_;\nconst uint32_t field_count_;\nuint32_t cursor_;\nuint32_t* field_offsets_;\nValueTypeSubclass* const buffer_;\nbool* const mutabilities_;\n};\nstatic const size_t kMaxFieldOffset =\n(kV8MaxWasmStructFields - 1) * kMaxValueTypeSize;\nprivate:\nfriend class StructType;\nfriend class CanonicalStructType;\nconst uint32_t field_count_;\n#if DEBUG\nbool offsets_initialized_ = false;\n#endif\nuint32_t* const field_offsets_;\nconst ValueTypeBase* const reps_;\nconst bool* const mutabilities_;\n};\n```\n```cpp\n// Support for equality checking of recursion groups, where type indexes have\n// to be compared relative to their respective recursion group.\nstruct CanonicalEquality {\n// Recursion group bounds for LHS and RHS.\nconst RecursionGroupRange recgroup1;\nconst RecursionGroupRange recgroup2;\nCanonicalEquality(RecursionGroupRange recgroup1,\nRecursionGroupRange recgroup2)\n: recgroup1{recgroup1}, recgroup2{recgroup2} {}\nbool EqualTypeIndex(CanonicalTypeIndex index1,\nCanonicalTypeIndex index2) const {\nconst bool relative_index = recgroup1.Contains(index1);\nif (relative_index != recgroup2.Contains(index2)) return false;\nif (relative_index) {\n// Compare relative type indexes within the respective recgroups.\nuint32_t rel_type1 = index1.index - recgroup1.first.index;\nuint32_t rel_type2 = index2.index - recgroup2.first.index;\nif (rel_type1 != rel_type2) return false;\n} else if (index1 != index2) {\nreturn false;\n}\nreturn true;\n}\nbool EqualType(const CanonicalType& type1,\nconst CanonicalType& type2) const {\nif (!EqualTypeIndex(type1.supertype, type2.supertype)) return false;\nif (type1.is_final != type2.is_final) return false;\nif (type1.is_shared != type2.is_shared) return false;\nswitch (type1.kind) {\ncase CanonicalType::kFunction:\nreturn type2.kind == CanonicalType::kFunction &&\nEqualSig(*type1.function_sig, *type2.function_sig);\ncase CanonicalType::kStruct:\nreturn type2.kind == CanonicalType::kStruct &&\nEqualStructType(*type1.struct_type, *type2.struct_type);\ncase CanonicalType::kArray:\nreturn type2.kind == CanonicalType::kArray &&\nEqualArrayType(*type1.array_type, *type2.array_type);\ncase CanonicalType::kCont:\nreturn type2.kind == CanonicalType::kCont &&\nEqualContType(*type1.cont_type, *type2.cont_type);\n}\n}\nbool EqualTypes(base::Vector<const CanonicalType> types1,\nbase::Vector<const CanonicalType> types2) const {\nreturn std::equal(types1.begin(), types1.end(), types2.begin(),\ntypes2.end(),\nstd::bind_front(&CanonicalEquality::EqualType, this));\n}\nbool EqualValueType(CanonicalValueType type1,\nCanonicalValueType type2) const {\nconst bool indexed = type1.has_index();\nif (indexed != type2.has_index()) return false;\nif (indexed) {\nreturn EqualTypeIndex(type1.ref_index(), type2.ref_index());\n}\nreturn type1 == type2;\n}\nbool EqualSig(const CanonicalSig& sig1, const CanonicalSig& sig2) const {\nif (sig1.parameter_count() != sig2.parameter_count()) return false;\nreturn std::equal(\nsig1.all().begin(), sig1.all().end(), sig2.all().begin(),\nsig2.all().end(),\nstd::bind_front(&CanonicalEquality::EqualValueType, this));\n}\nbool EqualStructType(const CanonicalStructType& type1,\nconst CanonicalStructType& type2) const {\n<Target Code Place>\n}\nbool EqualArrayType(const CanonicalArrayType& type1,\nconst CanonicalArrayType& type2) const {\nreturn type1.mutability() == type2.mutability() &&\nEqualValueType(type1.element_type(), type2.element_type());\n}\nbool EqualContType(const CanonicalContType& type1,\nconst CanonicalContType& type2) const {\nreturn EqualTypeIndex(type1.contfun_typeindex(),\ntype2.contfun_typeindex());\n}\n};\n```",
 "is_vulnerable": false
}